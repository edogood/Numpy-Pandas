{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984df3cd",
   "metadata": {},
   "source": [
    "# Lezione 29 — Fondamenti di Artificial Intelligence\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi di Apprendimento\n",
    "\n",
    "| Obiettivo | Descrizione |\n",
    "|-----------|-------------|\n",
    "| Comprendere | La distinzione tra AI, Machine Learning e Deep Learning |\n",
    "| Formalizzare | Il concetto di modello come funzione f(x) |\n",
    "| Distinguere | Training e Inference come fasi operative distinte |\n",
    "| Conoscere | Il No Free Lunch Theorem e le sue implicazioni pratiche |\n",
    "| Applicare | Il Rasoio di Occam nella scelta dei modelli |\n",
    "| Confrontare | Sistemi rule-based e sistemi data-driven |\n",
    "\n",
    "---\n",
    "\n",
    "## Perché Questa Lezione è Importante\n",
    "\n",
    "Questa lezione segna l'ingresso nel blocco dedicato all'**Artificial Intelligence**.\n",
    "\n",
    "Fino ad ora abbiamo studiato tecniche di Machine Learning supervisionato e non supervisionato, trattandole come strumenti operativi. Ora è necessario collocare queste tecniche in un quadro teorico più ampio, comprendendo:\n",
    "\n",
    "1. **Cosa significa realmente \"intelligenza artificiale\"**\n",
    "2. **Quali sono i limiti teorici di ogni approccio**\n",
    "3. **Come scegliere lo strumento giusto per il problema giusto**\n",
    "\n",
    "Un Data Analyst deve possedere una visione chiara di questi concetti per:\n",
    "- Comunicare correttamente con stakeholder tecnici e non tecnici\n",
    "- Evitare scelte tecnologiche inappropriate\n",
    "- Riconoscere i limiti intrinseci di ogni soluzione\n",
    "\n",
    "---\n",
    "\n",
    "## Posizione nel Percorso\n",
    "\n",
    "```\n",
    "BLOCCO 1: Fondamenti (Lezioni 1-18)\n",
    "    └── Python, NumPy, Pandas, Visualizzazione, Statistica\n",
    "\n",
    "BLOCCO 2: Machine Learning Supervisionato (già completato)\n",
    "    └── Regressione, Classificazione, Valutazione, Tuning\n",
    "\n",
    "BLOCCO 3: Machine Learning Non Supervisionato (Lezioni 19-28)\n",
    "    └── Clustering, PCA, Anomaly Detection, Feature Engineering\n",
    "\n",
    "BLOCCO 4: Artificial Intelligence & NLP (Lezioni 29-40) ← SIAMO QUI\n",
    "    └── Fondamenti AI, NLP, Knowledge Mining, Generative AI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c1607",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Sezione 1: Teoria Concettuale\n",
    "\n",
    "## 1.1 Che Cos'è l'Intelligenza Artificiale?\n",
    "\n",
    "### Definizione Operativa\n",
    "\n",
    "L'**Artificial Intelligence (AI)** è un campo dell'informatica che studia la progettazione di sistemi in grado di eseguire compiti che, se eseguiti da un essere umano, richiederebbero intelligenza.\n",
    "\n",
    "Questa definizione è volutamente ampia e include:\n",
    "- Sistemi che giocano a scacchi\n",
    "- Sistemi che riconoscono volti\n",
    "- Sistemi che traducono testi\n",
    "- Sistemi che guidano automobili\n",
    "\n",
    "### Precisazione Terminologica\n",
    "\n",
    "Il termine \"intelligenza\" in questo contesto **non** implica:\n",
    "- Coscienza\n",
    "- Comprensione semantica\n",
    "- Intenzionalità\n",
    "\n",
    "Implica invece:\n",
    "- Capacità di risolvere problemi specifici\n",
    "- Capacità di generalizzare da esempi\n",
    "- Capacità di adattarsi a input nuovi\n",
    "\n",
    "### Breve Storia\n",
    "\n",
    "| Periodo | Paradigma Dominante | Caratteristica |\n",
    "|---------|---------------------|----------------|\n",
    "| 1950-1970 | AI Simbolica | Regole esplicite, logica formale |\n",
    "| 1980-1990 | Sistemi Esperti | Knowledge base + inference engine |\n",
    "| 1990-2010 | Machine Learning Statistico | Apprendimento da dati |\n",
    "| 2010-oggi | Deep Learning | Reti neurali profonde, big data |\n",
    "\n",
    "Questa evoluzione non è lineare né sostitutiva: ogni paradigma ha ancora applicazioni valide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58224e0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 AI vs Machine Learning vs Deep Learning\n",
    "\n",
    "### La Gerarchia Concettuale\n",
    "\n",
    "Questi tre termini sono spesso usati in modo intercambiabile, ma rappresentano concetti distinti con una relazione gerarchica precisa.\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    ARTIFICIAL INTELLIGENCE                       │\n",
    "│    Qualsiasi sistema che esibisce comportamento \"intelligente\"  │\n",
    "│                                                                  │\n",
    "│    ┌─────────────────────────────────────────────────────────┐  │\n",
    "│    │                  MACHINE LEARNING                        │  │\n",
    "│    │    Sistemi che apprendono da dati senza essere          │  │\n",
    "│    │    esplicitamente programmati per ogni caso             │  │\n",
    "│    │                                                          │  │\n",
    "│    │    ┌─────────────────────────────────────────────────┐  │  │\n",
    "│    │    │               DEEP LEARNING                      │  │  │\n",
    "│    │    │    ML basato su reti neurali con molti layer    │  │  │\n",
    "│    │    │    (rappresentazione gerarchica delle feature)   │  │  │\n",
    "│    │    └─────────────────────────────────────────────────┘  │  │\n",
    "│    └─────────────────────────────────────────────────────────┘  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Definizioni Formali\n",
    "\n",
    "**Artificial Intelligence (AI)**\n",
    "> Campo che studia la creazione di agenti razionali, dove un agente è un'entità che percepisce il suo ambiente e agisce per massimizzare le probabilità di successo rispetto a un obiettivo.\n",
    "\n",
    "**Machine Learning (ML)**\n",
    "> Sottocampo dell'AI in cui i sistemi migliorano automaticamente le loro prestazioni attraverso l'esperienza (dati), senza essere esplicitamente programmati per ogni caso specifico.\n",
    "\n",
    "**Deep Learning (DL)**\n",
    "> Sottocampo del ML che utilizza reti neurali artificiali con molteplici strati nascosti (deep = profondo) per apprendere rappresentazioni gerarchiche dei dati.\n",
    "\n",
    "### Confronto Operativo\n",
    "\n",
    "| Aspetto | AI (generale) | Machine Learning | Deep Learning |\n",
    "|---------|---------------|------------------|---------------|\n",
    "| **Approccio** | Può essere rule-based o data-driven | Sempre data-driven | Data-driven con architetture neurali |\n",
    "| **Dati richiesti** | Variabile | Medio-alti | Molto alti |\n",
    "| **Interpretabilità** | Alta (se rule-based) | Media | Bassa |\n",
    "| **Feature engineering** | Manuale | Parzialmente automatico | Automatico |\n",
    "| **Risorse computazionali** | Variabile | Medie | Alte |\n",
    "\n",
    "### Esempio Concreto\n",
    "\n",
    "**Problema**: Riconoscere se un'email è spam.\n",
    "\n",
    "| Approccio | Implementazione |\n",
    "|-----------|-----------------|\n",
    "| **AI rule-based** | IF contiene \"viagra\" OR contiene \"lottery\" THEN spam |\n",
    "| **Machine Learning** | Naive Bayes su bag-of-words delle email |\n",
    "| **Deep Learning** | Rete neurale ricorrente sull'intera sequenza di token |\n",
    "\n",
    "Nessuno di questi approcci è intrinsecamente superiore: la scelta dipende dal contesto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e9b10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Il Modello come Funzione f(x)\n",
    "\n",
    "### Astrazione Fondamentale\n",
    "\n",
    "Qualsiasi sistema di AI/ML può essere astratto come una **funzione matematica**:\n",
    "\n",
    "$$\\hat{y} = f(x)$$\n",
    "\n",
    "Dove:\n",
    "- **x** = input (dati in ingresso)\n",
    "- **f** = modello (la trasformazione appresa o programmata)\n",
    "- **ŷ** = output (predizione, decisione, o azione)\n",
    "\n",
    "### Esempi di Mapping Input → Output\n",
    "\n",
    "| Dominio | Input (x) | Output (ŷ) | Tipo di f |\n",
    "|---------|-----------|------------|-----------|\n",
    "| Classificazione spam | Testo email | {spam, non_spam} | Classificatore binario |\n",
    "| Regressione prezzi | Caratteristiche casa | Prezzo € | Regressore |\n",
    "| Clustering clienti | Comportamento acquisto | ID cluster | Clustering |\n",
    "| OCR | Immagine documento | Stringa di testo | Sequence-to-sequence |\n",
    "| Chatbot | Domanda utente | Risposta testuale | Language model |\n",
    "\n",
    "### La Differenza Chiave: Come si Ottiene f\n",
    "\n",
    "**Programmazione Tradizionale**:\n",
    "```\n",
    "DATI + REGOLE → Programma → OUTPUT\n",
    "```\n",
    "Il programmatore scrive esplicitamente le regole che trasformano l'input in output.\n",
    "\n",
    "**Machine Learning**:\n",
    "```\n",
    "DATI + OUTPUT DESIDERATO → Algoritmo di apprendimento → MODELLO (f)\n",
    "```\n",
    "L'algoritmo **induce** le regole (il modello f) a partire da esempi di coppie input-output.\n",
    "\n",
    "### Formalizzazione\n",
    "\n",
    "Nel Machine Learning supervisionato, dato un dataset di training:\n",
    "\n",
    "$$D = \\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}$$\n",
    "\n",
    "L'obiettivo è trovare una funzione $f^*$ che minimizza una **loss function** $L$:\n",
    "\n",
    "$$f^* = \\arg\\min_f \\sum_{i=1}^{n} L(f(x_i), y_i)$$\n",
    "\n",
    "In termini pratici: trovare la f che commette meno errori possibile sui dati di training, sperando che generalizzi bene su dati mai visti.\n",
    "\n",
    "### Implicazione Pratica\n",
    "\n",
    "Come data analyst, quando usi un modello di ML stai essenzialmente:\n",
    "1. **Scegliendo** una famiglia di funzioni possibili (es. alberi, regressione lineare, reti neurali)\n",
    "2. **Addestrando** l'algoritmo per trovare la f migliore in quella famiglia\n",
    "3. **Applicando** quella f a nuovi dati per ottenere predizioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e475a8f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 Training vs Inference\n",
    "\n",
    "### Due Fasi Distinte\n",
    "\n",
    "Ogni sistema di Machine Learning opera in due fasi fondamentalmente diverse:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                         TRAINING                                 │\n",
    "│   \"Insegnare al modello usando dati storici\"                    │\n",
    "│                                                                  │\n",
    "│   Input: Dataset etichettato (X_train, y_train)                 │\n",
    "│   Processo: Ottimizzazione iterativa dei parametri              │\n",
    "│   Output: Modello addestrato (f con parametri θ fissati)        │\n",
    "│   Frequenza: Una volta (o periodicamente per retraining)        │\n",
    "│   Risorse: Alte (CPU/GPU, memoria, tempo)                       │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "                              ▼\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                        INFERENCE                                 │\n",
    "│   \"Usare il modello addestrato per fare predizioni\"            │\n",
    "│                                                                  │\n",
    "│   Input: Nuovo dato (x_new) mai visto                           │\n",
    "│   Processo: Applicazione diretta di f(x_new)                    │\n",
    "│   Output: Predizione ŷ                                          │\n",
    "│   Frequenza: Continua (ogni volta che serve una predizione)     │\n",
    "│   Risorse: Relativamente basse                                  │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Analogia Concettuale\n",
    "\n",
    "| Fase | Analogia Umana | Cosa Succede |\n",
    "|------|----------------|--------------|\n",
    "| **Training** | Studiare per un esame | Il modello \"impara\" dai dati, aggiustando i suoi parametri interni |\n",
    "| **Inference** | Sostenere l'esame | Il modello applica ciò che ha imparato a nuove situazioni |\n",
    "\n",
    "### Caratteristiche a Confronto\n",
    "\n",
    "| Aspetto | Training | Inference |\n",
    "|---------|----------|-----------|\n",
    "| **Obiettivo** | Minimizzare errore sui dati di training | Produrre output per nuovi input |\n",
    "| **Dati richiesti** | Dataset completo con labels | Singolo dato (o batch) |\n",
    "| **Modifica modello** | Sì (parametri si aggiornano) | No (modello \"congelato\") |\n",
    "| **Tempo di esecuzione** | Ore o giorni | Millisecondi o secondi |\n",
    "| **Hardware tipico** | GPU cluster, server potenti | CPU standard, dispositivi edge |\n",
    "| **Errori** | Accettabili (fa parte dell'apprendimento) | Da minimizzare (impatto su utenti) |\n",
    "\n",
    "### Flusso Operativo Reale\n",
    "\n",
    "```\n",
    "1. TRAINING (offline)\n",
    "   ├── Raccolta dati storici\n",
    "   ├── Preprocessing e pulizia\n",
    "   ├── Split train/validation/test\n",
    "   ├── Addestramento modello\n",
    "   ├── Validazione e tuning\n",
    "   ├── Test finale\n",
    "   └── Salvataggio modello (.pkl, .joblib, .h5, ecc.)\n",
    "\n",
    "2. DEPLOYMENT (una tantum)\n",
    "   └── Caricamento modello in ambiente di produzione\n",
    "\n",
    "3. INFERENCE (online, continua)\n",
    "   ├── Ricezione nuovo dato\n",
    "   ├── Preprocessing identico al training\n",
    "   ├── model.predict(x_new)\n",
    "   └── Restituzione risultato\n",
    "```\n",
    "\n",
    "### Implicazione per Data Analyst\n",
    "\n",
    "La maggior parte del lavoro di un data analyst riguarda la fase di **training** e **validazione**. L'inference è spesso gestita da sistemi automatizzati o da team di ML engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab4125",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Il Teorema \"No Free Lunch\"\n",
    "\n",
    "### Enunciato Informale\n",
    "\n",
    "> Non esiste un algoritmo di Machine Learning universalmente superiore a tutti gli altri su tutti i possibili problemi.\n",
    "\n",
    "In altre parole: **ogni algoritmo ha i suoi punti di forza e debolezza**, e la scelta dipende dal problema specifico.\n",
    "\n",
    "### Enunciato Formale (Wolpert & Macready, 1997)\n",
    "\n",
    "Per qualsiasi coppia di algoritmi di ottimizzazione A e B:\n",
    "\n",
    "$$\\sum_f P(d_m^y | f, m, A) = \\sum_f P(d_m^y | f, m, B)$$\n",
    "\n",
    "Dove la somma è su tutte le possibili funzioni obiettivo f. \n",
    "\n",
    "**Traduzione**: mediando su tutti i possibili problemi, ogni algoritmo ha le stesse prestazioni. Se un algoritmo eccelle su alcuni problemi, necessariamente performa peggio su altri.\n",
    "\n",
    "### Implicazioni Pratiche\n",
    "\n",
    "| Conseguenza | Cosa Significa in Pratica |\n",
    "|-------------|---------------------------|\n",
    "| **Non esiste il \"migliore\" in assoluto** | Random Forest non è sempre meglio di Logistic Regression |\n",
    "| **Il contesto è tutto** | La struttura dei dati determina quale algoritmo funzionerà meglio |\n",
    "| **Sperimentazione necessaria** | Bisogna provare più algoritmi e confrontarli sul proprio dataset |\n",
    "| **Prior knowledge è valore** | La conoscenza del dominio aiuta a scegliere algoritmi appropriati |\n",
    "\n",
    "### Esempio Concreto\n",
    "\n",
    "**Dataset A**: 10.000 campioni, 5 feature, relazione lineare tra input e output.\n",
    "- Migliore: Regressione Lineare (semplice, appropriata)\n",
    "- Peggiore: Rete neurale profonda (overfitting garantito)\n",
    "\n",
    "**Dataset B**: 1.000.000 immagini, pattern complessi non lineari.\n",
    "- Migliore: Rete neurale convoluzionale (CNN)\n",
    "- Peggiore: Regressione Lineare (troppo semplice)\n",
    "\n",
    "### Anti-Pattern Comune\n",
    "\n",
    "```\n",
    "❌ \"Uso sempre XGBoost perché è il migliore\"\n",
    "❌ \"Le reti neurali risolvono tutto\"\n",
    "❌ \"La regressione logistica è obsoleta\"\n",
    "\n",
    "✓ \"Scelgo l'algoritmo basandomi sulle caratteristiche del problema\"\n",
    "✓ \"Provo più approcci e confronto le prestazioni\"\n",
    "✓ \"Considero anche interpretabilità e costi computazionali\"\n",
    "```\n",
    "\n",
    "### Corollario per Data Analyst\n",
    "\n",
    "Il No Free Lunch Theorem giustifica l'approccio empirico del Machine Learning: non puoi sapere a priori quale algoritmo funzionerà meglio, quindi devi **sperimentare e validare**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc02cf7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.6 Il Rasoio di Occam nel Machine Learning\n",
    "\n",
    "### Principio Filosofico Originale\n",
    "\n",
    "> \"Entia non sunt multiplicanda praeter necessitatem\"\n",
    "> (Le entità non devono essere moltiplicate oltre il necessario)\n",
    "\n",
    "**Traduzione moderna**: tra più spiegazioni equivalenti, preferisci la più semplice.\n",
    "\n",
    "### Applicazione al Machine Learning\n",
    "\n",
    "Nel contesto ML, il Rasoio di Occam si traduce in:\n",
    "\n",
    "> A parità di prestazioni predittive, preferisci il modello più semplice.\n",
    "\n",
    "### Perché la Semplicità è Preferibile\n",
    "\n",
    "| Vantaggio | Spiegazione |\n",
    "|-----------|-------------|\n",
    "| **Generalizzazione** | Modelli semplici tendono a generalizzare meglio su dati nuovi |\n",
    "| **Interpretabilità** | Più facile capire e spiegare il funzionamento |\n",
    "| **Manutenibilità** | Più semplice da aggiornare e debuggare |\n",
    "| **Efficienza** | Meno risorse computazionali richieste |\n",
    "| **Robustezza** | Meno sensibile a rumore nei dati |\n",
    "\n",
    "### Il Trade-off Bias-Varianza\n",
    "\n",
    "Il Rasoio di Occam è strettamente legato al trade-off bias-varianza:\n",
    "\n",
    "```\n",
    "Modello troppo semplice (high bias)\n",
    "    └── Underfitting: non cattura la struttura dei dati\n",
    "    \n",
    "Modello troppo complesso (high variance)\n",
    "    └── Overfitting: memorizza il rumore invece del pattern\n",
    "    \n",
    "Modello \"giusto\" (Occam)\n",
    "    └── Bilancia complessità e capacità predittiva\n",
    "```\n",
    "\n",
    "### Formalizzazione: Principio MDL\n",
    "\n",
    "Il **Minimum Description Length** (MDL) formalizza matematicamente il Rasoio di Occam:\n",
    "\n",
    "$$\\text{Best Model} = \\arg\\min_M \\big[ L(\\text{Model}) + L(\\text{Data | Model}) \\big]$$\n",
    "\n",
    "Dove:\n",
    "- L(Model) = lunghezza della descrizione del modello (complessità)\n",
    "- L(Data | Model) = lunghezza della descrizione dei residui (errore)\n",
    "\n",
    "**Obiettivo**: minimizzare la somma di complessità ed errore.\n",
    "\n",
    "### Esempi Pratici\n",
    "\n",
    "**Scenario**: Regressione con R² = 0.85\n",
    "\n",
    "| Modello | Complessità | Scelta |\n",
    "|---------|-------------|--------|\n",
    "| Regressione lineare (3 parametri) | Bassa | ✓ **Preferito** |\n",
    "| Random Forest (1000 alberi) | Alta | Solo se significativamente migliore |\n",
    "| Rete neurale (10 layer) | Molto alta | Giustificato solo per guadagni sostanziali |\n",
    "\n",
    "### Implementazione in scikit-learn\n",
    "\n",
    "La regolarizzazione è l'implementazione pratica del Rasoio di Occam:\n",
    "\n",
    "- **L1 (Lasso)**: penalizza la somma dei valori assoluti dei coefficienti → sparsità\n",
    "- **L2 (Ridge)**: penalizza la somma dei quadrati dei coefficienti → coefficienti piccoli\n",
    "- **ElasticNet**: combinazione di L1 e L2\n",
    "\n",
    "```python\n",
    "# Esempio concettuale\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# alpha controlla quanto \"punire\" la complessità\n",
    "model = Ridge(alpha=1.0)  # alpha più alto = modello più semplice\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5e4ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.7 Sistemi Rule-Based vs Data-Driven\n",
    "\n",
    "### Due Paradigmi Fondamentali\n",
    "\n",
    "Nel campo dell'AI esistono due approcci radicalmente diversi per costruire sistemi intelligenti:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────┐    ┌─────────────────────────────────────┐\n",
    "│          RULE-BASED                  │    │           DATA-DRIVEN               │\n",
    "│    (Sistemi Esperti, Simbolico)     │    │      (Machine Learning)             │\n",
    "│                                      │    │                                      │\n",
    "│   Conoscenza → Regole Esplicite     │    │   Dati → Regole Implicite           │\n",
    "│   Esperto umano codifica le regole  │    │   Algoritmo estrae le regole        │\n",
    "│   \"Programmazione tradizionale\"     │    │   \"Apprendimento automatico\"        │\n",
    "└─────────────────────────────────────┘    └─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Confronto Dettagliato\n",
    "\n",
    "| Aspetto | Rule-Based | Data-Driven |\n",
    "|---------|------------|-------------|\n",
    "| **Fonte della logica** | Esperto di dominio | Dati storici |\n",
    "| **Rappresentazione** | IF-THEN-ELSE esplicite | Parametri numerici (pesi, split) |\n",
    "| **Interpretabilità** | Alta (regole leggibili) | Variabile (da alta a nulla) |\n",
    "| **Scalabilità** | Limitata (esplosione combinatoria) | Alta (più dati = più accuratezza) |\n",
    "| **Adattamento** | Manuale (riscrivere regole) | Automatico (retraining) |\n",
    "| **Costi iniziali** | Alti (elicitazione conoscenza) | Medi (raccolta dati) |\n",
    "| **Manutenzione** | Onerosa | Relativamente semplice |\n",
    "| **Copertura eccezioni** | Esplicita per ogni caso | Implicita (se nei dati) |\n",
    "\n",
    "### Esempio: Sistema di Approvazione Prestiti\n",
    "\n",
    "**Approccio Rule-Based**:\n",
    "```\n",
    "IF reddito > 50000 AND\n",
    "   anni_impiego > 2 AND\n",
    "   debiti_esistenti < 0.3 * reddito AND\n",
    "   score_creditizio > 700\n",
    "THEN approva_prestito\n",
    "ELSE rifiuta_prestito\n",
    "```\n",
    "\n",
    "**Approccio Data-Driven**:\n",
    "```python\n",
    "# Addestrato su storico di prestiti approvati/rifiutati\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_storico, y_esito)\n",
    "decisione = model.predict(X_nuovo_cliente)\n",
    "```\n",
    "\n",
    "### Quando Usare Quale\n",
    "\n",
    "| Scenario | Approccio Consigliato | Motivazione |\n",
    "|----------|----------------------|-------------|\n",
    "| Regole note e stabili | Rule-Based | Trasparenza, conformità normativa |\n",
    "| Regole sconosciute | Data-Driven | Scoperta automatica di pattern |\n",
    "| Pochi dati disponibili | Rule-Based | ML richiede dati sufficienti |\n",
    "| Molti dati, pattern complessi | Data-Driven | ML eccelle in questi scenari |\n",
    "| Requisiti di spiegabilità legale | Rule-Based (o ML interpretabile) | Audit trail chiaro |\n",
    "| Dominio in rapida evoluzione | Data-Driven | Adattamento tramite retraining |\n",
    "\n",
    "### Approcci Ibridi\n",
    "\n",
    "Nella pratica moderna, i due paradigmi spesso coesistono:\n",
    "\n",
    "1. **Pre-processing rule-based + ML core**: Regole per pulizia dati, ML per predizione\n",
    "2. **ML + post-processing rule-based**: ML propone, regole di business validano\n",
    "3. **Neuro-symbolic AI**: Integrazione di ragionamento simbolico e reti neurali\n",
    "\n",
    "### Evoluzione Storica\n",
    "\n",
    "```\n",
    "1950-1980: Dominanza AI Simbolica (rule-based)\n",
    "    └── Sistemi esperti, Prolog, LISP\n",
    "\n",
    "1990-2010: Ascesa del Machine Learning statistico\n",
    "    └── SVM, Random Forest, Boosting\n",
    "\n",
    "2010-oggi: Era del Deep Learning\n",
    "    └── Reti neurali profonde, transformer\n",
    "\n",
    "Futuro: Convergenza neuro-simbolica\n",
    "    └── Combinazione dei punti di forza di entrambi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d41c45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Schema Mentale\n",
    "\n",
    "## Mappa Decisionale: Orientarsi nel Panorama AI/ML\n",
    "\n",
    "```\n",
    "                    ┌─────────────────────────────┐\n",
    "                    │     HAI UN PROBLEMA DA      │\n",
    "                    │        RISOLVERE?           │\n",
    "                    └──────────────┬──────────────┘\n",
    "                                   │\n",
    "                    ┌──────────────▼──────────────┐\n",
    "                    │   LE REGOLE SONO NOTE       │\n",
    "                    │   E BEN DEFINITE?           │\n",
    "                    └──────────────┬──────────────┘\n",
    "                                   │\n",
    "              ┌────────────────────┴────────────────────┐\n",
    "              │ SÌ                                      │ NO\n",
    "              ▼                                         ▼\n",
    "    ┌─────────────────────┐               ┌─────────────────────┐\n",
    "    │   RULE-BASED SYSTEM │               │   HAI DATI STORICI  │\n",
    "    │   (Programmazione   │               │   SUFFICIENTI?      │\n",
    "    │    tradizionale)    │               └──────────┬──────────┘\n",
    "    └─────────────────────┘                          │\n",
    "                                    ┌────────────────┴────────────────┐\n",
    "                                    │ SÌ                              │ NO\n",
    "                                    ▼                                 ▼\n",
    "                        ┌─────────────────────┐         ┌─────────────────────┐\n",
    "                        │   MACHINE LEARNING  │         │   RACCOGLI DATI     │\n",
    "                        │                     │         │   O USA RULE-BASED  │\n",
    "                        └──────────┬──────────┘         └─────────────────────┘\n",
    "                                   │\n",
    "                    ┌──────────────▼──────────────┐\n",
    "                    │   I PATTERN SONO COMPLESSI  │\n",
    "                    │   (immagini, testo, audio)? │\n",
    "                    └──────────────┬──────────────┘\n",
    "                                   │\n",
    "              ┌────────────────────┴────────────────────┐\n",
    "              │ SÌ                                      │ NO\n",
    "              ▼                                         ▼\n",
    "    ┌─────────────────────┐               ┌─────────────────────┐\n",
    "    │   DEEP LEARNING     │               │   ML TRADIZIONALE   │\n",
    "    │   (Reti neurali     │               │   (Random Forest,   │\n",
    "    │    profonde)        │               │    SVM, XGBoost)    │\n",
    "    └─────────────────────┘               └─────────────────────┘\n",
    "```\n",
    "\n",
    "## Checklist: Scegliere l'Approccio\n",
    "\n",
    "| Domanda | Se SÌ → | Se NO → |\n",
    "|---------|---------|---------|\n",
    "| Le regole sono note e stabili? | Rule-based | Considera ML |\n",
    "| Hai almeno 1000+ esempi? | ML fattibile | Servono più dati |\n",
    "| Servono audit trail chiari? | Modelli interpretabili | Puoi usare black-box |\n",
    "| I dati sono strutturati (tabelle)? | ML tradizionale | Deep Learning |\n",
    "| Hai GPU disponibili? | Deep Learning possibile | Stick con ML tradizionale |\n",
    "\n",
    "## Principi Guida\n",
    "\n",
    "1. **No Free Lunch**: Non esiste l'algoritmo perfetto universale\n",
    "2. **Rasoio di Occam**: A parità di prestazioni, scegli il modello più semplice\n",
    "3. **Sperimenta**: Prova più approcci e valida empiricamente\n",
    "4. **Contesto**: La conoscenza del dominio guida le scelte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228968ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Notebook Dimostrativo\n",
    "\n",
    "## Dimostrazione: Rule-Based vs Data-Driven nella Pratica\n",
    "\n",
    "In questa sezione confrontiamo i due paradigmi su un problema concreto: classificare se un cliente è ad alto rischio di abbandono (churn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP: Importazione librerie e configurazione ambiente\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np                    # Operazioni numeriche\n",
    "import pandas as pd                   # Manipolazione dati\n",
    "from sklearn.datasets import make_classification  # Dataset sintetico\n",
    "from sklearn.model_selection import train_test_split  # Split dati\n",
    "from sklearn.tree import DecisionTreeClassifier  # Modello interpretabile\n",
    "from sklearn.ensemble import RandomForestClassifier  # Modello ensemble\n",
    "from sklearn.linear_model import LogisticRegression  # Modello lineare\n",
    "from sklearn.metrics import accuracy_score, classification_report  # Metriche\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')     # Soppressione warning per leggibilità\n",
    "\n",
    "# Seed per riproducibilità\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Librerie importate correttamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21582ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREAZIONE DATASET SIMULATO: Clienti con rischio churn\n",
    "# ============================================================\n",
    "\n",
    "# Generiamo un dataset realistico con feature interpretabili\n",
    "n_samples = 1000\n",
    "\n",
    "# Creiamo feature con significato business\n",
    "data = pd.DataFrame({\n",
    "    # Anzianità cliente (mesi)\n",
    "    'tenure_months': np.random.randint(1, 72, n_samples),\n",
    "    \n",
    "    # Numero di reclami negli ultimi 6 mesi\n",
    "    'complaints_6m': np.random.poisson(1.5, n_samples),\n",
    "    \n",
    "    # Spesa mensile media (euro)\n",
    "    'monthly_spend': np.random.normal(50, 20, n_samples).clip(10, 150),\n",
    "    \n",
    "    # Numero di prodotti attivi\n",
    "    'n_products': np.random.randint(1, 5, n_samples),\n",
    "    \n",
    "    # Giorni dall'ultimo utilizzo\n",
    "    'days_since_last_use': np.random.exponential(15, n_samples).astype(int).clip(0, 90),\n",
    "    \n",
    "    # Punteggio soddisfazione (1-10)\n",
    "    'satisfaction_score': np.random.randint(1, 11, n_samples)\n",
    "})\n",
    "\n",
    "# Creiamo la variabile target (churn) con logica realistica\n",
    "# Churn più probabile se: bassa tenure, molti reclami, bassa soddisfazione, inattivo\n",
    "churn_prob = (\n",
    "    0.3 * (data['tenure_months'] < 12).astype(int) +      # Clienti nuovi\n",
    "    0.25 * (data['complaints_6m'] >= 2).astype(int) +     # Molti reclami\n",
    "    0.25 * (data['satisfaction_score'] <= 4).astype(int) + # Insoddisfatti\n",
    "    0.2 * (data['days_since_last_use'] > 30).astype(int)   # Inattivi\n",
    ")\n",
    "\n",
    "# Aggiungiamo rumore e convertiamo in binario\n",
    "churn_prob = churn_prob + np.random.normal(0, 0.1, n_samples)\n",
    "data['churn'] = (churn_prob > 0.4).astype(int)\n",
    "\n",
    "print(f\"Dataset creato: {data.shape[0]} clienti, {data.shape[1]} colonne\")\n",
    "print(f\"\\nDistribuzione churn:\")\n",
    "print(data['churn'].value_counts(normalize=True).round(3))\n",
    "print(f\"\\nPrime 5 righe:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# APPROCCIO 1: SISTEMA RULE-BASED\n",
    "# ============================================================\n",
    "# Simuliamo un esperto di dominio che definisce regole esplicite\n",
    "# basate sulla sua esperienza nel business\n",
    "\n",
    "def rule_based_churn_predictor(row):\n",
    "    \"\"\"\n",
    "    Sistema esperto per predizione churn basato su regole di business.\n",
    "    \n",
    "    Regole definite da un esperto di dominio:\n",
    "    1. Cliente nuovo (< 12 mesi) con reclami → alto rischio\n",
    "    2. Cliente con molti reclami (≥ 3) → alto rischio  \n",
    "    3. Cliente insoddisfatto (score ≤ 3) e inattivo (> 30 gg) → alto rischio\n",
    "    4. Cliente con un solo prodotto e bassa soddisfazione → alto rischio\n",
    "    \n",
    "    Returns:\n",
    "        1 se alto rischio churn, 0 altrimenti\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regola 1: Cliente nuovo con problemi\n",
    "    if row['tenure_months'] < 12 and row['complaints_6m'] >= 1:\n",
    "        return 1\n",
    "    \n",
    "    # Regola 2: Troppi reclami (segnale forte)\n",
    "    if row['complaints_6m'] >= 3:\n",
    "        return 1\n",
    "    \n",
    "    # Regola 3: Insoddisfatto e inattivo\n",
    "    if row['satisfaction_score'] <= 3 and row['days_since_last_use'] > 30:\n",
    "        return 1\n",
    "    \n",
    "    # Regola 4: Poco engagement + bassa soddisfazione\n",
    "    if row['n_products'] == 1 and row['satisfaction_score'] <= 4:\n",
    "        return 1\n",
    "    \n",
    "    # Default: non a rischio\n",
    "    return 0\n",
    "\n",
    "# Applichiamo le regole a tutti i clienti\n",
    "data['pred_rule_based'] = data.apply(rule_based_churn_predictor, axis=1)\n",
    "\n",
    "# Valutiamo le prestazioni\n",
    "accuracy_rb = accuracy_score(data['churn'], data['pred_rule_based'])\n",
    "print(\"=\" * 60)\n",
    "print(\"SISTEMA RULE-BASED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAccuracy: {accuracy_rb:.3f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(data['churn'], data['pred_rule_based']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# APPROCCIO 2: SISTEMA DATA-DRIVEN (Machine Learning)\n",
    "# ============================================================\n",
    "# Il modello apprende le \"regole\" automaticamente dai dati\n",
    "\n",
    "# Preparazione dati\n",
    "feature_cols = ['tenure_months', 'complaints_6m', 'monthly_spend', \n",
    "                'n_products', 'days_since_last_use', 'satisfaction_score']\n",
    "X = data[feature_cols]\n",
    "y = data['churn']\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Mantiene proporzione classi\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} campioni\")\n",
    "print(f\"Test set: {X_test.shape[0]} campioni\")\n",
    "\n",
    "# Addestriamo diversi modelli (No Free Lunch: proviamo più approcci)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SISTEMI DATA-DRIVEN (Machine Learning)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Training (fase di apprendimento)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Inference (fase di predizione)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Valutazione\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecae17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFRONTO: Rule-Based vs Data-Driven\n",
    "# ============================================================\n",
    "\n",
    "# Per confronto equo, valutiamo rule-based solo sul test set\n",
    "X_test_with_pred = X_test.copy()\n",
    "X_test_with_pred['pred_rule_based'] = X_test.apply(rule_based_churn_predictor, axis=1)\n",
    "accuracy_rb_test = accuracy_score(y_test, X_test_with_pred['pred_rule_based'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFRONTO FINALE (sul test set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tabella comparativa\n",
    "comparison = pd.DataFrame({\n",
    "    'Approccio': ['Rule-Based (Esperto)', 'Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Accuracy': [accuracy_rb_test, results['Logistic Regression'], \n",
    "                 results['Decision Tree'], results['Random Forest']],\n",
    "    'Interpretabilità': ['Alta', 'Media', 'Alta', 'Media'],\n",
    "    'Richiede Dati': ['No', 'Sì', 'Sì', 'Sì'],\n",
    "    'Adattamento': ['Manuale', 'Retraining', 'Retraining', 'Retraining']\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Osservazioni\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OSSERVAZIONI\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Il sistema rule-based raggiunge accuracy ragionevole senza dati di training\n",
    "2. I modelli ML possono superare le regole manuali se i dati catturano pattern\n",
    "   che l'esperto non ha esplicitato\n",
    "3. Decision Tree offre un buon compromesso: performance ML + interpretabilità\n",
    "4. La scelta dipende dal contesto (No Free Lunch):\n",
    "   - Servono audit trail? → Rule-based o Decision Tree\n",
    "   - Hai molti dati? → Random Forest o altri ensemble\n",
    "   - Il dominio cambia spesso? → ML con retraining periodico\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIMOSTRAZIONE: IL MODELLO COME FUNZIONE f(x)\n",
    "# ============================================================\n",
    "# Visualizziamo concretamente che un modello è una funzione\n",
    "\n",
    "# Prendiamo un singolo cliente dal test set\n",
    "cliente_esempio = X_test.iloc[[0]]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"IL MODELLO COME FUNZIONE f(x)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nINPUT x (caratteristiche del cliente):\")\n",
    "print(\"-\" * 40)\n",
    "for col in feature_cols:\n",
    "    print(f\"  {col}: {cliente_esempio[col].values[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"APPLICAZIONE DI f(x) = ŷ\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Ogni modello è una funzione diversa\n",
    "for name, model in models.items():\n",
    "    # f(x) → ŷ\n",
    "    prediction = model.predict(cliente_esempio)[0]\n",
    "    probability = model.predict_proba(cliente_esempio)[0]\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  f(x) = {prediction}  (0=No churn, 1=Churn)\")\n",
    "    print(f\"  P(churn) = {probability[1]:.3f}\")\n",
    "\n",
    "# Valore reale\n",
    "print(f\"\\nValore reale y: {y_test.iloc[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NOTA: Stesso input, funzioni diverse, output potenzialmente diversi\")\n",
    "print(\"Questo illustra il No Free Lunch: ogni modello 'vede' i dati diversamente\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7495708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIMOSTRAZIONE: RASOIO DI OCCAM - COMPLESSITÀ vs PRESTAZIONI\n",
    "# ============================================================\n",
    "# Confrontiamo modelli di complessità crescente\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RASOIO DI OCCAM: COMPLESSITÀ vs PRESTAZIONI\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nDomanda: un modello più complesso è sempre migliore?\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Testiamo Decision Tree con profondità crescente\n",
    "depths = [1, 2, 3, 5, 10, 20, None]  # None = nessun limite\n",
    "results_occam = []\n",
    "\n",
    "for depth in depths:\n",
    "    # Creiamo modello con complessità controllata\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Accuracy su train e test\n",
    "    acc_train = accuracy_score(y_train, dt.predict(X_train))\n",
    "    acc_test = accuracy_score(y_test, dt.predict(X_test))\n",
    "    \n",
    "    # Numero di foglie (proxy per complessità)\n",
    "    n_leaves = dt.get_n_leaves()\n",
    "    \n",
    "    depth_str = str(depth) if depth else \"∞\"\n",
    "    results_occam.append({\n",
    "        'Max Depth': depth_str,\n",
    "        'N. Foglie': n_leaves,\n",
    "        'Acc Train': acc_train,\n",
    "        'Acc Test': acc_test,\n",
    "        'Gap': acc_train - acc_test\n",
    "    })\n",
    "\n",
    "# Mostriamo risultati\n",
    "df_occam = pd.DataFrame(results_occam)\n",
    "print(\"\\n\")\n",
    "print(df_occam.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"INTERPRETAZIONE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "• Modelli troppo semplici (depth=1,2): underfitting, basse performance\n",
    "• Modelli troppo complessi (depth=∞): overfitting, gap train-test alto\n",
    "• Modello 'giusto' (depth~5): bilancia complessità e generalizzazione\n",
    "\n",
    "→ Il Rasoio di Occam dice: scegli il modello più semplice che \n",
    "  raggiunge prestazioni accettabili sul test set.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f99d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Esercizi Svolti\n",
    "\n",
    "## Esercizio 1: Classificazione Concettuale\n",
    "\n",
    "**Problema**: Per ciascuno dei seguenti scenari, indica se l'approccio è AI, ML, o DL, e se è rule-based o data-driven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def00f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 1 - SOLUZIONE\n",
    "# Classificazione concettuale di scenari AI\n",
    "# ============================================================\n",
    "\n",
    "# Definiamo gli scenari da classificare\n",
    "scenari = [\n",
    "    {\n",
    "        'scenario': 'Un termostato che accende il riscaldamento se la temperatura scende sotto 18°C',\n",
    "        'descrizione': 'Regola fissa: IF temp < 18 THEN accendi'\n",
    "    },\n",
    "    {\n",
    "        'scenario': 'Un sistema che riconosce volti nelle foto usando milioni di immagini di training',\n",
    "        'descrizione': 'Rete neurale convoluzionale addestrata su dataset di volti'\n",
    "    },\n",
    "    {\n",
    "        'scenario': 'Un filtro spam che usa Naive Bayes addestrato su email etichettate',\n",
    "        'descrizione': 'Classificatore probabilistico addestrato su dati storici'\n",
    "    },\n",
    "    {\n",
    "        'scenario': 'Un chatbot che risponde a FAQ usando pattern matching (regex)',\n",
    "        'descrizione': 'IF input matches \"orario\" THEN risposta = \"Siamo aperti 9-18\"'\n",
    "    },\n",
    "    {\n",
    "        'scenario': 'GPT-4 che genera testo in risposta a prompt',\n",
    "        'descrizione': 'Large Language Model con miliardi di parametri'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Classifichiamo ogni scenario\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 1: CLASSIFICAZIONE CONCETTUALE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "soluzioni = []\n",
    "for i, s in enumerate(scenari, 1):\n",
    "    print(f\"\\n{'─' * 70}\")\n",
    "    print(f\"SCENARIO {i}: {s['scenario']}\")\n",
    "    print(f\"{'─' * 70}\")\n",
    "    print(f\"Descrizione: {s['descrizione']}\")\n",
    "\n",
    "# Scenario 1: Termostato\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SOLUZIONI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "classificazioni = pd.DataFrame([\n",
    "    {\n",
    "        'Scenario': 'Termostato temperatura',\n",
    "        'Categoria': 'AI (generale)',\n",
    "        'Paradigma': 'Rule-Based',\n",
    "        'Motivazione': 'Regola IF-THEN esplicita, nessun apprendimento'\n",
    "    },\n",
    "    {\n",
    "        'Scenario': 'Riconoscimento volti',\n",
    "        'Categoria': 'Deep Learning',\n",
    "        'Paradigma': 'Data-Driven',\n",
    "        'Motivazione': 'CNN addestrata su milioni di immagini, feature auto-apprese'\n",
    "    },\n",
    "    {\n",
    "        'Scenario': 'Filtro spam Naive Bayes',\n",
    "        'Categoria': 'Machine Learning',\n",
    "        'Paradigma': 'Data-Driven',\n",
    "        'Motivazione': 'Modello statistico addestrato su dati etichettati'\n",
    "    },\n",
    "    {\n",
    "        'Scenario': 'Chatbot regex FAQ',\n",
    "        'Categoria': 'AI (generale)',\n",
    "        'Paradigma': 'Rule-Based',\n",
    "        'Motivazione': 'Pattern matching esplicito, nessun apprendimento da dati'\n",
    "    },\n",
    "    {\n",
    "        'Scenario': 'GPT-4 text generation',\n",
    "        'Categoria': 'Deep Learning',\n",
    "        'Paradigma': 'Data-Driven',\n",
    "        'Motivazione': 'Transformer con miliardi di parametri, pre-training su testi'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\")\n",
    "for _, row in classificazioni.iterrows():\n",
    "    print(f\"\\n{row['Scenario']}:\")\n",
    "    print(f\"  Categoria: {row['Categoria']}\")\n",
    "    print(f\"  Paradigma: {row['Paradigma']}\")\n",
    "    print(f\"  Motivazione: {row['Motivazione']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667b997",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 2: Implementazione Rule-Based\n",
    "\n",
    "**Problema**: Crea un sistema rule-based per decidere se approvare una richiesta di ferie in un'azienda.\n",
    "\n",
    "Regole aziendali:\n",
    "1. Non si possono approvare ferie in agosto se il dipendente ha meno di 2 anni di anzianità\n",
    "2. Non si possono approvare più di 15 giorni consecutivi\n",
    "3. Deve rimanere almeno il 50% del team in ufficio\n",
    "4. Le ferie devono essere richieste con almeno 14 giorni di anticipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 2 - SOLUZIONE\n",
    "# Sistema rule-based per approvazione ferie\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def approva_ferie(richiesta: dict, stato_team: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Sistema esperto per approvazione richieste ferie.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    richiesta : dict\n",
    "        Contiene: dipendente, data_inizio, data_fine, data_richiesta, \n",
    "                  anni_anzianita\n",
    "    stato_team : dict\n",
    "        Contiene: totale_membri, membri_in_ferie (nel periodo richiesto)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict con 'approvato' (bool) e 'motivo' (str)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estrazione dati dalla richiesta\n",
    "    data_inizio = richiesta['data_inizio']\n",
    "    data_fine = richiesta['data_fine']\n",
    "    data_richiesta = richiesta['data_richiesta']\n",
    "    anni_anzianita = richiesta['anni_anzianita']\n",
    "    \n",
    "    # Calcolo giorni di ferie richiesti\n",
    "    giorni_richiesti = (data_fine - data_inizio).days + 1\n",
    "    \n",
    "    # Calcolo anticipo richiesta\n",
    "    giorni_anticipo = (data_inizio - data_richiesta).days\n",
    "    \n",
    "    # Calcolo percentuale team presente\n",
    "    membri_in_ferie_dopo = stato_team['membri_in_ferie'] + 1\n",
    "    percentuale_presente = 1 - (membri_in_ferie_dopo / stato_team['totale_membri'])\n",
    "    \n",
    "    # ── REGOLA 1: Agosto richiede 2+ anni anzianità ──\n",
    "    if data_inizio.month == 8 and anni_anzianita < 2:\n",
    "        return {\n",
    "            'approvato': False,\n",
    "            'motivo': 'Ferie in agosto richiedono almeno 2 anni di anzianità'\n",
    "        }\n",
    "    \n",
    "    # ── REGOLA 2: Massimo 15 giorni consecutivi ──\n",
    "    if giorni_richiesti > 15:\n",
    "        return {\n",
    "            'approvato': False,\n",
    "            'motivo': f'Richiesti {giorni_richiesti} giorni, massimo consentito: 15'\n",
    "        }\n",
    "    \n",
    "    # ── REGOLA 3: Almeno 50% team presente ──\n",
    "    if percentuale_presente < 0.5:\n",
    "        return {\n",
    "            'approvato': False,\n",
    "            'motivo': f'Team sotto 50%: {percentuale_presente:.0%} presenti'\n",
    "        }\n",
    "    \n",
    "    # ── REGOLA 4: Almeno 14 giorni di anticipo ──\n",
    "    if giorni_anticipo < 14:\n",
    "        return {\n",
    "            'approvato': False,\n",
    "            'motivo': f'Anticipo insufficiente: {giorni_anticipo} giorni (minimo 14)'\n",
    "        }\n",
    "    \n",
    "    # ── TUTTE LE REGOLE SODDISFATTE ──\n",
    "    return {\n",
    "        'approvato': True,\n",
    "        'motivo': 'Richiesta conforme a tutte le policy aziendali'\n",
    "    }\n",
    "\n",
    "# ── TEST DEL SISTEMA ──\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 2: SISTEMA RULE-BASED APPROVAZIONE FERIE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Casi di test\n",
    "casi_test = [\n",
    "    {\n",
    "        'nome': 'Mario Rossi - Ferie agosto, 1 anno anzianità',\n",
    "        'richiesta': {\n",
    "            'dipendente': 'Mario Rossi',\n",
    "            'data_inizio': datetime(2024, 8, 1),\n",
    "            'data_fine': datetime(2024, 8, 10),\n",
    "            'data_richiesta': datetime(2024, 7, 1),\n",
    "            'anni_anzianita': 1\n",
    "        },\n",
    "        'stato_team': {'totale_membri': 10, 'membri_in_ferie': 3}\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Anna Bianchi - 20 giorni consecutivi',\n",
    "        'richiesta': {\n",
    "            'dipendente': 'Anna Bianchi',\n",
    "            'data_inizio': datetime(2024, 6, 1),\n",
    "            'data_fine': datetime(2024, 6, 20),\n",
    "            'data_richiesta': datetime(2024, 5, 1),\n",
    "            'anni_anzianita': 5\n",
    "        },\n",
    "        'stato_team': {'totale_membri': 10, 'membri_in_ferie': 2}\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Luca Verdi - Richiesta valida',\n",
    "        'richiesta': {\n",
    "            'dipendente': 'Luca Verdi',\n",
    "            'data_inizio': datetime(2024, 7, 15),\n",
    "            'data_fine': datetime(2024, 7, 25),\n",
    "            'data_richiesta': datetime(2024, 6, 20),\n",
    "            'anni_anzianita': 3\n",
    "        },\n",
    "        'stato_team': {'totale_membri': 10, 'membri_in_ferie': 2}\n",
    "    },\n",
    "    {\n",
    "        'nome': 'Sara Neri - Troppo poco anticipo',\n",
    "        'richiesta': {\n",
    "            'dipendente': 'Sara Neri',\n",
    "            'data_inizio': datetime(2024, 9, 1),\n",
    "            'data_fine': datetime(2024, 9, 5),\n",
    "            'data_richiesta': datetime(2024, 8, 25),\n",
    "            'anni_anzianita': 4\n",
    "        },\n",
    "        'stato_team': {'totale_membri': 10, 'membri_in_ferie': 1}\n",
    "    }\n",
    "]\n",
    "\n",
    "for caso in casi_test:\n",
    "    risultato = approva_ferie(caso['richiesta'], caso['stato_team'])\n",
    "    print(f\"\\n{'─' * 70}\")\n",
    "    print(f\"CASO: {caso['nome']}\")\n",
    "    print(f\"{'─' * 70}\")\n",
    "    status = \"✓ APPROVATO\" if risultato['approvato'] else \"✗ RIFIUTATO\"\n",
    "    print(f\"Esito: {status}\")\n",
    "    print(f\"Motivo: {risultato['motivo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015c3d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 3: No Free Lunch in Pratica\n",
    "\n",
    "**Problema**: Dimostra empiricamente il teorema No Free Lunch confrontando le prestazioni di diversi algoritmi su dataset con caratteristiche diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 3 - SOLUZIONE\n",
    "# Dimostrazione empirica del No Free Lunch\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 3: NO FREE LUNCH - DIMOSTRAZIONE EMPIRICA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ── STEP 1: Creiamo dataset con caratteristiche diverse ──\n",
    "print(\"\\n1. CREAZIONE DATASET CON STRUTTURE DIVERSE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "datasets = {\n",
    "    'Lineare': make_classification(\n",
    "        n_samples=500, n_features=2, n_informative=2, \n",
    "        n_redundant=0, n_clusters_per_class=1, \n",
    "        class_sep=2.0, random_state=42\n",
    "    ),\n",
    "    'Cerchi concentrici': make_circles(\n",
    "        n_samples=500, noise=0.1, factor=0.5, random_state=42\n",
    "    ),\n",
    "    'Mezzelune': make_moons(\n",
    "        n_samples=500, noise=0.1, random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, (X, y) in datasets.items():\n",
    "    print(f\"  {name}: {X.shape[0]} campioni, classe 0: {(y==0).sum()}, classe 1: {(y==1).sum()}\")\n",
    "\n",
    "# ── STEP 2: Definiamo algoritmi da confrontare ──\n",
    "print(\"\\n2. ALGORITMI DA CONFRONTARE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "algorithms = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree (d=5)': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'SVM (RBF kernel)': SVC(kernel='rbf', random_state=42),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for name in algorithms:\n",
    "    print(f\"  • {name}\")\n",
    "\n",
    "# ── STEP 3: Confronto prestazioni ──\n",
    "print(\"\\n3. RISULTATI (Accuracy sul test set)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "results_nfl = []\n",
    "\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    row = {'Dataset': dataset_name}\n",
    "    \n",
    "    for algo_name, algo in algorithms.items():\n",
    "        # Clone per evitare stato condiviso\n",
    "        from sklearn.base import clone\n",
    "        model = clone(algo)\n",
    "        \n",
    "        # Fit e predict\n",
    "        model.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        row[algo_name] = f\"{acc:.3f}\"\n",
    "    \n",
    "    results_nfl.append(row)\n",
    "\n",
    "# Visualizziamo tabella risultati\n",
    "df_nfl = pd.DataFrame(results_nfl)\n",
    "print(\"\\n\")\n",
    "print(df_nfl.to_string(index=False))\n",
    "\n",
    "# ── STEP 4: Analisi ──\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"4. ANALISI DEI RISULTATI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "OSSERVAZIONI:\n",
    "\n",
    "• Dataset LINEARE:\n",
    "  → Logistic Regression eccelle (modello lineare su dati lineari)\n",
    "  → Modelli non-lineari (SVM RBF, Decision Tree) funzionano ma sono overkill\n",
    "\n",
    "• Dataset CERCHI CONCENTRICI:\n",
    "  → Logistic Regression fallisce (boundary non lineare)\n",
    "  → SVM con kernel RBF eccelle (trasforma lo spazio)\n",
    "  → KNN funziona bene (decision boundary locale)\n",
    "\n",
    "• Dataset MEZZELUNE:\n",
    "  → Logistic Regression fallisce (boundary non lineare)\n",
    "  → SVM RBF e KNN eccellono\n",
    "  → Decision Tree ragionevole ma con artefatti\n",
    "\n",
    "CONCLUSIONE NO FREE LUNCH:\n",
    "─────────────────────────\n",
    "Nessun algoritmo è il migliore su tutti i dataset.\n",
    "La struttura dei dati determina quale algoritmo performa meglio.\n",
    "L'unico modo per sapere quale usare è sperimentare.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947d7c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Conclusione Operativa\n",
    "\n",
    "## Cosa Abbiamo Imparato\n",
    "\n",
    "| Concetto | Implicazione Pratica |\n",
    "|----------|---------------------|\n",
    "| **AI ⊃ ML ⊃ DL** | Scegli il livello di complessità appropriato al problema |\n",
    "| **Modello = f(x)** | Ogni modello è una funzione che trasforma input in output |\n",
    "| **Training vs Inference** | Due fasi distinte con requisiti diversi |\n",
    "| **No Free Lunch** | Non esiste l'algoritmo universalmente migliore: sperimenta |\n",
    "| **Rasoio di Occam** | A parità di prestazioni, preferisci il modello più semplice |\n",
    "| **Rule-Based vs Data-Driven** | Scegli in base a: dati disponibili, interpretabilità, stabilità regole |\n",
    "\n",
    "## Quando Usare Cosa\n",
    "\n",
    "| Situazione | Approccio Consigliato |\n",
    "|------------|----------------------|\n",
    "| Regole di business note e stabili | Sistema rule-based |\n",
    "| Molti dati, pattern ignoti | Machine Learning |\n",
    "| Dati non strutturati (immagini, testo) | Deep Learning |\n",
    "| Requisiti di trasparenza/audit | Modelli interpretabili |\n",
    "| Risorse computazionali limitate | ML tradizionale |\n",
    "\n",
    "## Errori Comuni da Evitare\n",
    "\n",
    "1. ❌ Usare sempre lo stesso algoritmo senza sperimentare\n",
    "2. ❌ Scegliere modelli complessi quando uno semplice basta\n",
    "3. ❌ Confondere training con inference\n",
    "4. ❌ Ignorare le regole di business in favore del ML\n",
    "5. ❌ Non validare su dati mai visti\n",
    "\n",
    "## Prossimi Passi\n",
    "\n",
    "Questa lezione ha posto le basi concettuali. Nelle prossime lezioni:\n",
    "- **Lezione 30**: Come rappresentare il testo come dato numerico\n",
    "- **Lezione 31**: TF-IDF e tecniche di text mining\n",
    "- **Lezione 32**: Sentiment Analysis pratico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d48e89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Bignami — Scheda di Riferimento Rapido\n",
    "\n",
    "## Definizioni Chiave\n",
    "\n",
    "| Termine | Definizione |\n",
    "|---------|-------------|\n",
    "| **AI** | Campo che studia la creazione di agenti che esibiscono comportamento intelligente |\n",
    "| **ML** | Sottocampo AI: sistemi che apprendono dai dati senza programmazione esplicita |\n",
    "| **DL** | Sottocampo ML: reti neurali con molti layer per rappresentazione gerarchica |\n",
    "| **Training** | Fase in cui il modello apprende dai dati |\n",
    "| **Inference** | Fase in cui il modello applica ciò che ha appreso a nuovi dati |\n",
    "| **Rule-Based** | Sistema con regole esplicite codificate da esperti |\n",
    "| **Data-Driven** | Sistema che estrae regole implicite dai dati |\n",
    "\n",
    "## Formule e Principi\n",
    "\n",
    "**Modello come funzione:**\n",
    "$$\\hat{y} = f(x)$$\n",
    "\n",
    "**Obiettivo ML (minimizzazione loss):**\n",
    "$$f^* = \\arg\\min_f \\sum_{i=1}^{n} L(f(x_i), y_i)$$\n",
    "\n",
    "**No Free Lunch**: Non esiste algoritmo universalmente ottimo\n",
    "\n",
    "**Rasoio di Occam**: Preferisci modelli semplici a parità di prestazioni\n",
    "\n",
    "## Checklist Decisionale\n",
    "\n",
    "```\n",
    "□ Le regole sono note?\n",
    "  → SÌ: Rule-Based | NO: considera ML\n",
    "\n",
    "□ Hai dati sufficienti (1000+)?\n",
    "  → SÌ: ML fattibile | NO: raccogli dati o usa rule-based\n",
    "\n",
    "□ Dati strutturati (tabelle)?\n",
    "  → SÌ: ML tradizionale | NO: Deep Learning\n",
    "\n",
    "□ Servono audit trail?\n",
    "  → SÌ: Modelli interpretabili | NO: qualsiasi approccio\n",
    "```\n",
    "\n",
    "## Codice Essenziale\n",
    "\n",
    "```python\n",
    "# Training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Inference  \n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Valutazione\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "```\n",
    "\n",
    "---\n",
    "*Fine Lezione 29 — Fondamenti di Artificial Intelligence*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
