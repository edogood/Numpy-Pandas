{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f49d32",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "\n",
    "Lezione 34: Document Intelligence - Estrarre informazioni strutturate da documenti\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa della lezione\n",
    "\n",
    "| Sezione | Contenuto | Tempo stimato |\n",
    "|---------|-----------|---------------|\n",
    "| 1 | Titolo, obiettivi, cos'Ã¨ Document Intelligence | 5 min |\n",
    "| 2 | Teoria: pipeline di estrazione, approcci | 15 min |\n",
    "| 3 | Schema mentale: workflow estrazione | 5 min |\n",
    "| 4 | Demo: regex, normalizzazione, DataFrame output | 30 min |\n",
    "| 5 | Esercizi guidati | 15 min |\n",
    "| 6 | Conclusione operativa | 10 min |\n",
    "| 7 | Checklist di fine lezione + glossario | 5 min |\n",
    "| 8 | Changelog didattico | 2 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "| # | Obiettivo | Verifica |\n",
    "|---|-----------|----------|\n",
    "| 1 | Definire una **pipeline di estrazione** documenti | Sai identificare i campi da estrarre? |\n",
    "| 2 | Usare **regex** per campi strutturati | Sai estrarre email, date, importi? |\n",
    "| 3 | **Normalizzare** i valori estratti | Sai convertire date in ISO, importi in float? |\n",
    "| 4 | **Combinare** regex e NER | Sai quando usare quale? |\n",
    "| 5 | **Strutturare output** in DataFrame | Sai organizzare le estrazioni? |\n",
    "\n",
    "---\n",
    "\n",
    "## L'idea centrale: cos'Ã¨ Document Intelligence\n",
    "\n",
    "```\n",
    "INPUT (documento):                           OUTPUT (dati strutturati):\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ FATTURA N. 123                 â”‚           â”‚ campo       â”‚ valore         â”‚\n",
    "â”‚ Data: 15/02/2024               â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Cliente: Mario Rossi           â”‚    â†’      â”‚ num_fattura â”‚ 123            â”‚\n",
    "â”‚ Email: mario@example.com       â”‚           â”‚ data        â”‚ 2024-02-15     â”‚\n",
    "â”‚ Importo: EUR 1.250,50          â”‚           â”‚ cliente     â”‚ Mario Rossi    â”‚\n",
    "â”‚ Scadenza: 30/03/2024           â”‚           â”‚ email       â”‚ mario@...      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ importo     â”‚ 1250.50        â”‚\n",
    "                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        Testo semi-strutturato          â†’           Tabella strutturata\n",
    "```\n",
    "\n",
    "**Document Intelligence = trasformare testo in dati azionabili.**\n",
    "\n",
    "---\n",
    "\n",
    "## Tipi di documenti e approcci\n",
    "\n",
    "| Tipo documento | ComplessitÃ  | Approccio consigliato |\n",
    "|----------------|-------------|----------------------|\n",
    "| **Fatture** | Medio | Regex + normalizzazione |\n",
    "| **Email** | Basso | Header parsing + regex |\n",
    "| **Contratti** | Alto | NER + regex + ML |\n",
    "| **Form OCR** | Alto | Layout analysis + regex |\n",
    "| **Log files** | Basso | Regex con pattern fissi |\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Document Intelligence\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Documento   â”‚ â†’  â”‚   Pulizia    â”‚ â†’  â”‚  Estrazione  â”‚ â†’  â”‚Normalizzazioneâ”‚\n",
    "â”‚  (PDF/text)  â”‚    â”‚  encoding    â”‚    â”‚  regex/NER   â”‚    â”‚  date, float â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                                    â”‚\n",
    "                                                                    â–¼\n",
    "                                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                                           â”‚  Validazione â”‚\n",
    "                                                           â”‚  formato     â”‚\n",
    "                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                                    â”‚\n",
    "                                                                    â–¼\n",
    "                                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                                           â”‚  DataFrame   â”‚\n",
    "                                                           â”‚  output      â”‚\n",
    "                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Pattern regex comuni per documenti\n",
    "\n",
    "| Campo | Pattern | Esempio match |\n",
    "|-------|---------|---------------|\n",
    "| **Email** | `[\\w.+-]+@[\\w-]+\\.[\\w.-]+` | mario.rossi@example.com |\n",
    "| **Data IT** | `\\d{1,2}/\\d{1,2}/\\d{2,4}` | 15/02/2024 |\n",
    "| **Importo EUR** | `EUR?\\s*[\\d.,]+` | EUR 1.250,50 |\n",
    "| **Codice Fiscale** | `[A-Z]{6}\\d{2}[A-Z]\\d{2}[A-Z]\\d{3}[A-Z]` | RSSMRA80A01H501A |\n",
    "| **Telefono IT** | `(?:\\+39\\s?)?\\d{2,4}[\\s.-]?\\d{6,7}` | +39 02 1234567 |\n",
    "| **IBAN** | `IT\\d{2}[A-Z]\\d{22}` | IT60X0542811101000000123456 |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "| Concetto | Dove lo trovi | Verifica |\n",
    "|----------|---------------|----------|\n",
    "| Regex | Lezioni 30, 33 | Sai usare re.findall? |\n",
    "| NER | Lezione 33 | Sai estrarre entitÃ  con spaCy? |\n",
    "| Pandas | Lezioni 1-3 | Sai creare DataFrame? |\n",
    "\n",
    "**Cosa useremo:** re module, pandas DataFrame, opzionalmente spaCy NER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973573e9",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- Document intelligence combina NER, regex e parsing per estrarre campi chiave.\n",
    "- Input: PDF/OCR trasformato in testo, email, log; Output: tabelle con entita' o campi (nome, data, importi).\n",
    "- Sfide: formati variabili, rumorosi; soluzione: pattern progressivi (regex), fallback manuali, validazioni.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6baeb",
   "metadata": {},
   "source": [
    "## Scelte di estrazione\n",
    "- Regex per campi strutturati (email, date, importi). Pro: semplice; Contro: fragile su formati nuovi.\n",
    "- NER per entita' generiche (PER/ORG/LOC). Pro: copertura; Contro: richiede modelli e lingua corretta.\n",
    "- Post-processing: normalizzare campi (date ISO, importi float) e deduplicare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4796cf7",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Identifica i campi da estrarre (nome, email, importo, data, indirizzo).\n",
    "2. Scegli pattern regex e/o NER adeguati.\n",
    "3. Applica estrazione al testo pulito.\n",
    "4. Normalizza i valori (formati data/importi) e valida (es. pattern email).\n",
    "5. Struttura l'output in un DataFrame.\n",
    "6. Spot-check manuali su campioni se non hai label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32f68e",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "- Demo 1: estrazione di email, date e importi da un testo.\n",
    "- Demo 2: normalizzazione e costruzione di un DataFrame.\n",
    "- Demo 3: combinazione con (opzionale) NER se disponibile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: estrazione con regex da testo misto\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "text = \"\"\"\n",
    "Fattura n. 123 del 15/02/2024\n",
    "Cliente: Mario Rossi\n",
    "Email: mario.rossi@example.com\n",
    "Importo: EUR 1.250,50\n",
    "Pagamento previsto entro 30/03/2024\n",
    "\"\"\"\n",
    "\n",
    "emails = re.findall(r\"[\\w\\.]+@[\\w\\.]+\", text)\n",
    "dates = re.findall(r\"\b\\d{1,2}/\\d{1,2}/\\d{4}\b\", text)\n",
    "amounts = re.findall(r\"\b\\d{1,3}(?:\\.\\d{3})*,\\d{2}\b\", text)\n",
    "print(\"Email:\", emails)\n",
    "print(\"Date:\", dates)\n",
    "print(\"Importi:\", amounts)\n",
    "assert len(emails) > 0 and len(dates) > 0 and len(amounts) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71829ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: normalizzazione e tabella\n",
    "from datetime import datetime\n",
    "\n",
    "# Normalizza importi in float con punto decimale\n",
    "amounts_float = [float(a.replace('.', '').replace(',', '.')) for a in amounts]\n",
    "# Normalizza date in formato ISO\n",
    "norm_dates = [datetime.strptime(d, \"%d/%m/%Y\").date().isoformat() for d in dates]\n",
    "\n",
    "rows = []\n",
    "for email in emails:\n",
    "    rows.append({\n",
    "        'email': email,\n",
    "        'importo': amounts_float[0] if amounts_float else None,\n",
    "        'data_fattura': norm_dates[0] if norm_dates else None,\n",
    "        'data_pagamento': norm_dates[1] if len(norm_dates) > 1 else None\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "assert not df.empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: (opzionale) uso NER se spaCy disponibile\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    ents = [(ent.label_, ent.text) for ent in doc.ents]\n",
    "    print(\"Entita' NER:\", ents)\n",
    "except Exception as e:\n",
    "    print(\"spaCy non disponibile o modello non installato, salto NER.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 4: Key-Value Extraction per Fatture\n",
    "# ============================================================\n",
    "# Estraiamo campi specifici dalle fatture\n",
    "\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class InvoiceData:\n",
    "    \"\"\"Struttura dati per fattura estratta.\"\"\"\n",
    "    numero: Optional[str] = None\n",
    "    data: Optional[str] = None\n",
    "    cliente: Optional[str] = None\n",
    "    totale: Optional[str] = None\n",
    "    iva: Optional[str] = None\n",
    "    confidence: float = 0.0\n",
    "\n",
    "class InvoiceExtractor:\n",
    "    \"\"\"\n",
    "    Estrattore di dati da testo fattura.\n",
    "    Usa regex per campi strutturati.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Pattern per ogni campo\n",
    "        self.patterns = {\n",
    "            'numero': [\n",
    "                r'(?:fattura|invoice|n\\.?|numero|#)\\s*[:.]?\\s*([A-Z0-9\\-/]+)',\n",
    "                r'(?:n\\.?|numero)\\s*(?:fattura)?\\s*[:.]?\\s*([A-Z0-9\\-/]+)',\n",
    "            ],\n",
    "            'data': [\n",
    "                r'(?:data|date|del)\\s*[:.]?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})',\n",
    "                r'(\\d{4}-\\d{2}-\\d{2})',  # ISO format\n",
    "            ],\n",
    "            'totale': [\n",
    "                r'(?:totale|total|amount|importo)\\s*[:.]?\\s*(â‚¬?\\s*[\\d.,]+(?:\\s*(?:â‚¬|euro))?)',\n",
    "                r'(â‚¬\\s*[\\d.,]+)',\n",
    "            ],\n",
    "            'cliente': [\n",
    "                r'(?:cliente|customer|spett\\.?le|to)\\s*[:.]?\\s*([A-Za-zÃ€-Ã¿\\s&\\.]+(?:s\\.?r\\.?l\\.?|s\\.?p\\.?a\\.?)?)',\n",
    "            ],\n",
    "            'iva': [\n",
    "                r'(?:iva|vat)\\s*[:.]?\\s*([\\d.,]+%?|inclusa|esclusa)',\n",
    "            ],\n",
    "        }\n",
    "    \n",
    "    def extract(self, testo: str) -> InvoiceData:\n",
    "        \"\"\"Estrae dati strutturati da testo fattura.\"\"\"\n",
    "        result = InvoiceData()\n",
    "        campi_trovati = 0\n",
    "        campi_totali = len(self.patterns)\n",
    "        \n",
    "        for campo, patterns in self.patterns.items():\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, testo, re.IGNORECASE)\n",
    "                if match:\n",
    "                    valore = match.group(1).strip()\n",
    "                    setattr(result, campo, valore)\n",
    "                    campi_trovati += 1\n",
    "                    break  # Usa primo match\n",
    "        \n",
    "        # Confidence basata su quanti campi trovati\n",
    "        result.confidence = campi_trovati / campi_totali\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validate(self, data: InvoiceData) -> Dict:\n",
    "        \"\"\"Valida i dati estratti.\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if not data.numero:\n",
    "            issues.append(\"Numero fattura mancante\")\n",
    "        if not data.data:\n",
    "            issues.append(\"Data fattura mancante\")\n",
    "        if not data.totale:\n",
    "            issues.append(\"Totale mancante\")\n",
    "        if data.confidence < 0.6:\n",
    "            issues.append(f\"Bassa confidence: {data.confidence:.0%}\")\n",
    "        \n",
    "        return {\n",
    "            'valid': len(issues) == 0,\n",
    "            'issues': issues,\n",
    "            'requires_review': data.confidence < 0.8\n",
    "        }\n",
    "\n",
    "# Test\n",
    "extractor = InvoiceExtractor()\n",
    "\n",
    "fatture_test = [\n",
    "    \"FATTURA N. 2024/001 Data: 15/01/2024 Cliente: Rossi S.r.l. Totale: â‚¬1.250,00 IVA inclusa\",\n",
    "    \"Invoice #456 Date: 2024-03-10 To: Verdi & Co. Amount: â‚¬750.00 VAT included\",\n",
    "    \"Fattura numero F-789 Spett.le Bianchi SpA Importo â‚¬3.500\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 4: EXTRACTION DA FATTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, fattura in enumerate(fatture_test, 1):\n",
    "    print(f\"\\nðŸ“„ Fattura {i}:\")\n",
    "    print(f\"   Testo: '{fattura[:60]}...'\")\n",
    "    \n",
    "    # Estrazione\n",
    "    data = extractor.extract(fattura)\n",
    "    \n",
    "    print(f\"\\n   Campi estratti:\")\n",
    "    print(f\"      Numero:  {data.numero or 'N/A'}\")\n",
    "    print(f\"      Data:    {data.data or 'N/A'}\")\n",
    "    print(f\"      Cliente: {data.cliente or 'N/A'}\")\n",
    "    print(f\"      Totale:  {data.totale or 'N/A'}\")\n",
    "    print(f\"      IVA:     {data.iva or 'N/A'}\")\n",
    "    print(f\"      Confidence: {data.confidence:.0%}\")\n",
    "    \n",
    "    # Validazione\n",
    "    validation = extractor.validate(data)\n",
    "    status = \"âœ… VALIDO\" if validation['valid'] else \"âš ï¸ PROBLEMI\"\n",
    "    print(f\"\\n   Validazione: {status}\")\n",
    "    for issue in validation['issues']:\n",
    "        print(f\"      - {issue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2497709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 5: Pipeline Integrata Document Intelligence\n",
    "# ============================================================\n",
    "# Combiniamo Classification + Extraction in un'unica pipeline\n",
    "\n",
    "class DocumentIntelligencePipeline:\n",
    "    \"\"\"\n",
    "    Pipeline completa per Document Intelligence:\n",
    "    1. Classifica il documento\n",
    "    2. Applica extractor specifico per tipo\n",
    "    3. Valida e restituisce risultato strutturato\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorizer, classifier):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        # Extractors per tipo\n",
    "        self.extractors = {\n",
    "            'fattura': InvoiceExtractor(),\n",
    "            'contratto': ContractExtractor(),\n",
    "            'lettera': LetterExtractor(),\n",
    "            'report': ReportExtractor(),\n",
    "        }\n",
    "    \n",
    "    def process(self, documento: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Processa un documento end-to-end.\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                'tipo': str,\n",
    "                'confidence_classificazione': float,\n",
    "                'dati_estratti': dict,\n",
    "                'validation': dict\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Step 1: Classification\n",
    "        X = self.vectorizer.transform([documento])\n",
    "        \n",
    "        # Predizione con probabilitÃ \n",
    "        tipo_predetto = self.classifier.predict(X)[0]\n",
    "        probabilita = self.classifier.predict_proba(X)[0]\n",
    "        confidence_class = max(probabilita)\n",
    "        \n",
    "        # Step 2: Extraction\n",
    "        if tipo_predetto in self.extractors:\n",
    "            extractor = self.extractors[tipo_predetto]\n",
    "            dati = extractor.extract(documento)\n",
    "            validation = extractor.validate(dati)\n",
    "        else:\n",
    "            dati = {}\n",
    "            validation = {'valid': False, 'issues': ['Tipo non supportato']}\n",
    "        \n",
    "        # Step 3: Risultato\n",
    "        return {\n",
    "            'tipo': tipo_predetto,\n",
    "            'confidence_classificazione': confidence_class,\n",
    "            'dati_estratti': dati if hasattr(dati, '__dict__') else vars(dati) if hasattr(dati, '__dict__') else dati,\n",
    "            'validation': validation,\n",
    "            'richiede_review': confidence_class < 0.8 or not validation['valid']\n",
    "        }\n",
    "\n",
    "# Extractors semplificati per altri tipi\n",
    "class ContractExtractor:\n",
    "    def extract(self, testo):\n",
    "        @dataclass\n",
    "        class ContractData:\n",
    "            parti: Optional[str] = None\n",
    "            durata: Optional[str] = None\n",
    "            valore: Optional[str] = None\n",
    "            confidence: float = 0.0\n",
    "        \n",
    "        result = ContractData()\n",
    "        \n",
    "        # Pattern semplici\n",
    "        parti = re.search(r'tra\\s+(.+?)\\s+e\\s+(.+?)(?:\\s+durata|\\s+decorrenza|$)', testo, re.I)\n",
    "        if parti:\n",
    "            result.parti = f\"{parti.group(1)} / {parti.group(2)}\"\n",
    "        \n",
    "        durata = re.search(r'(\\d+)\\s*(?:mesi|anni|months|years)', testo, re.I)\n",
    "        if durata:\n",
    "            result.durata = durata.group(0)\n",
    "        \n",
    "        valore = re.search(r'â‚¬\\s*[\\d.,]+', testo)\n",
    "        if valore:\n",
    "            result.valore = valore.group(0)\n",
    "        \n",
    "        result.confidence = sum([1 for x in [result.parti, result.durata, result.valore] if x]) / 3\n",
    "        return result\n",
    "    \n",
    "    def validate(self, data):\n",
    "        return {'valid': data.confidence > 0.3, 'issues': []}\n",
    "\n",
    "class LetterExtractor:\n",
    "    def extract(self, testo):\n",
    "        @dataclass\n",
    "        class LetterData:\n",
    "            destinatario: Optional[str] = None\n",
    "            tipo_saluto: Optional[str] = None\n",
    "            confidence: float = 0.5\n",
    "        \n",
    "        result = LetterData()\n",
    "        \n",
    "        saluto = re.search(r'(gentile|egregio|spett\\.?le|dear)\\s+([^,]+)', testo, re.I)\n",
    "        if saluto:\n",
    "            result.destinatario = saluto.group(2)\n",
    "            result.tipo_saluto = saluto.group(1)\n",
    "            result.confidence = 0.8\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validate(self, data):\n",
    "        return {'valid': True, 'issues': []}\n",
    "\n",
    "class ReportExtractor:\n",
    "    def extract(self, testo):\n",
    "        @dataclass\n",
    "        class ReportData:\n",
    "            tipo_report: Optional[str] = None\n",
    "            metriche: List = None\n",
    "            confidence: float = 0.5\n",
    "        \n",
    "        result = ReportData()\n",
    "        result.metriche = []\n",
    "        \n",
    "        # Tipo report\n",
    "        tipo = re.search(r'(trimestrale|settimanale|annual|quarterly|weekly|mensile)', testo, re.I)\n",
    "        if tipo:\n",
    "            result.tipo_report = tipo.group(1)\n",
    "        \n",
    "        # Metriche numeriche\n",
    "        metriche = re.findall(r'(\\w+)\\s*[:=]\\s*([\\d.,]+[%â‚¬]?|â‚¬[\\d.,]+)', testo)\n",
    "        result.metriche = metriche[:5]  # Max 5\n",
    "        \n",
    "        result.confidence = 0.6 if result.tipo_report else 0.4\n",
    "        return result\n",
    "    \n",
    "    def validate(self, data):\n",
    "        return {'valid': True, 'issues': []}\n",
    "\n",
    "# Test pipeline\n",
    "pipeline = DocumentIntelligencePipeline(vectorizer, classifier)\n",
    "\n",
    "test_docs = [\n",
    "    \"FATTURA N. 2024/999 Data: 01/04/2024 Cliente: Test Srl Totale: â‚¬2.000,00\",\n",
    "    \"CONTRATTO tra Alfa SpA e Beta Srl durata 24 mesi valore â‚¬100.000\",\n",
    "    \"Gentile Dott. Rossi, Le scrivo per confermare l'appuntamento. Cordiali saluti\",\n",
    "    \"Report Q1 2024 Fatturato: â‚¬1.5M Crescita: +20% Margine: 15%\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 5: PIPELINE INTEGRATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for doc in test_docs:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“„ Input: '{doc[:50]}...'\")\n",
    "    \n",
    "    result = pipeline.process(doc)\n",
    "    \n",
    "    print(f\"\\n   ðŸ“‹ RISULTATO:\")\n",
    "    print(f\"      Tipo: {result['tipo'].upper()}\")\n",
    "    print(f\"      Confidence: {result['confidence_classificazione']:.1%}\")\n",
    "    print(f\"      Review richiesta: {'SÃ¬' if result['richiede_review'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ce2c3",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 34.1 - Estrazione ordini\n",
    "Obiettivo: estrarre ID ordine, data e importo da un blocco di testo strutturato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 34.1\n",
    "ordine_text = \"Ordine ID: ORD-2024-001 Data: 12/03/2024 Totale: EUR 250,00\"\n",
    "order_id = re.findall(r\"ORD-\\d{4}-\\d{3}\", ordine_text)\n",
    "order_date = re.findall(r\"\b\\d{2}/\\d{2}/\\d{4}\b\", ordine_text)\n",
    "order_amount = re.findall(r\"\\d+,\\d{2}\", ordine_text)\n",
    "print(order_id, order_date, order_amount)\n",
    "assert order_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2967bf4",
   "metadata": {},
   "source": [
    "## Esercizio 34.2 - Validazione campi estratti\n",
    "Obiettivo: creare una funzione che valida email e importi e segnala quelli non conformi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 34.2\n",
    "email_pattern = re.compile(r\"^[\\w\\.]+@[\\w\\.]+$\")\n",
    "amount_pattern = re.compile(r\"^\\d+[\\.,]\\d{2}$\")\n",
    "\n",
    "def valida_campi(row):\n",
    "    return email_pattern.match(row['email']) is not None and amount_pattern.match(str(row['importo']).replace('.', ',')) is not None\n",
    "\n",
    "print(df.apply(valida_campi, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e6133",
   "metadata": {},
   "source": [
    "## Esercizio 34.3 - Normalizzazione indirizzi\n",
    "Obiettivo: dato un testo con indirizzi, estrarre via/citta'/CAP con regex semplici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 34.3\n",
    "addr_text = \"Spedire a: Via Roma 10, 20121 Milano (MI)\"\n",
    "via = re.findall(r\"Via\\s+[A-Za-z]+\\s+\\d+\", addr_text)\n",
    "cap = re.findall(r\"\b\\d{5}\b\", addr_text)\n",
    "citta = re.findall(r\"\b[A-Z][a-z]+\b\", addr_text)\n",
    "print(via, cap, citta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0e9ee",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa\n",
    "\n",
    "## 5 take-home messages\n",
    "\n",
    "| # | Messaggio | PerchÃ© importante |\n",
    "|---|-----------|-------------------|\n",
    "| 1 | **Regex per campi strutturati** | Email, date, codici hanno pattern fissi |\n",
    "| 2 | **NER per entitÃ  generiche** | Nomi, aziende, luoghi sono variabili |\n",
    "| 3 | **Normalizzazione sempre** | Date ISO, importi float per downstream |\n",
    "| 4 | **Validazione per qualitÃ ** | Pattern valido â‰  valore valido |\n",
    "| 5 | **Output in DataFrame** | Struttura per analisi e export |\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto sintetico: quando usare cosa\n",
    "\n",
    "| Campo da estrarre | Approccio | Pattern/Strumento |\n",
    "|-------------------|-----------|-------------------|\n",
    "| Email | Regex | `[\\w.+-]+@[\\w-]+\\.[\\w.-]+` |\n",
    "| Date (formato fisso) | Regex + dateutil | `\\d{1,2}/\\d{1,2}/\\d{2,4}` |\n",
    "| Importi | Regex + normalizzazione | `EUR?\\s*[\\d.,]+` |\n",
    "| Nomi persone | NER (spaCy) | doc.ents con label PER |\n",
    "| Aziende | NER + Gazetteer | Lista nota + fallback ML |\n",
    "| Codici (CF, IBAN) | Regex con validazione | Pattern + checksum |\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow normalizzazione\n",
    "\n",
    "```python\n",
    "# Date: da DD/MM/YYYY a YYYY-MM-DD (ISO)\n",
    "def normalize_date(date_str):\n",
    "    from dateutil.parser import parse\n",
    "    return parse(date_str, dayfirst=True).strftime('%Y-%m-%d')\n",
    "\n",
    "# Importo: da \"1.250,50\" a 1250.50 (float)\n",
    "def normalize_amount(amount_str):\n",
    "    clean = amount_str.replace('EUR', '').replace('.', '').replace(',', '.').strip()\n",
    "    return float(clean)\n",
    "\n",
    "# Email: validazione basica\n",
    "def is_valid_email(email):\n",
    "    import re\n",
    "    return bool(re.match(r'^[\\w.+-]+@[\\w-]+\\.[\\w.-]+$', email))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Reference card metodi\n",
    "\n",
    "| Metodo | Input | Output | Note |\n",
    "|--------|-------|--------|------|\n",
    "| `re.findall(pattern, text)` | pattern, testo | lista match | Estrazione multipla |\n",
    "| `re.search(pattern, text)` | pattern, testo | match object | Primo match |\n",
    "| `dateutil.parser.parse()` | stringa data | datetime | Parsing flessibile |\n",
    "| `pd.DataFrame(dict)` | dizionario | DataFrame | Struttura output |\n",
    "| `spacy.nlp(text).ents` | testo | entitÃ  | NER |\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e debug rapido\n",
    "\n",
    "| Errore | PerchÃ© sbagliato | Fix |\n",
    "|--------|-----------------|-----|\n",
    "| Regex troppo stretta | Non cattura varianti | Allarga con `?`, `*`, alternation |\n",
    "| Regex troppo larga | Falsi positivi | Testa su casi limite |\n",
    "| No normalizzazione | Date/importi incompatibili | Sempre convertire |\n",
    "| Ignora encoding | Caratteri speciali rotti | Leggi con encoding corretto |\n",
    "| Output non strutturato | Difficile da usare | Sempre DataFrame |\n",
    "\n",
    "---\n",
    "\n",
    "## Template Document Intelligence\n",
    "\n",
    "```python\n",
    "import re\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def extract_document_fields(text):\n",
    "    \"\"\"Estrae campi chiave da un documento testuale.\"\"\"\n",
    "    \n",
    "    # Pattern\n",
    "    email_pattern = r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+'\n",
    "    date_pattern = r'\\d{1,2}/\\d{1,2}/\\d{2,4}'\n",
    "    amount_pattern = r'EUR?\\s*[\\d.,]+'\n",
    "    \n",
    "    # Estrazione\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    amounts = re.findall(amount_pattern, text)\n",
    "    \n",
    "    # Normalizzazione\n",
    "    dates_norm = [parse(d, dayfirst=True).strftime('%Y-%m-%d') for d in dates]\n",
    "    amounts_norm = [float(a.replace('EUR', '').replace('.', '').replace(',', '.').strip()) \n",
    "                    for a in amounts]\n",
    "    \n",
    "    return {\n",
    "        'emails': emails,\n",
    "        'dates': dates_norm,\n",
    "        'amounts': amounts_norm\n",
    "    }\n",
    "\n",
    "# Uso\n",
    "result = extract_document_fields(document_text)\n",
    "df = pd.DataFrame({\n",
    "    'tipo': ['email'] * len(result['emails']) + ['data'] * len(result['dates']),\n",
    "    'valore': result['emails'] + result['dates']\n",
    "})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prossimi passi\n",
    "\n",
    "| Lezione | Argomento | Collegamento |\n",
    "|---------|-----------|--------------|\n",
    "| 35 | Information Retrieval | Ricerca semantica in corpus |\n",
    "| 36 | Knowledge Mining | Costruzione knowledge graph |\n",
    "| 37+ | Deep Learning, Generativi | Estensioni avanzate |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce459d58",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho definito i campi da estrarre e scelto pattern adeguati.\n",
    "- [ ] Ho normalizzato date/importi e validato email/ID.\n",
    "- [ ] Ho strutturato l'output in DataFrame.\n",
    "- [ ] Ho valutato la necessita' di NER per entita' non strutturate.\n",
    "- [ ] Ho documentato limitazioni dei pattern usati.\n",
    "\n",
    "Glossario\n",
    "- Document intelligence: estrazione di campi chiave da documenti.\n",
    "- Regex: espressioni regolari per pattern testuali.\n",
    "- Normalizzazione: conversione a formati standard (date ISO, importi float).\n",
    "- Validazione: controlli su formati attesi.\n",
    "- NER: riconoscimento di entita' nominate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-02-15 | Creazione: estrazione regex base |\n",
    "| 1.1 | 2024-02-22 | Aggiunta normalizzazione date/importi |\n",
    "| 2.0 | 2024-02-28 | Integrato DataFrame output |\n",
    "| 2.1 | 2024-03-05 | Refactor con pattern comuni |\n",
    "| **2.3** | **2024-12-19** | **ESPANSIONE COMPLETA:** mappa lezione 8 sezioni, tabella obiettivi, ASCII pipeline estrazione, tipi documenti table, pattern regex comuni (email, CF, IBAN, telefono), 5 take-home messages, workflow normalizzazione funzioni, template completo Document Intelligence, reference card metodi |\n",
    "\n",
    "---\n",
    "\n",
    "## Note per lo studente\n",
    "\n",
    "Document Intelligence Ã¨ la base di:\n",
    "\n",
    "| Applicazione | Documenti | Output |\n",
    "|--------------|-----------|--------|\n",
    "| Invoice Processing | Fatture | Tabelle contabili |\n",
    "| Contract Analysis | Contratti | Clausole, date, parti |\n",
    "| Email Parsing | Email | Campi strutturati |\n",
    "| Form Processing | Moduli OCR | Database |\n",
    "\n",
    "**Pipeline standard:**\n",
    "1. Input (PDF/text) â†’ 2. Pulizia â†’ 3. Estrazione â†’ 4. Normalizzazione â†’ 5. Validazione â†’ 6. Output\n",
    "\n",
    "**Prossima tappa:** Lesson 35 - Information Retrieval"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
