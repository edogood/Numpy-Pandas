{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59457317",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "\n",
    "Lezione 32: Sentiment Analysis - Classificare la polarità del testo\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa della lezione\n",
    "\n",
    "| Sezione | Contenuto | Tempo stimato |\n",
    "|---------|-----------|---------------|\n",
    "| 1 | Titolo, obiettivi, cos'è sentiment analysis | 5 min |\n",
    "| 2 | Teoria: rappresentazioni, modelli, metriche | 15 min |\n",
    "| 3 | Schema mentale: pipeline sentiment | 5 min |\n",
    "| 4 | Demo: BoW + NB, TF-IDF + LR, interpretazione | 25 min |\n",
    "| 5 | Esercizi guidati + error analysis | 15 min |\n",
    "| 6 | Conclusione operativa | 10 min |\n",
    "| 7 | Checklist di fine lezione + glossario | 5 min |\n",
    "| 8 | Changelog didattico | 2 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "| # | Obiettivo | Verifica |\n",
    "|---|-----------|----------|\n",
    "| 1 | Costruire **pipeline sentiment** completa | Sai fare preprocessing → vectorize → classify? |\n",
    "| 2 | Confrontare **BoW vs TF-IDF** per sentiment | Sai quale performa meglio? |\n",
    "| 3 | Usare **NaiveBayes e LogisticRegression** | Sai quando preferire quale? |\n",
    "| 4 | Valutare con **metriche appropriate** | Sai usare F1 su classi sbilanciate? |\n",
    "| 5 | **Interpretare il modello** | Sai estrarre parole positive/negative? |\n",
    "\n",
    "---\n",
    "\n",
    "## L'idea centrale: cos'è Sentiment Analysis\n",
    "\n",
    "```\n",
    "INPUT (recensione):                  OUTPUT (sentiment):\n",
    "\n",
    "\"This product is amazing!           → POSITIVE (0.95)\n",
    " Best purchase ever!\"\n",
    "\n",
    "\"Terrible quality, waste            → NEGATIVE (0.92)\n",
    " of money. Very disappointed.\"\n",
    "\n",
    "\"It's okay, nothing special.\"       → NEUTRAL/MIXED (0.55)\n",
    "```\n",
    "\n",
    "**Applicazioni:** recensioni prodotti, social media, feedback clienti, brand monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "## Il problema delle negazioni\n",
    "\n",
    "```\n",
    "SENZA BIGRAMMI:                     CON BIGRAMMI:\n",
    "\n",
    "\"not good\"                          \"not good\"\n",
    "   ↓                                    ↓\n",
    "token: [\"not\", \"good\"]              token: [\"not\", \"good\", \"not good\"]\n",
    "   ↓                                    ↓\n",
    "\"good\" → positivo!                  \"not good\" → negativo!\n",
    "   ↓                                    ↓\n",
    "ERRORE!                             CORRETTO!\n",
    "```\n",
    "\n",
    "**Soluzione:** usa `ngram_range=(1, 2)` per catturare negazioni.\n",
    "\n",
    "---\n",
    "\n",
    "## Modelli per Sentiment Analysis\n",
    "\n",
    "| Modello | Pro | Contro | Quando usare |\n",
    "|---------|-----|--------|--------------|\n",
    "| **MultinomialNB** | Veloce, baseline | Assume indipendenza | Prototipo rapido |\n",
    "| **LogisticRegression** | Interpretabile, robusto | Lento su grandi dataset | Produzione |\n",
    "| **SVM (LinearSVC)** | Ottimo su sparse | Meno probabilistico | Alta precisione |\n",
    "| **Deep Learning** | Cattura semantica | Richiede molti dati | Dataset grandi |\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Sentiment Analysis\n",
    "\n",
    "```\n",
    "┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌──────────────┐\n",
    "│    Testo     │ →  │   Pulizia    │ →  │  Vectorizer  │ →  │  Classifier  │\n",
    "│   grezzo     │    │  lowercase   │    │  TF-IDF      │    │  LogReg      │\n",
    "└──────────────┘    │  punct       │    └──────────────┘    └──────────────┘\n",
    "                    │  stopwords   │           │                    │\n",
    "                    └──────────────┘           ▼                    ▼\n",
    "                                        fit su TRAIN          predict su TEST\n",
    "                                        transform su          evaluate F1\n",
    "                                        TRAIN + TEST\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "| Concetto | Dove lo trovi | Verifica |\n",
    "|----------|---------------|----------|\n",
    "| BoW | Lezione 30 | Sai usare CountVectorizer? |\n",
    "| TF-IDF | Lezione 31 | Sai usare TfidfVectorizer? |\n",
    "| Classificazione binaria | Lezioni 5-6 | Sai cosa sono precision/recall? |\n",
    "| Metriche F1 | Lezione 17 | Sai interpretare classification_report? |\n",
    "\n",
    "**Cosa useremo:** CountVectorizer, TfidfVectorizer, MultinomialNB, LogisticRegression, accuracy_score, classification_report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed083ef8",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- Sentiment analysis: assegnare etichette positive/negative a testi.\n",
    "- Rappresentazioni: BoW (conteggi) vs TF-IDF (pesi informativi).\n",
    "- Modelli comuni: Naive Bayes (adatto a conteggi), Logistic Regression (lineare su feature sparse).\n",
    "- Metriche: accuracy, precision, recall, F1; attenzione a dataset sbilanciati.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73f10a",
   "metadata": {},
   "source": [
    "## Scelte di preprocessing\n",
    "- Lowercase, rimozione punteggiatura/numeri, eventualmente stopword.\n",
    "- Uso di `fit` sul train e `transform` su test; non rifittare il vocabolario.\n",
    "- ngram_range per catturare bigrammi utili a negazioni.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36413cc8",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Pulizia base del testo.\n",
    "2. Split train/test stratificato.\n",
    "3. Vettorizzazione (BoW o TF-IDF) con vocabolario fit sul train.\n",
    "4. Addestramento modello (NB o LR) e valutazione su test.\n",
    "5. Confronto rappresentazioni e modelli; scelta in base a F1/accuracy.\n",
    "6. Interpretazione: parole piu' pesanti/coef per capire il modello.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae527427",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "- Demo 1: dataset di recensioni, BoW + MultinomialNB.\n",
    "- Demo 2: TF-IDF + LogisticRegression e confronto metriche.\n",
    "- Demo 3: parole piu' indicative per classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0945201",
   "metadata": {},
   "source": [
    "## Demo 1 - BoW + Naive Bayes\n",
    "Perche': baseline rapida su conteggi. Checkpoint: vocabolario fit su train, shape coerenti, accuracy > 0.5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3050f",
   "metadata": {},
   "source": [
    "## Demo 2 - TF-IDF + Logistic Regression\n",
    "Perche': pesi informativi e modello lineare; confronto con baseline. Checkpoint: F1 test, nessun rifit su test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfcae2",
   "metadata": {},
   "source": [
    "## Demo 3 - Parole piu' importanti\n",
    "Perche': interpretare il modello TF-IDF con i coefficienti della logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87649942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup e dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "recensioni = [\n",
    "    (\"Prodotto eccezionale, lo consiglio a tutti\", 1),\n",
    "    (\"Ottimo acquisto, qualita eccellente\", 1),\n",
    "    (\"Pessimo, arrivato rotto\", 0),\n",
    "    (\"Non funziona, soldi sprecati\", 0),\n",
    "    (\"Prezzo onesto e buona qualita\", 1),\n",
    "    (\"Esperienza terribile, non comprare\", 0),\n",
    "    (\"Prodotto difettoso e assistenza assente\", 0),\n",
    "    (\"Spedizione veloce e prodotto perfetto\", 1),\n",
    "    (\"Deluso, qualita bassa\", 0),\n",
    "    (\"Fantastico, supera le aspettative\", 1)\n",
    "]\n",
    "texts, labels = zip(*recensioni)\n",
    "X_train_txt, X_test_txt, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "print(f\"Train: {len(X_train_txt)}, Test: {len(X_test_txt)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: BoW + MultinomialNB\n",
    "bow_vec = CountVectorizer()\n",
    "X_train_bow = bow_vec.fit_transform(X_train_txt)\n",
    "X_test_bow = bow_vec.transform(X_test_txt)\n",
    "assert X_train_bow.shape[0] == len(X_train_txt)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)\n",
    "preds_bow = nb.predict(X_test_bow)\n",
    "acc_bow = accuracy_score(y_test, preds_bow)\n",
    "print(f\"Accuracy BoW+NB: {acc_bow:.3f}\")\n",
    "print(classification_report(y_test, preds_bow, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55334666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: TF-IDF + Logistic Regression\n",
    "vec_tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "X_train_tfidf = vec_tfidf.fit_transform(X_train_txt)\n",
    "X_test_tfidf = vec_tfidf.transform(X_test_txt)\n",
    "assert X_test_tfidf.shape[1] == X_train_tfidf.shape[1]\n",
    "\n",
    "lr = LogisticRegression(max_iter=500, random_state=42)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "preds_tfidf = lr.predict(X_test_tfidf)\n",
    "acc_tfidf = accuracy_score(y_test, preds_tfidf)\n",
    "print(f\"Accuracy TF-IDF+LR: {acc_tfidf:.3f}\")\n",
    "print(classification_report(y_test, preds_tfidf, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: parole piu' indicative (TF-IDF + LR)\n",
    "feature_names = vec_tfidf.get_feature_names_out()\n",
    "coefs = lr.coef_[0]\n",
    "idx_sorted = np.argsort(coefs)\n",
    "neg_terms = [(feature_names[i], coefs[i]) for i in idx_sorted[:5]]\n",
    "pos_terms = [(feature_names[i], coefs[i]) for i in idx_sorted[-5:][::-1]]\n",
    "print(\"Top parole negative:\", neg_terms)\n",
    "print(\"Top parole positive:\", pos_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: nessuna esecuzione necessaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: nessuna esecuzione necessaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e93872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder: nessuna esecuzione necessaria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c2659",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 32.1 - Pipeline completa\n",
    "Obiettivo: implementare la pipeline (BoW/TF-IDF) e confrontare NB vs LR su un nuovo set di frasi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72087a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 32.1\n",
    "frasi = [\n",
    "    (\"servizio clienti pessimo e tempi lunghi\", 0),\n",
    "    (\"molto soddisfatto dell acquisto\", 1),\n",
    "    (\"qualita scarsa e prodotto rotto\", 0),\n",
    "    (\"spedizione rapida e prodotto conforme\", 1),\n",
    "    (\"non vale il prezzo pagato\", 0),\n",
    "    (\"ottimo rapporto qualita prezzo\", 1)\n",
    "]\n",
    "texts2, labels2 = zip(*frasi)\n",
    "Xtr, Xte, ytr, yte = train_test_split(texts2, labels2, test_size=0.33, random_state=42, stratify=labels2)\n",
    "vec2 = TfidfVectorizer(ngram_range=(1,2))\n",
    "Xtr_t = vec2.fit_transform(Xtr)\n",
    "Xte_t = vec2.transform(Xte)\n",
    "nb2 = MultinomialNB()\n",
    "nb2.fit(Xtr_t, ytr)\n",
    "preds = nb2.predict(Xte_t)\n",
    "print(classification_report(yte, preds, digits=3))\n",
    "assert preds.shape[0] == len(yte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ef7e9",
   "metadata": {},
   "source": [
    "## Esercizio 32.2 - Error analysis\n",
    "Obiettivo: identificare false positive/negative e verificare termini che generano errori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40cf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 32.2\n",
    "misclassified = []\n",
    "for text, true, pred in zip(X_test_txt, y_test, preds_tfidf):\n",
    "    if true != pred:\n",
    "        misclassified.append((text, true, pred))\n",
    "print(\"Errori trovati:\")\n",
    "for e in misclassified:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68cafc",
   "metadata": {},
   "source": [
    "## Esercizio 32.3 - Stopword e n-grammi\n",
    "Obiettivo: misurare l'impatto di stopword rimosse e bigrammi sul punteggio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 32.3\n",
    "stopwords_it = {'il','lo','la','i','gli','le','un','una','di','a','da','in','con','su','per','tra','fra','e','o','ma','che','non','sono','ho','ha','questo','questa','questi','queste'}\n",
    "vec_sw = TfidfVectorizer(stop_words=stopwords_it, ngram_range=(1,2))\n",
    "Xtr_sw = vec_sw.fit_transform(X_train_txt)\n",
    "Xte_sw = vec_sw.transform(X_test_txt)\n",
    "acc_sw = accuracy_score(y_test, lr.fit(Xtr_sw, y_train).predict(Xte_sw))\n",
    "print(f\"Accuracy con stopword e bigrammi: {acc_sw:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e892e1",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa\n",
    "\n",
    "## 5 take-home messages\n",
    "\n",
    "| # | Messaggio | Perché importante |\n",
    "|---|-----------|-------------------|\n",
    "| 1 | **Bigrammi per negazioni** | \"not good\" ≠ \"good\" |\n",
    "| 2 | **TF-IDF spesso batte BoW** | Pesi informativi migliorano F1 |\n",
    "| 3 | **LogReg interpretabile** | coef_ mostra parole positive/negative |\n",
    "| 4 | **Stratify nello split** | Bilancia classi nel train/test |\n",
    "| 5 | **Error analysis obbligatoria** | Guarda i falsi positivi/negativi |\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto sintetico: BoW vs TF-IDF per sentiment\n",
    "\n",
    "| Aspetto | BoW + NB | TF-IDF + LR |\n",
    "|---------|----------|-------------|\n",
    "| **Velocità training** | Molto veloce | Veloce |\n",
    "| **F1 tipico** | 0.75-0.85 | 0.80-0.90 |\n",
    "| **Interpretabilità** | Media | Alta (coef_) |\n",
    "| **Gestione negazioni** | Richiede bigrammi | Richiede bigrammi |\n",
    "| **Quando preferire** | Baseline, prototipo | Produzione |\n",
    "\n",
    "---\n",
    "\n",
    "## Perché questi metodi funzionano\n",
    "\n",
    "### 1) MultinomialNB per testo\n",
    "\n",
    "```\n",
    "P(positivo | \"great\", \"product\") ∝ P(\"great\" | positivo) × P(\"product\" | positivo) × P(positivo)\n",
    "\n",
    "Naive = assume che \"great\" e \"product\" siano indipendenti\n",
    "→ Semplificazione, ma funziona sorprendentemente bene su testo!\n",
    "```\n",
    "\n",
    "### 2) LogisticRegression per interpretazione\n",
    "\n",
    "```\n",
    "score = w₁×\"great\" + w₂×\"terrible\" + w₃×\"not_good\" + ...\n",
    "\n",
    "w₁ = +2.5  (parola positiva)\n",
    "w₂ = -3.0  (parola negativa)\n",
    "w₃ = -1.8  (bigramma negativo)\n",
    "\n",
    "→ Ordina per peso = keyword positive/negative!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Reference card metodi\n",
    "\n",
    "| Metodo | Input | Output | Note |\n",
    "|--------|-------|--------|------|\n",
    "| `MultinomialNB()` | X sparse | predict, predict_proba | Per conteggi BoW |\n",
    "| `LogisticRegression()` | X sparse | predict, predict_proba, coef_ | Interpretabile |\n",
    "| `classification_report()` | y_true, y_pred | precision, recall, F1 | Metriche complete |\n",
    "| `TfidfVectorizer(ngram_range=(1,2))` | docs | X sparse | Bigrammi inclusi |\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e debug rapido\n",
    "\n",
    "| Errore | Perché sbagliato | Fix |\n",
    "|--------|-----------------|-----|\n",
    "| No bigrammi | Perde negazioni | ngram_range=(1,2) |\n",
    "| Refit vectorizer su test | Leakage | Solo transform() |\n",
    "| Ignora sbilanciamento | F1 ingannevole | stratify=y, macro F1 |\n",
    "| Non guarda errori | Non capisci il modello | Analizza FP e FN |\n",
    "| Troppi max_features | Overfitting | Prova 3000-5000 |\n",
    "\n",
    "---\n",
    "\n",
    "## Template Sentiment Analysis completo\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Prepara dati\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# 2) Vettorizza con bigrammi\n",
    "vec = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=2)\n",
    "X_train_vec = vec.fit_transform(X_train)\n",
    "X_test_vec = vec.transform(X_test)\n",
    "\n",
    "# 3) Classifica\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "preds = clf.predict(X_test_vec)\n",
    "\n",
    "# 4) Valuta\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# 5) Interpreta\n",
    "feature_names = vec.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "top_pos = np.argsort(coefs)[-10:][::-1]\n",
    "top_neg = np.argsort(coefs)[:10]\n",
    "print(\"Parole POSITIVE:\", [feature_names[i] for i in top_pos])\n",
    "print(\"Parole NEGATIVE:\", [feature_names[i] for i in top_neg])\n",
    "\n",
    "# 6) Error analysis\n",
    "errors = X_test[(preds != y_test)]\n",
    "print(f\"Errori: {len(errors)} / {len(y_test)}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prossimi passi\n",
    "\n",
    "| Lezione | Argomento | Collegamento |\n",
    "|---------|-----------|--------------|\n",
    "| 33 | Named Entity Recognition | Estrarre entità dal testo |\n",
    "| 34 | Document Intelligence | Struttura documenti |\n",
    "| 35+ | Information Retrieval | Ricerca semantica |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e21d5c",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho pulito i testi e gestito stopword/negazioni.\n",
    "- [ ] Ho fatto split stratificato e fit del vocabolario solo sul train.\n",
    "- [ ] Ho confrontato BoW e TF-IDF e almeno due modelli (NB, LR).\n",
    "- [ ] Ho controllato metriche su test (accuracy/F1) e analizzato errori.\n",
    "- [ ] Ho interpretato le parole piu' pesanti del modello.\n",
    "\n",
    "Glossario\n",
    "- Bag of Words: rappresentazione a conteggi.\n",
    "- TF-IDF: pesi basati su frequenza e rarita'.\n",
    "- Stopword: termini molto frequenti e poco informativi.\n",
    "- Bigramma: sequenza di 2 parole consecutive.\n",
    "- Logistic Regression: classificatore lineare per probabilita'.\n",
    "- MultinomialNB: Naive Bayes per conteggi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-02-08 | Creazione: BoW + NB baseline |\n",
    "| 1.1 | 2024-02-15 | Aggiunto TF-IDF + LR |\n",
    "| 2.0 | 2024-02-20 | Integrata interpretazione coef_ |\n",
    "| 2.1 | 2024-02-25 | Refactor con error analysis |\n",
    "| **2.3** | **2024-12-19** | **ESPANSIONE COMPLETA:** mappa lezione 8 sezioni, tabella obiettivi, ASCII pipeline sentiment, problema negazioni con bigrammi, confronto modelli table, 5 take-home messages, NB vs LR explanation, template completo con interpretazione, error analysis guidata |\n",
    "\n",
    "---\n",
    "\n",
    "## Note per lo studente\n",
    "\n",
    "Sentiment Analysis è uno dei task NLP più comuni:\n",
    "\n",
    "| Variante | Classi | Esempio |\n",
    "|----------|--------|---------|\n",
    "| Binario | pos/neg | Recensioni prodotti |\n",
    "| Ternario | pos/neu/neg | Social media |\n",
    "| Fine-grained | 1-5 stelle | Rating |\n",
    "| Aspect-based | Sentiment per aspetto | \"Camera ottima, batteria pessima\" |\n",
    "\n",
    "**Pipeline standard:**\n",
    "1. Pulizia → 2. Vettorizzazione → 3. Classificazione → 4. Interpretazione\n",
    "\n",
    "**Prossima tappa:** Lesson 33 - Named Entity Recognition (NER)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
