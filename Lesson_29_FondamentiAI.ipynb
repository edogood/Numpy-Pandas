{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984df3cd",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "\n",
    "Lezione 29: Fondamenti di Artificial Intelligence - Rule-based vs Data-driven\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa della lezione\n",
    "\n",
    "| Sezione | Contenuto | Tempo stimato |\n",
    "|---------|-----------|---------------|\n",
    "| 1 | Titolo, obiettivi, definizione AI | 5 min |\n",
    "| 2 | Teoria: rule-based vs data-driven, bias-variance | 15 min |\n",
    "| 3 | Schema mentale: workflow confronto modelli | 5 min |\n",
    "| 4 | Demo: churn, baseline rules, ML, f(x), Occam | 30 min |\n",
    "| 5 | Esercizi guidati | 15 min |\n",
    "| 6 | Conclusione operativa | 10 min |\n",
    "| 7 | Checklist di fine lezione + glossario | 5 min |\n",
    "| 8 | Changelog didattico | 2 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "| # | Obiettivo | Verifica |\n",
    "|---|-----------|----------|\n",
    "| 1 | Distinguere **rule-based vs data-driven** | Sai spiegare pro/contro di ciascuno? |\n",
    "| 2 | Comprendere il **No Free Lunch theorem** | Sai perché serve confrontare modelli? |\n",
    "| 3 | Capire **bias-variance trade-off** | Sai riconoscere overfitting/underfitting? |\n",
    "| 4 | Applicare il **rasoio di Occam** | Sai scegliere il modello più semplice che funziona? |\n",
    "| 5 | Costruire **baseline + confronto ML** | Sai fare pipeline rule-based → LogReg → Tree → RF? |\n",
    "\n",
    "---\n",
    "\n",
    "## L'idea centrale: cos'è l'Intelligenza Artificiale\n",
    "\n",
    "```\n",
    "                      INTELLIGENZA ARTIFICIALE\n",
    "                              │\n",
    "          ┌───────────────────┼───────────────────┐\n",
    "          │                                       │\n",
    "    RULE-BASED                              DATA-DRIVEN\n",
    "    (Sistemi esperti)                      (Machine Learning)\n",
    "          │                                       │\n",
    "    IF tenure < 6                          f(X) = model.predict(X)\n",
    "    AND complaints > 2                           │\n",
    "    THEN churn = 1                    ┌──────────┼──────────┐\n",
    "          │                           │          │          │\n",
    "    Trasparente                    LogReg     Tree      Forest\n",
    "    ma rigido                      Semplice   Interpretabile  Potente\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto: Rule-based vs Data-driven\n",
    "\n",
    "| Aspetto | Rule-based | Data-driven |\n",
    "|---------|------------|-------------|\n",
    "| **Creazione** | Esperti scrivono regole | Modello apprende da dati |\n",
    "| **Trasparenza** | Alta (IF-THEN leggibili) | Variabile (Tree ✓, NN ✗) |\n",
    "| **Scalabilità** | Bassa (100+ regole = caos) | Alta (milioni di esempi) |\n",
    "| **Adattabilità** | Manuale (riscrivere regole) | Automatica (re-training) |\n",
    "| **Dati richiesti** | Nessuno | Tanti e di qualità |\n",
    "| **Rischio** | Regole incomplete | Overfitting |\n",
    "\n",
    "---\n",
    "\n",
    "## No Free Lunch Theorem\n",
    "\n",
    "```\n",
    "\"Nessun algoritmo è migliore su TUTTI i problemi\"\n",
    "\n",
    "Problema A:          Problema B:          Problema C:\n",
    "LogReg vince         Tree vince           RF vince\n",
    "│                    │                    │\n",
    "└────────────────────┴────────────────────┘\n",
    "                     │\n",
    "              DEVI SEMPRE CONFRONTARE!\n",
    "```\n",
    "\n",
    "**Implicazione pratica:** testa sempre almeno 2-3 modelli diversi.\n",
    "\n",
    "---\n",
    "\n",
    "## Bias-Variance Trade-off\n",
    "\n",
    "```\n",
    "BIAS ALTO (Underfitting):          VARIANCE ALTA (Overfitting):\n",
    "\n",
    "   ●  ●                               ●──●\n",
    "    ●   ●    ──────── linea retta        ╲ ╱●\n",
    "   ●  ●                                   ●╲╱●\n",
    "                                            ●\n",
    "Modello troppo semplice             Modello troppo complesso\n",
    "Non cattura il pattern              Memorizza il rumore\n",
    "Train basso, Test basso             Train alto, Test basso\n",
    "```\n",
    "\n",
    "**Obiettivo:** trovare la complessità giusta (Rasoio di Occam).\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "| Concetto | Dove lo trovi | Verifica |\n",
    "|----------|---------------|----------|\n",
    "| Classificazione binaria | Lezioni 5-6 | Sai cosa sono 0/1? |\n",
    "| Train/test split | Lezione 8 | Sai perché separare? |\n",
    "| Precision/Recall | Lezione 17 | Sai calcolarle? |\n",
    "| Alberi decisionali | Lezione 14 | Conosci max_depth? |\n",
    "\n",
    "**Cosa useremo:** LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, train_test_split, accuracy_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c1607",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- AI come insieme di tecniche per prendere decisioni automatiche (regole esplicite o apprendimento da dati).\n",
    "- Sistemi rule-based: trasparenza e controllo, ma scalano male con problemi complessi e dati rumorosi.\n",
    "- Sistemi data-driven: apprendono pattern dai dati, richiedono etichette e generalizzazione; rischio overfitting se poco dati o modello complesso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58224e0a",
   "metadata": {},
   "source": [
    "## Approcci rule-based vs data-driven\n",
    "- Rule-based: IF-THEN definite da esperti; input = record con feature, output = classe/azione; errori tipici: regole incomplete o conflittuali.\n",
    "- Data-driven: modello f(x) appreso; input = matrice (n_samples, n_features), output = probabilita'/label; errori tipici: dati sbilanciati, leakage, complessita' eccessiva.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e9b10",
   "metadata": {},
   "source": [
    "## Bias-variance e No Free Lunch\n",
    "- Nessun algoritmo e' migliore su tutti i problemi: serve confrontare piu' modelli con dati reali.\n",
    "- Bias: modello troppo semplice (underfitting); Varianza: modello troppo complesso (overfitting).\n",
    "- Rasoio di Occam: preferire il modello piu' semplice a parita' di prestazioni.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e475a8f2",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "Workflow: definisci il problema -> raccogli/crea dati -> prova baseline rule-based (se disponibile) -> costruisci train/test -> testa modelli semplici/complessi -> confronta metriche -> scegli modello + complessita' adeguata -> interpreta e documenta.\n",
    "Checklist: dati senza NaN, split stratificato, almeno due modelli a confronto, controllo su overfitting (gap train/test), motivazione scelta finale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab4125",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Demo incluse:\n",
    "- Demo 1: dataset churn sintetico + baseline rule-based.\n",
    "- Demo 2: modelli data-driven (LogReg, Tree, Random Forest) e confronto.\n",
    "- Demo 3: funzione f(x) su un singolo caso.\n",
    "- Demo 4: rasoio di Occam (profondita' albero vs prestazioni).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc02cf7",
   "metadata": {},
   "source": [
    "## Demo 1 - Dataset e sistema rule-based\n",
    "Perche': avere una baseline interpretabile e verificare subito se le regole coprono i casi principali. Checkpoint: nessun NaN, classi bilanciate ragionevolmente, regole applicate a tutti i record.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5e4ae",
   "metadata": {},
   "source": [
    "## Demo 2 - Modelli data-driven\n",
    "Perche': confrontare algoritmi standard con la baseline e misurare generalizzazione. Checkpoint: split stratificato, metriche su test, nessun warning di convergenza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d41c45",
   "metadata": {},
   "source": [
    "## Demo 3 - f(x) e interpretazione\n",
    "Perche': mostrare che ogni modello implementa una funzione f(x) con output diverso per lo stesso input. Checkpoint: predizioni coerenti per il campione scelto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228968ba",
   "metadata": {},
   "source": [
    "## Demo 4 - Rasoio di Occam\n",
    "Perche': evidenziare il trade-off complessita'/prestazioni variando la profondita' dell'albero. Checkpoint: trend di accuracy train/test e scelta di una complessita' parsimoniosa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: setup e dataset churn sintetico\n",
    "# Scopo: creare un dataset interpretabile, definire la baseline rule-based e preparare lo split.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset con feature business\n",
    "n_samples = 1000\n",
    "recency = np.random.exponential(40, n_samples)\n",
    "complaints = np.random.poisson(1.5, n_samples)\n",
    "spend = np.random.normal(50, 20, n_samples).clip(10, 150)\n",
    "products = np.random.randint(1, 5, n_samples)\n",
    "days_idle = np.random.exponential(30, n_samples)\n",
    "satisfaction = np.random.randint(1, 6, n_samples)\n",
    "\n",
    "prob = (\n",
    "    0.4 * (complaints > 2).astype(float) +\n",
    "    0.3 * (satisfaction <= 2).astype(float) +\n",
    "    0.2 * (days_idle > 45).astype(float) +\n",
    "    0.1 * (spend < 30).astype(float)\n",
    ")\n",
    "prob = prob / prob.max()\n",
    "np.random.seed(42)\n",
    "churn = np.random.binomial(1, prob.clip(0.05, 0.95))\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'tenure_months': np.random.randint(1, 72, n_samples),\n",
    "    'complaints_6m': complaints,\n",
    "    'monthly_spend': spend,\n",
    "    'n_products': products,\n",
    "    'days_since_last_use': days_idle,\n",
    "    'satisfaction_score': satisfaction,\n",
    "    'churn': churn\n",
    "})\n",
    "\n",
    "print(data.head())\n",
    "print(data['churn'].value_counts())\n",
    "assert not data.isna().any().any(), \"NaN nel dataset\"\n",
    "assert data['churn'].nunique() == 2, \"Label non binarie\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21582ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1 (continua): sistema rule-based\n",
    "# Definizione di regole IF-THEN esplicite e valutazione su train/test.\n",
    "\n",
    "def rule_based_churn_predictor(row):\n",
    "    if row['tenure_months'] < 12 and row['complaints_6m'] >= 2:\n",
    "        return 1\n",
    "    if row['complaints_6m'] >= 3:\n",
    "        return 1\n",
    "    if row['satisfaction_score'] <= 2 and row['days_since_last_use'] > 30:\n",
    "        return 1\n",
    "    if row['n_products'] == 1 and row['satisfaction_score'] <= 3:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "X = data.drop(columns=['churn'])\n",
    "y = data['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rule_preds_train = X_train.apply(rule_based_churn_predictor, axis=1)\n",
    "rule_preds_test = X_test.apply(rule_based_churn_predictor, axis=1)\n",
    "\n",
    "acc_rule_train = accuracy_score(y_train, rule_preds_train)\n",
    "acc_rule_test = accuracy_score(y_test, rule_preds_test)\n",
    "print(f\"Accuracy rule-based train: {acc_rule_train:.3f}, test: {acc_rule_test:.3f}\")\n",
    "assert acc_rule_test > 0, \"Rule-based non predice correttamente\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: modelli data-driven (LogReg, Tree, Random Forest)\n",
    "# Addestriamo e valutiamo modelli supervisionati standard.\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=None, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} - accuracy test: {acc:.3f}\")\n",
    "\n",
    "print(\"\n",
    "Classification report (Random Forest):\")\n",
    "print(classification_report(y_test, models['Random Forest'].predict(X_test), digits=3))\n",
    "assert all(acc > 0 for acc in results.values()), \"Modelli non addestrati\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: confronto rule-based vs data-driven\n",
    "comparison = pd.DataFrame({\n",
    "    'Approccio': ['Rule-Based', 'Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Accuracy_test': [acc_rule_test, results['Logistic Regression'], results['Decision Tree'], results['Random Forest']]\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "best = comparison.sort_values(by='Accuracy_test', ascending=False).iloc[0]\n",
    "print(f\"Miglior approccio: {best['Approccio']} con accuracy {best['Accuracy_test']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecae17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3 (continua): f(x) su un singolo cliente\n",
    "sample = X_test.iloc[[0]]\n",
    "print(\"\n",
    "Esempio cliente (input x):\")\n",
    "print(sample)\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(sample)[0]\n",
    "    proba = model.predict_proba(sample)[0][1]\n",
    "    print(f\"{name}: predizione={pred}, proba_churn={proba:.3f}\")\n",
    "\n",
    "rule_pred = rule_based_churn_predictor(sample.iloc[0])\n",
    "print(f\"Rule-based: predizione={rule_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: Rasoio di Occam (profondita' albero vs prestazioni)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"\n",
    "Rasoio di Occam - profondita' vs accuracy\")\n",
    "depths = [1, 2, 3, 5, 10, None]\n",
    "rows = []\n",
    "for depth in depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    acc_tr = accuracy_score(y_train, dt.predict(X_train))\n",
    "    acc_te = accuracy_score(y_test, dt.predict(X_test))\n",
    "    rows.append({'max_depth': depth if depth is not None else 'None', 'acc_train': acc_tr, 'acc_test': acc_te})\n",
    "\n",
    "res_occam = pd.DataFrame(rows)\n",
    "print(res_occam)\n",
    "assert len(res_occam) == len(depths), \"Tabella occam incompleta\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7495708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIMOSTRAZIONE: RASOIO DI OCCAM - COMPLESSITÀ vs PRESTAZIONI\n",
    "# ============================================================\n",
    "# Confrontiamo modelli di complessità crescente\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RASOIO DI OCCAM: COMPLESSITÀ vs PRESTAZIONI\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nDomanda: un modello più complesso è sempre migliore?\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Testiamo Decision Tree con profondità crescente\n",
    "depths = [1, 2, 3, 5, 10, 20, None]  # None = nessun limite\n",
    "results_occam = []\n",
    "\n",
    "for depth in depths:\n",
    "    # Creiamo modello con complessità controllata\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Accuracy su train e test\n",
    "    acc_train = accuracy_score(y_train, dt.predict(X_train))\n",
    "    acc_test = accuracy_score(y_test, dt.predict(X_test))\n",
    "    \n",
    "    # Numero di foglie (proxy per complessità)\n",
    "    n_leaves = dt.get_n_leaves()\n",
    "    \n",
    "    depth_str = str(depth) if depth else \"∞\"\n",
    "    results_occam.append({\n",
    "        'Max Depth': depth_str,\n",
    "        'N. Foglie': n_leaves,\n",
    "        'Acc Train': acc_train,\n",
    "        'Acc Test': acc_test,\n",
    "        'Gap': acc_train - acc_test\n",
    "    })\n",
    "\n",
    "# Mostriamo risultati\n",
    "df_occam = pd.DataFrame(results_occam)\n",
    "print(\"\\n\")\n",
    "print(df_occam.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"INTERPRETAZIONE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "• Modelli troppo semplici (depth=1,2): underfitting, basse performance\n",
    "• Modelli troppo complessi (depth=∞): overfitting, gap train-test alto\n",
    "• Modello 'giusto' (depth~5): bilancia complessità e generalizzazione\n",
    "\n",
    "→ Il Rasoio di Occam dice: scegli il modello più semplice che \n",
    "  raggiunge prestazioni accettabili sul test set.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f99d9",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 29.1 - Classificare scenari AI\n",
    "Obiettivo: classificare scenari come rule-based, ML supervisionato o altro, motivando la scelta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def00f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 29.1\n",
    "scenari = [\n",
    "    {'scenario': 'Termostato accende riscaldamento se temp < 18', 'tipo_atteso': 'Rule-based'},\n",
    "    {'scenario': 'Riconoscimento volti con rete neurale addestrata', 'tipo_atteso': 'ML supervisionato'},\n",
    "    {'scenario': 'Filtro spam Naive Bayes su email etichettate', 'tipo_atteso': 'ML supervisionato'},\n",
    "    {'scenario': 'Motore regole fiscali per bonus energia', 'tipo_atteso': 'Rule-based'},\n",
    "]\n",
    "\n",
    "for s in scenari:\n",
    "    if 'regola' in s['scenario'].lower() or 'se' in s['scenario'].lower():\n",
    "        s['classificazione'] = 'Rule-based'\n",
    "    else:\n",
    "        s['classificazione'] = 'ML supervisionato'\n",
    "\n",
    "res_scenari = pd.DataFrame(scenari)\n",
    "print(res_scenari)\n",
    "assert res_scenari.shape[0] == len(scenari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667b997",
   "metadata": {},
   "source": [
    "## Esercizio 29.2 - Sistema rule-based per approvazione ferie\n",
    "Obiettivo: implementare regole di business per approvare o negare richieste, verificando copertura casi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 29.2\n",
    "from datetime import datetime\n",
    "\n",
    "def approva_ferie(richiesta: dict, stato_team: dict) -> dict:\n",
    "    # Regole semplici: limite membri in ferie e preavviso minimo 7 giorni\n",
    "    giorni_preavviso = (richiesta['data_inizio'] - richiesta['data_richiesta']).days\n",
    "    overlapping = stato_team['membri_in_ferie']\n",
    "    if giorni_preavviso < 7:\n",
    "        return {'approvato': False, 'motivo': 'Preavviso insufficiente'}\n",
    "    if overlapping >= stato_team['totale_membri'] * 0.3:\n",
    "        return {'approvato': False, 'motivo': 'Troppe persone gia in ferie'}\n",
    "    if richiesta['anni_anzianita'] < 1:\n",
    "        return {'approvato': False, 'motivo': 'Anzianita insufficiente'}\n",
    "    return {'approvato': True, 'motivo': 'Approvato secondo regole'}\n",
    "\n",
    "oggi = datetime(2024, 5, 1)\n",
    "richieste = [\n",
    "    {'dipendente': 'A', 'data_inizio': oggi + pd.Timedelta(days=10), 'data_fine': oggi + pd.Timedelta(days=15), 'data_richiesta': oggi, 'anni_anzianita': 2},\n",
    "    {'dipendente': 'B', 'data_inizio': oggi + pd.Timedelta(days=3), 'data_fine': oggi + pd.Timedelta(days=8), 'data_richiesta': oggi, 'anni_anzianita': 5},\n",
    "]\n",
    "stato_team = {'totale_membri': 10, 'membri_in_ferie': 2}\n",
    "\n",
    "for r in richieste:\n",
    "    print(r['dipendente'], approva_ferie(r, stato_team))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015c3d2",
   "metadata": {},
   "source": [
    "## Esercizio 29.3 - No Free Lunch empirico\n",
    "Obiettivo: confrontare modelli diversi su dataset con forme differenti per mostrare che nessuno vince sempre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 29.3\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "datasets = {\n",
    "    'Lineare': make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, class_sep=2.0, random_state=42),\n",
    "    'Moons': make_moons(n_samples=500, noise=0.2, random_state=42),\n",
    "    'Circles': make_circles(n_samples=500, noise=0.1, factor=0.5, random_state=42)\n",
    "}\n",
    "\n",
    "models_nfl = {\n",
    "    'LogReg': LogisticRegression(max_iter=200),\n",
    "    'SVM RBF': SVC(kernel='rbf', probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for dname, (X_d, y_d) in datasets.items():\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_d, y_d, test_size=0.2, random_state=42, stratify=y_d)\n",
    "    for mname, model in models_nfl.items():\n",
    "        model.fit(X_tr, y_tr)\n",
    "        acc = accuracy_score(y_te, model.predict(X_te))\n",
    "        rows.append({'dataset': dname, 'modello': mname, 'accuracy': acc})\n",
    "\n",
    "res_nfl = pd.DataFrame(rows)\n",
    "print(res_nfl.pivot(index='dataset', columns='modello', values='accuracy'))\n",
    "assert not res_nfl.empty, \"Nessun risultato calcolato\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947d7c4",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa\n",
    "\n",
    "## 5 take-home messages\n",
    "\n",
    "| # | Messaggio | Perché importante |\n",
    "|---|-----------|-------------------|\n",
    "| 1 | **Rule-based = trasparente ma rigido** | Ottimo per pochi casi semplici |\n",
    "| 2 | **Data-driven = adattabile ma opaco** | Scala con i dati, rischio overfitting |\n",
    "| 3 | **No Free Lunch: confronta sempre** | Nessun modello è universalmente migliore |\n",
    "| 4 | **Bias-Variance: trova l'equilibrio** | Troppo semplice ≠ troppo complesso |\n",
    "| 5 | **Rasoio di Occam: semplicità vince** | A parità di performance, scegli il più semplice |\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto sintetico: quando usare cosa\n",
    "\n",
    "| Situazione | Approccio consigliato | Perché |\n",
    "|------------|----------------------|--------|\n",
    "| Pochi casi, regole note | Rule-based | Trasparenza, nessun dato richiesto |\n",
    "| Tanti dati, pattern complessi | Data-driven (RF) | Apprende automaticamente |\n",
    "| Interpretabilità richiesta | Tree o LogReg | Coefficienti leggibili |\n",
    "| Baseline veloce | Rule-based | Riferimento immediato |\n",
    "| Produzione scalabile | Pipeline ML | Re-training automatico |\n",
    "\n",
    "---\n",
    "\n",
    "## Perché questi concetti funzionano\n",
    "\n",
    "### 1) Il modello come funzione f(x)\n",
    "\n",
    "```\n",
    "INPUT:                     MODELLO:                    OUTPUT:\n",
    "┌─────────────────┐       ┌─────────────────┐        ┌─────────────┐\n",
    "│ tenure = 3      │       │                 │        │             │\n",
    "│ complaints = 4  │  →    │     f(x)        │   →    │  churn = 1  │\n",
    "│ monthly = 80    │       │                 │        │             │\n",
    "└─────────────────┘       └─────────────────┘        └─────────────┘\n",
    "\n",
    "Rule-based:   IF complaints > 2 AND tenure < 6 THEN 1\n",
    "LogReg:       sigmoid(w1*tenure + w2*complaints + ...)\n",
    "Tree:         split su complaints > 2.5, poi tenure < 5.5\n",
    "```\n",
    "\n",
    "Tutti implementano f(x), ma con logiche diverse!\n",
    "\n",
    "### 2) Il trade-off nella pratica\n",
    "\n",
    "| Complessità | Train Acc | Test Acc | Diagnosi |\n",
    "|-------------|-----------|----------|----------|\n",
    "| max_depth=1 | 0.65 | 0.64 | Underfitting |\n",
    "| max_depth=5 | 0.85 | 0.82 | GIUSTO |\n",
    "| max_depth=20 | 0.99 | 0.70 | Overfitting |\n",
    "\n",
    "---\n",
    "\n",
    "## Metodi spiegati: reference card\n",
    "\n",
    "| Metodo | Input | Output | Quando usarlo |\n",
    "|--------|-------|--------|---------------|\n",
    "| Rule-based (IF-THEN) | Record | Classe | Baseline, casi semplici |\n",
    "| `LogisticRegression` | X train | proba, coef_ | Baseline ML, interpretabile |\n",
    "| `DecisionTreeClassifier` | X train | predict, feature_importances_ | Interpretabile, visual |\n",
    "| `RandomForestClassifier` | X train | predict, importances | Potente, meno overfitting |\n",
    "| `train_test_split(stratify)` | X, y | X_train, X_test | Split bilanciato |\n",
    "| `accuracy_score` | y_true, y_pred | float | Metrica base |\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e debug rapido\n",
    "\n",
    "| Errore | Perché sbagliato | Fix |\n",
    "|--------|-----------------|-----|\n",
    "| Nessuna baseline | Non sai se ML migliora | Sempre partire da rule-based o dummy |\n",
    "| Non stratificare split | Classi sbilanciate | stratify=y |\n",
    "| max_depth troppo alto | Overfitting | Prova valori bassi, cross-validation |\n",
    "| Confronto solo su train | Illusione di performance | Sempre valutare su test |\n",
    "| Un solo modello testato | Viola No Free Lunch | Almeno 2-3 modelli diversi |\n",
    "\n",
    "---\n",
    "\n",
    "## Prossimi passi\n",
    "\n",
    "| Lezione | Argomento | Collegamento |\n",
    "|---------|-----------|--------------|\n",
    "| 30 | Testo e Dato | Preprocessing testo, tokenizzazione |\n",
    "| 31+ | TF-IDF, Sentiment, NER | NLP applicato |\n",
    "\n",
    "**Nuovo modulo iniziato:** AI e NLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d48e89",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho costruito una baseline rule-based e l'ho confrontata con almeno due modelli di ML.\n",
    "- [ ] Ho usato uno split stratificato e controllato il gap train/test.\n",
    "- [ ] Ho valutato le metriche su test (accuracy, report di classificazione).\n",
    "- [ ] Ho verificato il teorema No Free Lunch provando modelli diversi su dati diversi.\n",
    "- [ ] Ho documentato la complessita' scelta (es. max_depth) con motivazione.\n",
    "\n",
    "Glossario\n",
    "- Rule-based: sistema di regole IF-THEN definite da esperti.\n",
    "- Modello data-driven: f(x) appresa dai dati per predire un output.\n",
    "- Overfitting/Underfitting: modello troppo complesso o troppo semplice rispetto ai dati.\n",
    "- Stratify: mantenere la proporzione di classi nello split train/test.\n",
    "- Accuracy: frazione di predizioni corrette.\n",
    "- No Free Lunch: nessun algoritmo e' migliore per tutti i problemi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-01-28 | Creazione: rule-based vs ML base |\n",
    "| 1.1 | 2024-02-05 | Aggiunto No Free Lunch demo |\n",
    "| 2.0 | 2024-02-12 | Integrato rasoio di Occam con max_depth |\n",
    "| 2.1 | 2024-02-18 | Refactor con checkpoint e assert |\n",
    "| **2.3** | **2024-12-19** | **ESPANSIONE COMPLETA:** mappa lezione 8 sezioni, tabella obiettivi, ASCII tassonomia AI, confronto rule-based vs data-driven, No Free Lunch diagram, bias-variance ASCII, 5 take-home messages, f(x) unified view, trade-off tabella pratica, reference card metodi, errori comuni |\n",
    "\n",
    "---\n",
    "\n",
    "## Note per lo studente\n",
    "\n",
    "Questa lezione apre il **modulo AI/NLP**:\n",
    "\n",
    "| Concetto | Importanza |\n",
    "|----------|------------|\n",
    "| Rule-based vs Data-driven | Fondamento di ogni scelta AI |\n",
    "| No Free Lunch | Giustifica il confronto modelli |\n",
    "| Bias-Variance | Guida la scelta complessità |\n",
    "| Rasoio di Occam | Principio di parsimonia |\n",
    "\n",
    "**Dove siamo nel corso:**\n",
    "- Lezioni 1-18: ML Supervised (Regressione, Classificazione)\n",
    "- Lezioni 19-28: ML Unsupervised (Clustering, PCA, Anomaly)\n",
    "- **Lezione 29+: AI/NLP** (Questa lezione!)\n",
    "\n",
    "**Prossima tappa:** Lesson 30 - Testo e Dato (preprocessing NLP)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
