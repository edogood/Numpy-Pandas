{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "Lezione 40: Recap finale e mappa completa degli approcci visti.\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa del corso completo\n",
    "\n",
    "```\n",
    "MACHINE LEARNING - PERCORSO DIDATTICO COMPLETO\n",
    "===============================================\n",
    "\n",
    "FONDAMENTI (Lezioni 1-8)\n",
    "========================\n",
    "NumPy/Pandas â†’ Feature Eng â†’ Modelli Lineari â†’ Validazione\n",
    "     â†“             â†“              â†“               â†“\n",
    "  Array ops    Filter/Agg    Lin/Log Reg      Train/Val/Test\n",
    "\n",
    "\n",
    "TREE-BASED MODELS (Lezioni 9-16)\n",
    "=================================\n",
    "Decision Tree â†’ Random Forest â†’ XGBoost/LightGBM â†’ Feature Importance\n",
    "      â†“               â†“               â†“                  â†“\n",
    "   Splits         Bagging         Boosting          Interpretability\n",
    "\n",
    "\n",
    "METRICHE E VALIDAZIONE (Lezioni 17-18)\n",
    "======================================\n",
    "Classification Metrics â†’ Regression Metrics â†’ Threshold Optimization\n",
    "         â†“                      â†“                      â†“\n",
    "   F1, ROC-AUC           RMSE, MAE, RÂ²          Precision/Recall curves\n",
    "\n",
    "\n",
    "UNSUPERVISED LEARNING (Lezioni 19-28)\n",
    "=====================================\n",
    "KMeans â†’ Gerarchico â†’ DBSCAN â†’ PCA â†’ Anomaly Detection â†’ Progetti\n",
    "   â†“          â†“          â†“       â†“           â†“              â†“\n",
    "Centroid   Dendrogramma  Density  Dim.Red   IF/LOF       End-to-End\n",
    "\n",
    "\n",
    "TEXT & NLP (Lezioni 29-36)\n",
    "==========================\n",
    "BoW â†’ TF-IDF â†’ Sentiment â†’ NER â†’ Document Intel â†’ IR â†’ Knowledge Mining\n",
    " â†“       â†“         â†“        â†“          â†“          â†“          â†“\n",
    "Sparse  Weights   Opinion  Entities  Patterns   Search    Facts\n",
    "\n",
    "\n",
    "ADVANCED TOPICS (Lezioni 37-40)\n",
    "===============================\n",
    "Deep Learning â†’ Generative â†’ AI in Production â†’ THIS RECAP\n",
    "      â†“              â†“              â†“               â†“\n",
    "    MLP           Bigrams       Thresholds      Decision Map\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi didattici\n",
    "\n",
    "| # | Obiettivo | Livello |\n",
    "|---|-----------|---------|\n",
    "| 1 | Avere visione d'insieme del percorso ML | Panoramica |\n",
    "| 2 | Scegliere approccio giusto per problema dato | Decisionale |\n",
    "| 3 | Ricordare baseline per ogni tipo di task | Pratico |\n",
    "| 4 | Identificare metriche appropriate | Valutativo |\n",
    "| 5 | Pianificare pipeline complete | Progettuale |\n",
    "| 6 | Sapere dove approfondire | Meta-learning |\n",
    "\n",
    "---\n",
    "\n",
    "## Decision tree per scelta modello\n",
    "\n",
    "```\n",
    "                    HAI LABELS?\n",
    "                        |\n",
    "          +-------------+-------------+\n",
    "          |                           |\n",
    "         SI                          NO\n",
    "          |                           |\n",
    "    SUPERVISED                  UNSUPERVISED\n",
    "          |                           |\n",
    "    +-----+-----+              +------+------+\n",
    "    |           |              |             |\n",
    "  CLASSIFY   REGRESS       CLUSTER      DIM.RED\n",
    "    |           |              |             |\n",
    "+---+---+   +---+---+     +----+----+       PCA\n",
    "|       |   |       |     |    |    |\n",
    "Binary Multi LinReg Tree  KMeans DBSCAN Hierarchical\n",
    "\n",
    "\n",
    "DATI TESTUALI?\n",
    "--------------\n",
    "     â†“\n",
    "BoW/TF-IDF â†’ [Classificazione, Ricerca, Estrazione]\n",
    "     â†“\n",
    "Sentiment, NER, Document Intelligence\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cosa useremo\n",
    "- Tabelle riassuntive per ogni area\n",
    "- Esempi di scelta rapida\n",
    "- Reference a lezioni specifiche\n",
    "\n",
    "## Prerequisiti\n",
    "- Aver seguito (almeno concettualmente) le lezioni 1-39\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- Scelta modello = combinazione di dati disponibili, obiettivo, vincoli di rischio e interpretabilita'.\n",
    "- Trade-off: accuratezza vs costo/interpretabilita'/tempo di sviluppo.\n",
    "- Importanza di baseline, validazione e monitoraggio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Tipo di dato (tabellare, testo, immagini) e presenza di label.\n",
    "2. Dimensione e qualita' dei dati -> complessita' modello.\n",
    "3. Rischio errore -> soglie, fallback umano, interpretabilita'.\n",
    "4. Ciclo di vita: training, validazione, deploy, monitoraggio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Tabella riassuntiva di scelta modelli/approcci per casi tipici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cases = [\n",
    "    {\"Problema\": \"Classificazione tabellare sbilanciata\", \"Baseline\": \"Regressione/Tree con class_weight\", \"Modello\": \"XGBoost/LightGBM\", \"Note\": \"ROC-AUC, calibration, soglie\"},\n",
    "    {\"Problema\": \"Clustering clienti\", \"Baseline\": \"KMeans\", \"Modello\": \"KMeans + PCA\", \"Note\": \"Silhouette, profiling\"},\n",
    "    {\"Problema\": \"Testo breve (sentiment)\", \"Baseline\": \"BoW + NB\", \"Modello\": \"TF-IDF + LR\", \"Note\": \"F1, stopword, bigrammi\"},\n",
    "    {\"Problema\": \"Ricerca documenti\", \"Baseline\": \"TF-IDF + coseno\", \"Modello\": \"BM25/semantic search\", \"Note\": \"Valutare recall\"},\n",
    "    {\"Problema\": \"Decisione automatica rischiosa\", \"Baseline\": \"Soglia + fallback\", \"Modello\": \"Policy con audit\", \"Note\": \"Monitor drift\"},\n",
    "]\n",
    "\n",
    "summary = pd.DataFrame(cases)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osservazioni\n",
    "- La tabella e gia un primo checklist di selezione.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (step-by-step)\n",
    "## Esercizio 40.1 - Caso tabellare sbilanciato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 40.1: baseline per tabellare sbilanciato\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=10, weights=[0.9, 0.1], random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "logr = LogisticRegression(class_weight='balanced', max_iter=200)\n",
    "logr.fit(X_train, y_train)\n",
    "preds = logr.predict(X_test)\n",
    "print(classification_report(y_test, preds, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 40.2 - Recupero documenti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 40.2: recupero documenti semplice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "corpus = [\"manuale tecnico api\", \"guida marketing\", \"report vendite\"]\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "query = \"manuale api\"\n",
    "q_vec = vec.transform([query])\n",
    "sims = cosine_similarity(q_vec, X).flatten()\n",
    "print(list(zip(corpus, sims)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 40.3 - Generazione assistita\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 40.3: placeholder per checklist generativa\n",
    "steps = [\n",
    "    \"Definisci prompt e contesto\",\n",
    "    \"Imposta vincoli (lunghezza, tono)\",\n",
    "    \"Prepara esempi few-shot se utili\",\n",
    "    \"Aggiungi controlli post-generazione (filtri, validazioni)\",\n",
    "]\n",
    "for s in steps:\n",
    "    print(\"-\", s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa - Bignami Finale del Corso\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Reference per Tipo di Problema\n",
    "\n",
    "### Classificazione Tabellare\n",
    "| Situazione | Baseline | Modello consigliato | Metrica | Lezione ref |\n",
    "|------------|----------|---------------------|---------|-------------|\n",
    "| Binaria bilanciata | LogReg | XGBoost | Accuracy, F1 | 6, 15 |\n",
    "| Binaria sbilanciata | LogReg + class_weight | XGBoost + scale_pos_weight | ROC-AUC, PR-AUC | 17 |\n",
    "| Multiclasse | LogReg OvR | Random Forest | Macro-F1 | 14, 17 |\n",
    "| Interpretabilita' richiesta | Decision Tree | SHAP + any model | - | 16 |\n",
    "\n",
    "### Regressione Tabellare\n",
    "| Situazione | Baseline | Modello consigliato | Metrica | Lezione ref |\n",
    "|------------|----------|---------------------|---------|-------------|\n",
    "| Lineare | LinearReg | Ridge/Lasso | RMSE, RÂ² | 6, 7 |\n",
    "| Non lineare | Decision Tree | XGBoost | MAE, RMSE | 15, 18 |\n",
    "| Outlier presenti | Ridge | Huber o MAE loss | MAE | 18 |\n",
    "\n",
    "### Clustering\n",
    "| Situazione | Baseline | Modello consigliato | Validazione | Lezione ref |\n",
    "|------------|----------|---------------------|-------------|-------------|\n",
    "| Cluster convessi | KMeans | KMeans + PCA | Silhouette | 20, 25 |\n",
    "| Cluster arbitrari | - | DBSCAN | Stabilita' eps | 23 |\n",
    "| Gerarchia richiesta | - | Agglomerative | Dendrogramma | 22 |\n",
    "| Numero ignoto | Elbow | Silhouette analysis | Gap statistic | 21 |\n",
    "\n",
    "### Testo\n",
    "| Situazione | Baseline | Modello consigliato | Output | Lezione ref |\n",
    "|------------|----------|---------------------|--------|-------------|\n",
    "| Classificazione | BoW + NB | TF-IDF + LogReg/SVM | Classe | 31, 32 |\n",
    "| Ricerca | TF-IDF + coseno | BM25 | Ranking | 35 |\n",
    "| Estrazione info | Regex | NER + patterns | Entita' | 33, 34 |\n",
    "| Generazione | Bigram | (Neural LM) | Testo | 38 |\n",
    "\n",
    "---\n",
    "\n",
    "## I 10 Principi Universali del ML\n",
    "\n",
    "| # | Principio | Applicazione |\n",
    "|---|-----------|--------------|\n",
    "| 1 | **Baseline first** | Sempre iniziare con modello semplice |\n",
    "| 2 | **Validation matters** | Train/Val/Test split, cross-validation |\n",
    "| 3 | **Metric = business goal** | Scegliere metrica che riflette l'obiettivo |\n",
    "| 4 | **Feature > Model** | Feature engineering spesso piu' impattante |\n",
    "| 5 | **Overfitting e' il nemico** | Regolarizzare, validare, early stopping |\n",
    "| 6 | **Interpretabilita' ha valore** | Non sempre serve il modello piu' complesso |\n",
    "| 7 | **Dati > Algoritmi** | Piu' dati di qualita' > algoritmo sofisticato |\n",
    "| 8 | **Deployment e' meta' del lavoro** | Soglie, monitoring, fallback |\n",
    "| 9 | **Drift happens** | Monitorare e retrainare periodicamente |\n",
    "| 10 | **Document everything** | Riproducibilita' e compliance |\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow universale\n",
    "\n",
    "```\n",
    "+----------------------------------------------------------+\n",
    "|  1. DEFINISCI PROBLEMA                                   |\n",
    "|     - Tipo: classificazione/regressione/clustering/...   |\n",
    "|     - Metrica di successo                                |\n",
    "|     - Vincoli (interpretabilita', latenza, costo)        |\n",
    "+----------------------------------------------------------+\n",
    "                           â†“\n",
    "+----------------------------------------------------------+\n",
    "|  2. ESPLORA DATI                                         |\n",
    "|     - EDA: distribuzioni, missing, outlier               |\n",
    "|     - Feature engineering                                |\n",
    "|     - Train/Val/Test split                               |\n",
    "+----------------------------------------------------------+\n",
    "                           â†“\n",
    "+----------------------------------------------------------+\n",
    "|  3. BASELINE + ITERATE                                   |\n",
    "|     - Modello semplice (LogReg, DT, KMeans)              |\n",
    "|     - Valuta metrica                                     |\n",
    "|     - Modello piu' complesso se necessario               |\n",
    "+----------------------------------------------------------+\n",
    "                           â†“\n",
    "+----------------------------------------------------------+\n",
    "|  4. VALIDATE & TUNE                                      |\n",
    "|     - Cross-validation                                   |\n",
    "|     - Hyperparameter tuning                              |\n",
    "|     - Feature selection/importance                       |\n",
    "+----------------------------------------------------------+\n",
    "                           â†“\n",
    "+----------------------------------------------------------+\n",
    "|  5. DEPLOY & MONITOR                                     |\n",
    "|     - Soglie e policy                                    |\n",
    "|     - Drift detection                                    |\n",
    "|     - Audit logging                                      |\n",
    "+----------------------------------------------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Reference rapido librerie\n",
    "\n",
    "| Task | Libreria principale | Funzioni chiave |\n",
    "|------|---------------------|-----------------|\n",
    "| Array/Matrix | NumPy | `np.array`, `@`, `reshape` |\n",
    "| DataFrame | Pandas | `groupby`, `merge`, `apply` |\n",
    "| ML classico | Scikit-learn | `fit`, `predict`, `score` |\n",
    "| Boosting | XGBoost/LightGBM | `XGBClassifier`, `LGBMRegressor` |\n",
    "| Text | Scikit-learn | `TfidfVectorizer`, `CountVectorizer` |\n",
    "| NLP avanzato | spaCy | `nlp()`, `ents`, `tokens` |\n",
    "| Visualizzazione | Matplotlib/Seaborn | `plt.plot`, `sns.heatmap` |\n",
    "\n",
    "---\n",
    "\n",
    "## Dove andare da qui\n",
    "\n",
    "| Area | Prossimi passi | Risorse |\n",
    "|------|----------------|---------|\n",
    "| Deep Learning | PyTorch, TensorFlow | fast.ai, DeepLearning.AI |\n",
    "| NLP avanzato | Transformers, LLM | Hugging Face course |\n",
    "| Computer Vision | CNN, Object Detection | OpenCV, YOLO |\n",
    "| MLOps | MLflow, Kubeflow | Made With ML |\n",
    "| Time Series | Prophet, ARIMA | Forecasting book (Hyndman) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho identificato tipo di dato e obiettivo.\n",
    "- [ ] Ho definito baseline e metrica principale.\n",
    "- [ ] Ho valutato rischio e necessit? di fallback.\n",
    "- [ ] Ho piani di monitoraggio/drift.\n",
    "- [ ] Ho documentato decisioni di scelta modello.\n",
    "\n",
    "Glossario\n",
    "- Baseline: modello semplice di riferimento.\n",
    "- Rischio: costo dell'errore per il business.\n",
    "- Monitoraggio: controllo in produzione di metriche e drift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-01-XX | Struttura iniziale 8 sezioni |\n",
    "| 2.0 | 2024-12-XX | Espansione completa Recap Finale |\n",
    "| 2.1 | - | Mappa corso completa ASCII (40 lezioni) |\n",
    "| 2.2 | - | Decision tree per scelta modello |\n",
    "| 2.3 | - | Quick reference per ogni tipo problema |\n",
    "| 2.4 | - | 10 principi universali ML |\n",
    "| 2.5 | - | Workflow universale in 5 step |\n",
    "| 2.6 | - | Reference librerie e prossimi passi |\n",
    "\n",
    "---\n",
    "\n",
    "## Note di versione\n",
    "\n",
    "**v2.0 - Recap finale espanso**\n",
    "- Visione d'insieme del percorso completo\n",
    "- Reference tables per decisioni rapide\n",
    "- Principi universali come checklist mentale\n",
    "- Workflow riutilizzabile per qualsiasi progetto\n",
    "- Pointers per approfondimenti futuri\n",
    "\n",
    "**Struttura del corso**\n",
    "- Lezioni 01-08: Fondamenti (NumPy, Pandas, Linear Models)\n",
    "- Lezioni 09-16: Tree-based Models e Interpretabilita'\n",
    "- Lezioni 17-18: Metriche Avanzate\n",
    "- Lezioni 19-28: Unsupervised Learning\n",
    "- Lezioni 29-36: NLP e Text Mining\n",
    "- Lezioni 37-39: Advanced Topics\n",
    "- Lezione 40: Questo recap\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulazioni!\n",
    "\n",
    "Hai completato il percorso di **40 lezioni** su Machine Learning con Python.\n",
    "Ora hai le basi per affrontare problemi reali di:\n",
    "- Classificazione e Regressione\n",
    "- Clustering e Dimensionality Reduction\n",
    "- Text Mining e NLP\n",
    "- Deployment e Monitoring\n",
    "\n",
    "**Prossimo passo**: scegli un progetto reale e applica quello che hai imparato!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
