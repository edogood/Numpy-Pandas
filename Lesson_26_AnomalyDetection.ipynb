{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e086e21",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "Lezione 26: Anomaly Detection - trovare l'ago nel pagliaio con approcci non supervisionati.\n",
    "- Obiettivi: capire cosa sono le anomalie, applicare Isolation Forest e Local Outlier Factor, scegliere soglie/contamination, combinare piu' metodi e valutare con metriche adatte.\n",
    "- Cosa useremo: dataset sintetici e una simulazione frodi; StandardScaler, IsolationForest, LocalOutlierFactor, metriche di classificazione binaria.\n",
    "- Prerequisiti: scaling dei dati, nozioni base di alberi decisionali e metodi basati su vicinato, interpretazione di precision/recall/F1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3816d89",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "## 2.1 Cosa sono le anomalie e perche' sono difficili\n",
    "- Un'anomalia e' un'osservazione che si discosta nettamente dal comportamento atteso.\n",
    "- Tipi: globali (lontane da tutto), locali (in zone meno dense), contestuali (anomale solo in certi contesti/tempi).\n",
    "- Sfide: classi sbilanciate, assenza di etichette, soglie da impostare, dati spesso non scalati e con feature eterogenee.\n",
    "## 2.2 Algoritmi chiave\n",
    "- Isolation Forest: isola i punti con tagli casuali; anomalie richiedono meno tagli. Input matrice (n_samples, n_features) scalata; output etichette (+1 regolare, -1 anomalo) e decision_function (score). Errori tipici: contamination incoerente, dati non scalati, troppi estimators lenti.\n",
    "- Local Outlier Factor (LOF): confronta densita' locale con quella dei vicini. Input matrice (n_samples, n_features), output etichette (-1 anomalo) e negative_outlier_factor_. Errori tipici: n_neighbors troppo alto/basso, dati non scalati.\n",
    "## 2.3 Metriche e soglie\n",
    "- Con etichette: precision, recall, F1, confusion matrix. Con punteggi continui: PR curve, ROC, percentili come soglia.\n",
    "- Contamination: stima della % di anomalie. Se troppo alta genera falsi positivi; se troppo bassa perde anomalie.\n",
    "- Regola pratica: partire da 1-5% e fare tuning empirico con F1/recall in base alle priorita' business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0a22c",
   "metadata": {},
   "source": [
    "## 2.2 Quando usare IF o LOF\n",
    "- Preferisci Isolation Forest se le anomalie sono sparse e globali, e vuoi un modello che scala bene con molte feature.\n",
    "- Preferisci LOF se le anomalie sono locali (zone meno dense dentro cluster) e hai dati 2D/3D o pochi attributi dopo PCA.\n",
    "- Se non conosci il tipo di anomalia, prova entrambi e confronta F1/recall in base al costo degli errori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b4d27",
   "metadata": {},
   "source": [
    "## 2.3 Soglie, percentili e interpretazione degli score\n",
    "- Isolation Forest: `decision_function` restituisce score (alto = normale). Scegli soglie con percentili (es. 95-esimo) o usa `contamination` per fissare la percentuale di anomalie.\n",
    "- LOF: `negative_outlier_factor_` (piu' negativo = piu' anomalo). Puoi ordinare gli score e scegliere un cutoff.\n",
    "- Interpretazione: confronta sempre score/soglie con esempi noti di anomalie per validare che il modello non stia marcando punti plausibili come outlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d0b08",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "Workflow: load -> check/clean -> scale -> scegli modello (IF/LOF) -> stima contamination/soglia -> valuta -> interpreta -> iterazioni.\n",
    "Decision map sintetica:\n",
    "1. Scala le feature numeriche (StandardScaler/RobustScaler).\n",
    "2. Se hai label di anomalie, usa PR/F1 per scegliere soglia o contamination.\n",
    "3. Prova sia Isolation Forest (globali) sia LOF (locali); confronta.\n",
    "4. Se anomalie sono poche e vicine a cluster densi, LOF e' spesso migliore; se sono sparse globali, Isolation Forest.\n",
    "5. Documenta la soglia scelta e verifica stabilita' su run multipli.\n",
    "Micro-checklist: nessun NaN, forme coerenti, contamination compatibile con la % attesa, almeno alcuni punti marcati come anomali.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de206ae",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Panoramica demo:\n",
    "- Demo 1: Isolation Forest su dataset sintetico, metriche e grafico.\n",
    "- Demo 2: LOF su anomalie locali vs globali.\n",
    "- Demo 3: Tuning della contamination con F1.\n",
    "- Demo 4: Simulazione frodi con Isolation Forest.\n",
    "- Demo 5: Ensemble IF + LOF e confronto strategie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2524b8",
   "metadata": {},
   "source": [
    "## Demo 1 - Isolation Forest base\n",
    "Perche': mostrare isolamento rapido di anomalie globali su dati scalati.\n",
    "Metodi: `StandardScaler` (input n_samples x n_features, output scalato), `IsolationForest` (etichette +1/-1, decision_function). Checkpoint: nessun NaN, contamination coerente, almeno alcune anomalie rilevate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Isolation Forest su dataset sintetico\n",
    "# Scopo: generare dati con poche anomalie globali, scalare le feature, applicare Isolation Forest e valutare precision/recall/F1.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.close('all')\n",
    "\n",
    "# 1) Crea dataset con anomalie\n",
    "X_normal, _ = make_blobs(n_samples=800, centers=3, cluster_std=0.6, random_state=42)\n",
    "anomalies = np.random.uniform(low=-6, high=6, size=(40, 2))\n",
    "X = np.vstack([X_normal, anomalies])\n",
    "y_true = np.hstack([np.zeros(len(X_normal)), np.ones(len(anomalies))]).astype(int)\n",
    "print(f\"Forma dati: {X.shape}, anomalie attese: {y_true.sum()}\")\n",
    "assert X.shape[0] == y_true.shape[0], \"Shape incoerente\"\n",
    "assert not np.isnan(X).any(), \"NaN nei dati\"\n",
    "\n",
    "# 2) Scala le feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"Forma dopo scaling: {X_scaled.shape}\")\n",
    "\n",
    "# 3) Isolation Forest con contamination ipotizzata al 5%\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "y_pred = iso.fit_predict(X_scaled)\n",
    "y_pred_bin = (y_pred == -1).astype(int)\n",
    "\n",
    "# 4) Metriche\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred_bin, average='binary', zero_division=0)\n",
    "print(classification_report(y_true, y_pred_bin, digits=3))\n",
    "print(f\"Confusion matrix:\n",
    "{confusion_matrix(y_true, y_pred_bin)}\")\n",
    "print(f\"Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "assert y_pred_bin.sum() > 0, \"Nessuna anomalia rilevata\"\n",
    "\n",
    "# 5) Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_pred_bin, cmap='coolwarm', s=15, alpha=0.8)\n",
    "ax.set_title('Isolation Forest: 0=normale, 1=anomalia (scalato)')\n",
    "ax.set_xlabel('Feature 1 (scaled)')\n",
    "ax.set_ylabel('Feature 2 (scaled)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f0123",
   "metadata": {},
   "source": [
    "## Demo 2 - Local Outlier Factor\n",
    "Perche': gestire anomalie locali che un modello globale potrebbe ignorare. Metodi: `LocalOutlierFactor` con n_neighbors e contamination. Checkpoint: almeno un'anomalia trovata, differenza tra anomalie globali e locali.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a55de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Local Outlier Factor (LOF)\n",
    "# Scopo: evidenziare anomalie locali e globali con LOF su dati 2D scalati.\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 2 - Local Outlier Factor\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset con cluster denso e sparso + anomalie\n",
    "cluster_dense = np.random.randn(200, 2) * 0.3\n",
    "cluster_sparse = np.random.randn(120, 2) * 2 + [5, 5]\n",
    "local_anomalies = np.array([[2.5, 2.5], [2.0, 3.0], [3.0, 2.0], [-2, -2], [-2.5, -1.5]])\n",
    "global_anomalies = np.array([[10, 10], [-8, 8]])\n",
    "X_lof = np.vstack([cluster_dense, cluster_sparse, local_anomalies, global_anomalies])\n",
    "y_true_lof = np.hstack([\n",
    "    np.zeros(len(cluster_dense) + len(cluster_sparse)),\n",
    "    np.ones(len(local_anomalies) + len(global_anomalies))\n",
    "]).astype(int)\n",
    "\n",
    "scaler_lof = StandardScaler()\n",
    "X_lof_scaled = scaler_lof.fit_transform(X_lof)\n",
    "print(f\"Forma dataset LOF: {X_lof_scaled.shape}\")\n",
    "assert not np.isnan(X_lof_scaled).any(), \"NaN nei dati LOF\"\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "y_pred_lof = lof.fit_predict(X_lof_scaled)\n",
    "y_pred_lof_bin = (y_pred_lof == -1).astype(int)\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true_lof, y_pred_lof_bin, average='binary', zero_division=0)\n",
    "print(f\"Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "assert y_pred_lof_bin.sum() > 0, \"LOF non ha rilevato anomalie\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.scatter(X_lof_scaled[:, 0], X_lof_scaled[:, 1], c=y_pred_lof_bin, cmap='coolwarm', s=15, alpha=0.8)\n",
    "ax.set_title('LOF: 0=normale, 1=anomalia (scalato)')\n",
    "ax.set_xlabel('Feature 1 (scaled)')\n",
    "ax.set_ylabel('Feature 2 (scaled)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ffa86",
   "metadata": {},
   "source": [
    "## Demo 3 - Tuning del parametro contamination\n",
    "Perche': la % di anomalie attese impatta fortemente precision/recall. Strategia: grid manuale su contamination e confronto F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ee823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: tuning del parametro contamination\n",
    "# Scopo: mostrare l'impatto di contamination su precision/recall/F1 con Isolation Forest (dataset Demo 1).\n",
    "contamination_values = [0.01, 0.02, 0.05, 0.10]\n",
    "\n",
    "results_cont = []\n",
    "for cont in contamination_values:\n",
    "    iso_tune = IsolationForest(contamination=cont, random_state=42)\n",
    "    pred = iso_tune.fit_predict(X_scaled)\n",
    "    pred_bin = (pred == -1).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, pred_bin, average='binary', zero_division=0)\n",
    "    results_cont.append({\"contamination\": cont, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"anomalie_predette\": pred_bin.sum()})\n",
    "\n",
    "res_df = pd.DataFrame(results_cont).sort_values(by='f1', ascending=False)\n",
    "print(res_df)\n",
    "\n",
    "best_row = res_df.iloc[0]\n",
    "print(f\"Miglior contamination per F1: {best_row['contamination']}, F1={best_row['f1']:.3f}\")\n",
    "assert best_row['anomalie_predette'] > 0, \"Nessuna anomalia individuata nel tuning\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c2400",
   "metadata": {},
   "source": [
    "## Demo 4 - Anomaly detection simulazione frodi\n",
    "Perche': applicare Isolation Forest a un dataset sbilanciato con feature eterogenee (importo, orario, distanza). Checkpoint: recall accettabile sulle frodi e controllo falsi positivi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: anomaly detection su simulazione frodi\n",
    "# Scopo: simulare transazioni (2% frodi), scalare feature eterogenee e valutare Isolation Forest.\n",
    "np.random.seed(42)\n",
    "\n",
    "n_normal = 5000\n",
    "n_fraud = 100  # 2% frodi\n",
    "\n",
    "# Transazioni normali\n",
    "normal_amount = np.abs(np.random.exponential(50, n_normal))\n",
    "normal_hour = np.random.normal(14, 4, n_normal) % 24\n",
    "normal_freq = np.random.poisson(5, n_normal)\n",
    "normal_distance = np.abs(np.random.normal(20, 10, n_normal))\n",
    "\n",
    "# Transazioni fraudolente\n",
    "fraud_amount = np.abs(np.random.exponential(200, n_fraud))\n",
    "fraud_hour = (np.random.normal(2, 3, n_fraud) % 24)\n",
    "fraud_freq = np.random.poisson(1, n_fraud)\n",
    "fraud_distance = np.abs(np.random.normal(200, 50, n_fraud))\n",
    "\n",
    "X_fraud = np.vstack([\n",
    "    np.column_stack([normal_amount, normal_hour, normal_freq, normal_distance]),\n",
    "    np.column_stack([fraud_amount, fraud_hour, fraud_freq, fraud_distance])\n",
    "])\n",
    "y_fraud = np.hstack([np.zeros(n_normal), np.ones(n_fraud)]).astype(int)\n",
    "print(f\"Forma X_fraud: {X_fraud.shape}, frodi attese: {y_fraud.sum()}\")\n",
    "assert not np.isnan(X_fraud).any(), \"NaN nel dataset frodi\"\n",
    "\n",
    "scaler_fraud = StandardScaler()\n",
    "X_fraud_scaled = scaler_fraud.fit_transform(X_fraud)\n",
    "\n",
    "iso_fraud = IsolationForest(contamination=0.02, random_state=42)\n",
    "pred_fraud = iso_fraud.fit_predict(X_fraud_scaled)\n",
    "pred_fraud_bin = (pred_fraud == -1).astype(int)\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_fraud, pred_fraud_bin, average='binary', zero_division=0)\n",
    "print(classification_report(y_fraud, pred_fraud_bin, digits=3))\n",
    "print(f\"Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "assert pred_fraud_bin.sum() > 0, \"Nessuna frode rilevata\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b61a72",
   "metadata": {},
   "source": [
    "## Demo 5 - Ensemble IF + LOF\n",
    "Perche': combinare punti di forza di modelli globali e locali. Strategie: AND (entrambi dicono anomalia) e OR (almeno uno). Valutiamo precision/recall/F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c174975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 5: ensemble Isolation Forest + LOF\n",
    "# Scopo: confrontare strategie AND/OR combinando IF e LOF sul dataset frodi.\n",
    "lof_fraud = LocalOutlierFactor(n_neighbors=25, contamination=0.02)\n",
    "# fit_predict restituisce -1 per anomalie\n",
    "pred_lof = lof_fraud.fit_predict(X_fraud_scaled)\n",
    "pred_lof_bin = (pred_lof == -1).astype(int)\n",
    "\n",
    "# Strategie di combinazione\n",
    "pred_and = ((pred_fraud_bin == 1) & (pred_lof_bin == 1)).astype(int)\n",
    "pred_or = ((pred_fraud_bin == 1) | (pred_lof_bin == 1)).astype(int)\n",
    "\n",
    "rows = []\n",
    "for name, pred_vec in [(\"IsolationForest\", pred_fraud_bin), (\"LOF\", pred_lof_bin), (\"AND\", pred_and), (\"OR\", pred_or)]:\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_fraud, pred_vec, average='binary', zero_division=0)\n",
    "    rows.append({\"metodo\": name, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"anomalie_predette\": pred_vec.sum()})\n",
    "\n",
    "res_ensemble = pd.DataFrame(rows).sort_values(by='f1', ascending=False)\n",
    "print(res_ensemble)\n",
    "assert len(res_ensemble) == 4, \"Risultati ensemble mancanti\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220b6c0",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 26.1 - Monitoraggio sensori industriali\n",
    "Obiettivo: generare letture sensori, inserire anomalie e rilevarle con Isolation Forest, controllando recall e falsi positivi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a34f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 26.1: monitoraggio sensori industriali\n",
    "# Passi: crea dati sensori, aggiungi anomalie, scala, applica Isolation Forest, valuta recall e falsi positivi.\n",
    "np.random.seed(42)\n",
    "\n",
    "n_normal_sensors = 10000\n",
    "n_anomaly_sensors = 100\n",
    "\n",
    "# Letture normali (macchinario funzionante)\n",
    "temp_normal = np.random.normal(70, 5, n_normal_sensors)\n",
    "pressure_normal = np.random.normal(100, 10, n_normal_sensors)\n",
    "vibration_normal = np.random.normal(0.5, 0.1, n_normal_sensors)\n",
    "rpm_normal = np.random.normal(3000, 100, n_normal_sensors)\n",
    "energy_normal = np.random.normal(50, 5, n_normal_sensors)\n",
    "\n",
    "# Anomalie (surriscaldamento, pressione anomala)\n",
    "temp_anom = np.random.normal(95, 3, n_anomaly_sensors)\n",
    "pressure_anom = np.random.normal(140, 5, n_anomaly_sensors)\n",
    "vibration_anom = np.random.normal(1.0, 0.2, n_anomaly_sensors)\n",
    "rpm_anom = np.random.normal(3200, 80, n_anomaly_sensors)\n",
    "energy_anom = np.random.normal(70, 6, n_anomaly_sensors)\n",
    "\n",
    "X_sensors = np.vstack([\n",
    "    np.column_stack([temp_normal, pressure_normal, vibration_normal, rpm_normal, energy_normal]),\n",
    "    np.column_stack([temp_anom, pressure_anom, vibration_anom, rpm_anom, energy_anom])\n",
    "])\n",
    "y_sensors = np.hstack([np.zeros(n_normal_sensors), np.ones(n_anomaly_sensors)]).astype(int)\n",
    "print(f\"Shape dati sensori: {X_sensors.shape}, anomalie attese: {y_sensors.sum()}\")\n",
    "assert not np.isnan(X_sensors).any(), \"NaN nei dati sensori\"\n",
    "\n",
    "scaler_sensors = StandardScaler()\n",
    "X_sensors_scaled = scaler_sensors.fit_transform(X_sensors)\n",
    "\n",
    "iso_sensors = IsolationForest(contamination=0.01, random_state=42)\n",
    "pred_sensors = iso_sensors.fit_predict(X_sensors_scaled)\n",
    "pred_sensors_bin = (pred_sensors == -1).astype(int)\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_sensors, pred_sensors_bin, average='binary', zero_division=0)\n",
    "print(f\"Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "print(f\"Anomalie rilevate: {pred_sensors_bin.sum()} su {y_sensors.sum()}\")\n",
    "assert rec > 0, \"Recall nulla: alzare contamination\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4b6f2",
   "metadata": {},
   "source": [
    "## Esercizio 26.2 - Confronto LOF vs Isolation Forest\n",
    "Obiettivo: su dati con anomalie globali e locali, confrontare F1 e scegliere l'algoritmo piu' adatto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 26.2: confronto LOF vs Isolation Forest\n",
    "# Passi: dati con anomalie globali e locali, applica entrambi e confronta F1.\n",
    "np.random.seed(42)\n",
    "\n",
    "cluster_dense = np.random.randn(500, 2) * 0.5\n",
    "cluster_sparse = np.random.randn(500, 2) * 1.5 + [6, 6]\n",
    "global_anom = np.array([[15, 15], [-10, 10], [10, -10], [-10, -10], [0, 15]])\n",
    "local_anom = np.array([[3, 3], [2.5, 3.5], [3.5, 2.5], [4, 4], [2, 4]])\n",
    "\n",
    "X_comp = np.vstack([cluster_dense, cluster_sparse, global_anom, local_anom])\n",
    "y_comp = np.hstack([np.zeros(len(cluster_dense) + len(cluster_sparse)), np.ones(len(global_anom) + len(local_anom))]).astype(int)\n",
    "print(f\"Shape dataset confronto: {X_comp.shape}\")\n",
    "assert not np.isnan(X_comp).any(), \"NaN nei dati\"\n",
    "\n",
    "scaler_comp = StandardScaler()\n",
    "X_comp_scaled = scaler_comp.fit_transform(X_comp)\n",
    "\n",
    "iso_comp = IsolationForest(contamination=0.02, random_state=42)\n",
    "pred_iso = (iso_comp.fit_predict(X_comp_scaled) == -1).astype(int)\n",
    "lof_comp = LocalOutlierFactor(n_neighbors=30, contamination=0.02)\n",
    "pred_lof = (lof_comp.fit_predict(X_comp_scaled) == -1).astype(int)\n",
    "\n",
    "rows = []\n",
    "for name, preds in [(\"IsolationForest\", pred_iso), (\"LOF\", pred_lof)]:\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_comp, preds, average='binary', zero_division=0)\n",
    "    rows.append({\"modello\": name, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"anomalie_predette\": preds.sum()})\n",
    "\n",
    "res_comp = pd.DataFrame(rows)\n",
    "print(res_comp)\n",
    "assert len(res_comp) == 2, \"Risultati mancanti\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7bf020",
   "metadata": {},
   "source": [
    "## Esercizio 26.3 - Ottimizzazione della soglia\n",
    "Obiettivo: usare gli anomaly score di Isolation Forest sulle frodi e scegliere la soglia migliore (percentile) per massimizzare F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 26.3: ottimizzazione soglia su anomaly score\n",
    "# Passi: usa gli score di Isolation Forest sul dataset frodi e seleziona il percentile che massimizza F1.\n",
    "from numpy import percentile\n",
    "\n",
    "scores = -iso_fraud.decision_function(X_fraud_scaled)  # piu' alto = piu' anomalo\n",
    "print(f\"Score: min {scores.min():.3f}, max {scores.max():.3f}, mean {scores.mean():.3f}\")\n",
    "assert scores.shape[0] == y_fraud.shape[0], \"Shape inconsistente\"\n",
    "\n",
    "percentiles = [90, 92, 94, 95, 96, 97, 98]\n",
    "rows = []\n",
    "for p in percentiles:\n",
    "    thr = percentile(scores, p)\n",
    "    preds = (scores >= thr).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_fraud, preds, average='binary', zero_division=0)\n",
    "    rows.append({\"percentile\": p, \"threshold\": thr, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"anomalie_predette\": preds.sum()})\n",
    "\n",
    "res_thr = pd.DataFrame(rows).sort_values(by='f1', ascending=False)\n",
    "print(res_thr)\n",
    "\n",
    "best = res_thr.iloc[0]\n",
    "print(f\"Miglior soglia: percentile {best['percentile']} con F1={best['f1']:.3f}\")\n",
    "assert best['anomalie_predette'] > 0, \"Soglia troppo alta, nessuna anomalia trovata\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b534fb",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa\n",
    "Takeaways:\n",
    "- Isolation Forest performa bene su anomalie globali e resta stabile al variare delle feature se i dati sono scalati.\n",
    "- LOF intercetta anomalie locali ma e' sensibile a n_neighbors e alla scala.\n",
    "- La scelta di contamination/soglia orienta il trade-off precision vs recall: documentarla e validarla con business.\n",
    "\n",
    "Metodi spiegati (cosa fa, input/output, quando usarlo):\n",
    "- `IsolationForest`: isola punti rari con alberi casuali; input matrice scalata; output etichette (+1/-1) e score; usalo per anomalie sparse/globali.\n",
    "- `LocalOutlierFactor`: confronta densita' locali; input matrice scalata; output etichette (-1) e fattore; usalo per anomalie locali in cluster densi.\n",
    "- `StandardScaler`: centra e scala; input matrice; output stessa forma; necessario per IF/LOF.\n",
    "- `precision_recall_fscore_support`/`classification_report`: misurano precision, recall, F1; richiedono etichette vere e predette; evita se non hai label.\n",
    "- `decision_function` (IF): restituisce score (maggiore = piu' normale); serve per scegliere soglie personalizzate.\n",
    "\n",
    "Errori comuni e debug rapido:\n",
    "- Nessuna anomalia rilevata: contamination troppo bassa o dati non scalati; aumenta contamination o verifica scaler.\n",
    "- Troppi falsi positivi: contamination troppo alta o n_neighbors LOF troppo basso; riduci contamination o aumenta n_neighbors.\n",
    "- Risultati instabili tra run: fissa random_state e controlla dimensione del campione.\n",
    "- Metriche NaN: tutti i predetti nella stessa classe; cambia soglia o garantisci almeno un anomalo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f77a58",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho scalato le feature prima di applicare IF/LOF.\n",
    "- [ ] Ho scelto contamination o soglie in linea con la % attesa di anomalie.\n",
    "- [ ] Ho verificato che almeno alcune anomalie vengano identificate.\n",
    "- [ ] Ho confrontato precision/recall/F1 e documentato il trade-off.\n",
    "- [ ] Ho testato almeno un modello globale (IF) e uno locale (LOF) se il contesto lo richiede.\n",
    "- [ ] Ho salvato la soglia/scaler per riprodurre i risultati.\n",
    "\n",
    "Glossario (termini usati):\n",
    "- Anomalia/outlier: osservazione lontana dal comportamento atteso.\n",
    "- Contamination: stima percentuale di anomalie usata dal modello.\n",
    "- Isolation Forest: algoritmo basato su alberi casuali per isolare punti rari.\n",
    "- Local Outlier Factor: algoritmo basato su densita' locale.\n",
    "- n_neighbors: numero di vicini considerati da LOF.\n",
    "- decision_function: score continuo di anomalia/normalita'.\n",
    "- Precision: quota di predetti anomali che sono davvero anomali.\n",
    "- Recall: quota di anomalie reali identificate.\n",
    "- F1-score: media armonica precision/recall.\n",
    "- Threshold: soglia sullo score per decidere anomalie.\n",
    "- False positive: punto normale marcato come anomalo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "- Riorganizzata la lezione in 8 sezioni con titoli in italiano e senza emoji.\n",
    "- Aggiunti razionali prima di ogni demo/esercizio e checklist di controlli.\n",
    "- Inseriti assert su forme, NaN, presenza di anomalie e metriche F1/precision/recall.\n",
    "- Riscritte le demo con tuning contamination, simulazione frodi e ensemble IF+LOF.\n",
    "- Guidati gli esercizi con passi espliciti e controlli sulle soglie.\n",
    "- Integrati metodi spiegati, errori comuni, checklist e glossario.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}