{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b64c49",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "Lezione 35: Information Retrieval con TF-IDF e similarita' coseno.\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa concettuale della lezione\n",
    "\n",
    "```\n",
    "INFORMATION RETRIEVAL - PIPELINE COMPLETA\n",
    "==========================================\n",
    "\n",
    "    +--------------------+\n",
    "    |   CORPUS (N docs)  |\n",
    "    |  \"doc1\", \"doc2\"... |\n",
    "    +----------+---------+\n",
    "               |\n",
    "               v\n",
    "    +--------------------+      +-----------------+\n",
    "    | TfidfVectorizer    |      | Vocabolario V   |\n",
    "    | .fit(corpus)       +----->| fit salva i     |\n",
    "    | .transform(corpus) |      | termini => REUSE|\n",
    "    +----------+---------+      +-----------------+\n",
    "               |\n",
    "               v\n",
    "    +--------------------+\n",
    "    |  MATRICE TF-IDF    |\n",
    "    |  (N docs x V feat) |\n",
    "    +----------+---------+\n",
    "               |\n",
    "               |    +------------------+\n",
    "               |    |  QUERY \"q\"       |\n",
    "               |    |  .transform([q]) |\n",
    "               |    +--------+---------+\n",
    "               |             |\n",
    "               v             v\n",
    "    +----------------------------+\n",
    "    | cosine_similarity(Q, M)    |\n",
    "    | => scores (N,)             |\n",
    "    +-------------+--------------+\n",
    "                  |\n",
    "                  v\n",
    "    +----------------------------+\n",
    "    |  RANKING: argsort desc     |\n",
    "    |  top_k = indices[:k]       |\n",
    "    +-------------+--------------+\n",
    "                  |\n",
    "                  v\n",
    "    +----------------------------+\n",
    "    |  VALUTAZIONE: precision@k  |\n",
    "    |  = |rilevanti âˆ© top_k| / k |\n",
    "    +----------------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi didattici\n",
    "\n",
    "| # | Obiettivo | Livello |\n",
    "|---|-----------|---------|\n",
    "| 1 | Comprendere la pipeline IR: indicizzazione, query, ranking | Fondamentale |\n",
    "| 2 | Usare TfidfVectorizer per indicizzare documenti e query | Operativo |\n",
    "| 3 | Applicare cosine_similarity per rankare risultati | Operativo |\n",
    "| 4 | Valutare la qualita' con precision@k | Valutativo |\n",
    "| 5 | Implementare query expansion per migliorare recall | Avanzato |\n",
    "| 6 | Gestire stopword di dominio e preprocessing coerente | Best Practice |\n",
    "\n",
    "---\n",
    "\n",
    "## Concetti chiave\n",
    "\n",
    "> **Information Retrieval (IR)**: disciplina che si occupa di trovare documenti rilevanti rispetto a un bisogno informativo espresso come query testuale.\n",
    "\n",
    "> **Modello vettoriale**: rappresenta sia documenti che query come vettori nello stesso spazio; la similarita' coseno misura la \"vicinanza angolare\" tra essi.\n",
    "\n",
    "> **Precision@k**: metrica che risponde a \"Quanti dei primi k risultati sono effettivamente rilevanti?\" - cruciale quando l'utente guarda solo i top risultati.\n",
    "\n",
    "---\n",
    "\n",
    "## Tassonomia dei sistemi IR\n",
    "\n",
    "```\n",
    "+---------------------------+---------------------------+\n",
    "|   IR TRADIZIONALE         |   IR SEMANTICO            |\n",
    "+---------------------------+---------------------------+\n",
    "| TF-IDF / BM25             | Embeddings (Word2Vec/BERT)|\n",
    "| Match lessicale esatto    | Match concettuale         |\n",
    "| Vocabolario fisso         | Spazio denso latente      |\n",
    "| Interpretabile            | Black-box ma potente      |\n",
    "| Baseline veloce           | Richiede modelli pesanti  |\n",
    "+---------------------------+---------------------------+\n",
    "```\n",
    "\n",
    "Questa lezione si concentra sull'IR tradizionale con TF-IDF, che rimane una **baseline solida e interpretabile** prima di passare a metodi semantici.\n",
    "\n",
    "---\n",
    "\n",
    "## Cosa useremo\n",
    "- `TfidfVectorizer` per indicizzare documenti e trasformare query\n",
    "- `cosine_similarity` per calcolare rilevanza\n",
    "- `pandas` per organizzare risultati\n",
    "- Funzioni custom per precision@k e query expansion\n",
    "\n",
    "## Prerequisiti\n",
    "- Concetti di BoW e TF-IDF (Lezione 31)\n",
    "- Similarita' coseno (Lezione 31)\n",
    "- Preprocessing testuale (Lezione 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d391ef",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- Information Retrieval: trovare documenti rilevanti dato un bisogno informativo (query).\n",
    "- TF-IDF: rappresenta documenti e query come vettori pesati per frequenza/rarita'.\n",
    "- Similarita' coseno: misura di vicinanza tra vettori; usata per rankare i documenti.\n",
    "- Metriche: precision@k (quota di documenti rilevanti nei primi k).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89850bcb",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Raccogli e pulisci documenti (stopword, lower).\n",
    "2. Fit TF-IDF sul corpus; salva vocabolario.\n",
    "3. Trasforma query con lo stesso vectorizer.\n",
    "4. Calcola similarita' coseno e ordina i documenti.\n",
    "5. Valuta con precision@k se hai rilevanza; altrimenti spot-check manuale.\n",
    "6. Migliora con query expansion o stopword custom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3be5b",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Demo: corpus sintetico, indicizzazione TF-IDF, ricerca con due query, calcolo precision@k e query expansion minimale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup librerie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus di esempio e label di rilevanza per valutazione\n",
    "corpus = [\n",
    "    \"Guida all'uso delle API aziendali\",\n",
    "    \"Manuale di marketing digitale per e-commerce\",\n",
    "    \"Report finanziario trimestrale\",\n",
    "    \"Procedura per richiedere rimborsi e resi\",\n",
    "    \"Tutorial machine learning applicato al churn\"\n",
    "]\n",
    "# Rilevanza binaria per due query\n",
    "relevance = {\n",
    "    'api': {0:1},\n",
    "    'rimborsi': {3:1}\n",
    "}\n",
    "print(f\"Documenti: {len(corpus)}\")\n",
    "assert len(corpus)>0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5eebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicizzazione TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='italian')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(f\"Shape TF-IDF: {X.shape}, sparsimita': {1 - X.nnz/(X.shape[0]*X.shape[1]):.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di ricerca con precision@k\n",
    "\n",
    "def search(query, top_k=3):\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(q_vec, X).flatten()\n",
    "    order = sims.argsort()[::-1][:top_k]\n",
    "    return order, sims[order]\n",
    "\n",
    "def precision_at_k(query, k):\n",
    "    order, _ = search(query, top_k=k)\n",
    "    rel_docs = relevance.get(query, {})\n",
    "    rel_found = sum(1 for idx in order if rel_docs.get(idx,0)==1)\n",
    "    return rel_found / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61357a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguiamo due query\n",
    "for q in ['api','rimborsi']:\n",
    "    order, scores = search(q, top_k=3)\n",
    "    print(f\"Query: {q}\")\n",
    "    for idx, score in zip(order, scores):\n",
    "        print(f\"  Score {score:.3f} -> Doc {idx}: {corpus[idx]}\")\n",
    "    print(f\"Precision@3: {precision_at_k(q,3):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query expansion semplice: sinonimi manuali\n",
    "synonyms = {'api': ['api','interfaccia'], 'rimborsi': ['rimborsi','resi','refund']}\n",
    "\n",
    "def expand_query(q):\n",
    "    terms = synonyms.get(q, [q])\n",
    "    return ' '.join(terms)\n",
    "\n",
    "q_expanded = expand_query('rimborsi')\n",
    "order, scores = search(q_expanded, top_k=3)\n",
    "print(\"Query espansa:\", q_expanded)\n",
    "print(\"Precision@3 espansa:\", precision_at_k('rimborsi',3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479a1f2",
   "metadata": {},
   "source": [
    "### Osservazioni\n",
    "- Precision@k migliora se i termini espansi coprono il vocabolario.\n",
    "- Stopword influenzano la sparsita' e i match; controllarle per il dominio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff7065",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 35.1 - Aggiungere documenti e rivalutare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ee735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 35.1\n",
    "new_doc = \"Documentazione API per pagamenti\"\n",
    "corpus2 = corpus + [new_doc]\n",
    "vectorizer.fit(corpus2)\n",
    "order, scores = search('api', top_k=3)\n",
    "print(\"Nuovi top3 per api:\")\n",
    "for idx, score in zip(order, scores):\n",
    "    print(idx, score, corpus[idx] if idx < len(corpus) else '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4b8f7",
   "metadata": {},
   "source": [
    "## Esercizio 35.2 - Stopword di dominio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 35.2\n",
    "custom_stop = ['manuale','guida']\n",
    "vec_custom = TfidfVectorizer(stop_words=set(custom_stop + list(TfidfVectorizer(stop_words='italian').get_stop_words())))\n",
    "Xc = vec_custom.fit_transform(corpus)\n",
    "print(f\"Sparsimita' con stopword custom: {1 - Xc.nnz/(Xc.shape[0]*Xc.shape[1]):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c993c1c",
   "metadata": {},
   "source": [
    "## Esercizio 35.3 - Precision@k con rilevanze multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 35.3\n",
    "relevance_multi = {'marketing': {1:1, 4:1}}\n",
    "q = 'marketing'\n",
    "order, _ = search(q, top_k=3)\n",
    "rel_docs = relevance_multi[q]\n",
    "prec3 = sum(1 for idx in order if rel_docs.get(idx,0)==1)/3\n",
    "print(f\"Precision@3 per {q}: {prec3:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e3f4c",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa - Bignami IR\n",
    "\n",
    "---\n",
    "\n",
    "## I 5 Take-Home Messages\n",
    "\n",
    "| # | Concetto | Perche' conta |\n",
    "|---|----------|---------------|\n",
    "| 1 | **Pipeline IR = fit(corpus) + transform(query) + cosine + rank** | Workflow standard per qualsiasi ricerca testuale |\n",
    "| 2 | **Stesso vectorizer per corpus e query** | Vocabolario deve essere identico, mai rifittare |\n",
    "| 3 | **Precision@k misura qualita' percepita** | Utenti guardano solo i primi risultati |\n",
    "| 4 | **Query expansion aumenta recall** | Aggiungere sinonimi trova documenti con termini diversi |\n",
    "| 5 | **Stopword di dominio migliorano precision** | Rimuovere termini troppo comuni nel contesto specifico |\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline IR in 6 step\n",
    "\n",
    "```\n",
    "STEP 1: CORPUS              STEP 2: PREPROCESSING\n",
    "+----------------+          +--------------------+\n",
    "| docs = [...]   |   --->   | lower, stopword,   |\n",
    "|                |          | stemming/lemma     |\n",
    "+----------------+          +--------------------+\n",
    "                                    |\n",
    "                                    v\n",
    "STEP 3: INDICIZZAZIONE      STEP 4: QUERY\n",
    "+--------------------+      +--------------------+\n",
    "| vectorizer.fit()   |      | q_vec = transform  |\n",
    "| doc_matrix = tfm() |      | ([query])          |\n",
    "+--------------------+      +--------------------+\n",
    "                                    |\n",
    "                                    v\n",
    "STEP 5: RANKING             STEP 6: VALUTAZIONE\n",
    "+--------------------+      +--------------------+\n",
    "| scores = cosine()  |      | precision@k        |\n",
    "| top_k = argsort()  |      | recall@k, MRR      |\n",
    "+--------------------+      +--------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto metriche IR\n",
    "\n",
    "| Metrica | Formula | Interpretazione |\n",
    "|---------|---------|-----------------|\n",
    "| Precision@k | rilevanti_in_k / k | Quanti top-k sono buoni? |\n",
    "| Recall@k | rilevanti_in_k / tot_rilevanti | Quanti rilevanti ho trovato? |\n",
    "| MRR | 1/rank_primo_rilevante | Quanto presto trovo qualcosa? |\n",
    "| MAP | media precision a ogni rilevante | Qualita' globale del ranking |\n",
    "\n",
    "---\n",
    "\n",
    "## Template operativo\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1) Setup\n",
    "corpus = [\"doc1 text\", \"doc2 text\", ...]\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)\n",
    "doc_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 2) Funzione ricerca\n",
    "def search(query, top_k=5):\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    scores = cosine_similarity(q_vec, doc_matrix).flatten()\n",
    "    top_idx = scores.argsort()[::-1][:top_k]\n",
    "    return [(i, corpus[i], scores[i]) for i in top_idx]\n",
    "\n",
    "# 3) Query expansion\n",
    "def expand_query(query, synonyms_dict):\n",
    "    tokens = query.lower().split()\n",
    "    expanded = tokens.copy()\n",
    "    for t in tokens:\n",
    "        if t in synonyms_dict:\n",
    "            expanded.extend(synonyms_dict[t])\n",
    "    return ' '.join(expanded)\n",
    "\n",
    "# 4) Precision@k\n",
    "def precision_at_k(retrieved_idx, relevant_set, k):\n",
    "    top_k = retrieved_idx[:k]\n",
    "    hits = len(set(top_k) & relevant_set)\n",
    "    return hits / k\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e soluzioni\n",
    "\n",
    "| Errore | Conseguenza | Soluzione |\n",
    "|--------|-------------|-----------|\n",
    "| Rifittare vectorizer su ogni query | Vocabolario diverso, risultati sbagliati | Salvare vectorizer dopo fit su corpus |\n",
    "| Query non preprocessata | Termini non matchano | Stesso preprocessing di corpus |\n",
    "| Ignorare stopword di dominio | Termini troppo comuni dominano | Stopword custom + max_df |\n",
    "| Nessuna valutazione | Non sai se funziona | Creare set di rilevanze anche piccolo |\n",
    "\n",
    "---\n",
    "\n",
    "## Metodi e attributi chiave\n",
    "\n",
    "| Metodo/Attributo | Uso |\n",
    "|------------------|-----|\n",
    "| `vectorizer.fit_transform(corpus)` | Indicizza corpus |\n",
    "| `vectorizer.transform([query])` | Trasforma query |\n",
    "| `vectorizer.vocabulary_` | Mappa termine -> indice |\n",
    "| `cosine_similarity(q, M)` | Scores di similarita' |\n",
    "| `np.argsort()[::-1][:k]` | Top-k indici |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc316cc3",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho pulito il corpus e definito stopword adeguate.\n",
    "- [ ] Ho fit il TF-IDF sul corpus e usato transform sulle query.\n",
    "- [ ] Ho calcolato similarita' coseno e ordinato i documenti.\n",
    "- [ ] Ho valutato precision@k dove avevo rilevanze.\n",
    "- [ ] Ho considerato query expansion o sinonimi di dominio.\n",
    "\n",
    "Glossario\n",
    "- Information Retrieval: recupero di documenti rilevanti da un corpus.\n",
    "- Precision@k: quota di documenti rilevanti nei primi k.\n",
    "- Query expansion: aggiunta di termini correlati alla query.\n",
    "- Similarita' coseno: misura di vicinanza tra vettori.\n",
    "- Vocabolario: termini indicizzati dal vectorizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96a2e8",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-01-XX | Struttura iniziale 8 sezioni |\n",
    "| 2.0 | 2024-12-XX | Espansione completa con pipeline IR ASCII |\n",
    "| 2.1 | - | Aggiunta tassonomia IR tradizionale vs semantico |\n",
    "| 2.2 | - | Tabella obiettivi con livelli di competenza |\n",
    "| 2.3 | - | 5 take-home messages con razionali |\n",
    "| 2.4 | - | Confronto metriche IR (P@k, R@k, MRR, MAP) |\n",
    "| 2.5 | - | Template completo con search + expand + precision |\n",
    "| 2.6 | - | Tabella errori comuni con soluzioni |\n",
    "\n",
    "---\n",
    "\n",
    "## Note di versione\n",
    "\n",
    "**v2.0 - Espansione didattica completa**\n",
    "- Pipeline IR visualizzata in ASCII con tutti i passaggi\n",
    "- Tassonomia che posiziona TF-IDF rispetto a metodi semantici\n",
    "- Emphasis su \"stesso vectorizer\" come punto critico\n",
    "- Metriche IR spiegate con formule e interpretazioni\n",
    "- Template operativo con 4 funzioni chiave\n",
    "- Preparazione concettuale per IR semantico (Lezione 36+)\n",
    "\n",
    "**Dipendenze didattiche**\n",
    "- Richiede: Lezione 30 (preprocessing), Lezione 31 (TF-IDF)\n",
    "- Prepara: Lezione 36 (Knowledge Mining), semantic search\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
