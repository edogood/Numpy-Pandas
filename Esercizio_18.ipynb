{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c142b91",
   "metadata": {},
   "source": [
    "# üìä Lezione 18 ‚Äî Metriche di Valutazione per la Regressione\n",
    "\n",
    "## üéØ Obiettivi della Lezione\n",
    "\n",
    "In questa lezione imparerai:\n",
    "\n",
    "1. **Perch√© non basta R¬≤** ‚Äî limiti e interpretazione\n",
    "2. **MAE, MSE, RMSE** ‚Äî errori assoluti e quadratici\n",
    "3. **MAPE** ‚Äî errore percentuale (interpretabilit√† business)\n",
    "4. **Confronto tra metriche** ‚Äî quando usare quale\n",
    "5. **Residui** ‚Äî analisi diagnostica del modello\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Il Problema: Come Valuto un Modello di Regressione?\n",
    "\n",
    "### Classificazione vs Regressione\n",
    "\n",
    "| Classificazione | Regressione |\n",
    "|-----------------|-------------|\n",
    "| Predice classi discrete | Predice valori continui |\n",
    "| Accuracy, Precision, Recall | MAE, MSE, R¬≤ |\n",
    "| \"Giusto o sbagliato\" | \"Quanto sbaglio?\" |\n",
    "\n",
    "### Domanda Chiave\n",
    "\n",
    "> In regressione non c'√® \"giusto/sbagliato\". C'√® solo **quanto sei lontano** dal valore vero.\n",
    "\n",
    "**Esempio:** Predici che una casa costa ‚Ç¨200.000, il prezzo reale √® ‚Ç¨210.000.\n",
    "- Non √® \"sbagliato\" in senso assoluto\n",
    "- L'errore √® ‚Ç¨10.000 (o 5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a8c30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ MAE ‚Äî Mean Absolute Error\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "\n",
    "### Interpretazione\n",
    "\n",
    "| Aspetto | Descrizione |\n",
    "|---------|-------------|\n",
    "| **Cosa misura** | Media degli errori assoluti |\n",
    "| **Unit√†** | Stessa unit√† di y (‚Ç¨, kg, anni...) |\n",
    "| **Range** | [0, ‚àû) ‚Äî 0 = perfetto |\n",
    "| **Sensibilit√† outlier** | Bassa (robusto) |\n",
    "\n",
    "### Pro e Contro\n",
    "\n",
    "| ‚úÖ Pro | ‚ùå Contro |\n",
    "|--------|----------|\n",
    "| Facile da interpretare | Non penalizza grandi errori |\n",
    "| Robusto agli outlier | Non differenziabile in 0 |\n",
    "| Stessa scala di y | Pu√≤ sottovalutare errori gravi |\n",
    "\n",
    "### Esempio Intuitivo\n",
    "\n",
    "```\n",
    "Predizioni: [100, 200, 150]\n",
    "Valori veri: [110, 180, 160]\n",
    "Errori: |110-100|=10, |180-200|=20, |160-150|=10\n",
    "MAE = (10 + 20 + 10) / 3 = 13.33\n",
    "```\n",
    "‚Üí \"In media, sbaglio di ‚Ç¨13.33\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45e5a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ MSE e RMSE ‚Äî Mean Squared Error\n",
    "\n",
    "### Formule\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "$$RMSE = \\sqrt{MSE}$$\n",
    "\n",
    "### Interpretazione\n",
    "\n",
    "| Metrica | Unit√† | Sensibilit√† Outlier |\n",
    "|---------|-------|---------------------|\n",
    "| **MSE** | y¬≤ (es. ‚Ç¨¬≤) | ALTA |\n",
    "| **RMSE** | y (es. ‚Ç¨) | ALTA |\n",
    "\n",
    "### Perch√© RMSE invece di MSE?\n",
    "\n",
    "- **MSE** √® in unit√† quadrate ‚Üí difficile da interpretare\n",
    "- **RMSE** riporta alla scala originale ‚Üí confrontabile con MAE\n",
    "\n",
    "### Esempio: Effetto Outlier\n",
    "\n",
    "```\n",
    "Scenario 1: errori = [10, 10, 10]\n",
    "    MAE = 10, MSE = 100, RMSE = 10\n",
    "\n",
    "Scenario 2: errori = [1, 1, 28]  (un outlier!)\n",
    "    MAE = 10, MSE = 262, RMSE = 16.2\n",
    "```\n",
    "‚Üí MSE/RMSE **penalizzano molto** i grandi errori!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO: MAE vs MSE vs RMSE\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Simuliamo previsioni di prezzi immobiliari\n",
    "np.random.seed(42)\n",
    "\n",
    "y_true = np.array([200, 250, 180, 320, 275, 190, 400, 350, 220, 280])  # Prezzi reali (k‚Ç¨)\n",
    "y_pred = np.array([210, 240, 175, 310, 290, 200, 380, 340, 230, 270])  # Predizioni\n",
    "\n",
    "# Calcolo metriche\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä CONFRONTO METRICHE DI ERRORE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìå Dataset: Prezzi immobiliari (k‚Ç¨)\")\n",
    "print(f\"   - Campioni: {len(y_true)}\")\n",
    "print(f\"   - Prezzo medio reale: {y_true.mean():.1f}k‚Ç¨\")\n",
    "\n",
    "print(f\"\\nüìà Metriche:\")\n",
    "print(f\"   MAE  = {mae:.2f}k‚Ç¨  (errore medio assoluto)\")\n",
    "print(f\"   MSE  = {mse:.2f}k‚Ç¨¬≤ (errore quadratico medio)\")\n",
    "print(f\"   RMSE = {rmse:.2f}k‚Ç¨  (radice di MSE)\")\n",
    "\n",
    "# Visualizzazione errori\n",
    "errori = y_true - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predizioni vs Valori Reali\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_true, y_pred, s=100, alpha=0.7, c='steelblue', edgecolors='black')\n",
    "ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \n",
    "         'r--', linewidth=2, label='Predizione perfetta')\n",
    "ax1.set_xlabel('Prezzo Reale (k‚Ç¨)', fontsize=12)\n",
    "ax1.set_ylabel('Prezzo Predetto (k‚Ç¨)', fontsize=12)\n",
    "ax1.set_title('üéØ Predizioni vs Valori Reali', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuzione errori\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(range(len(errori)), errori, color=['green' if e >= 0 else 'red' for e in errori],\n",
    "               edgecolor='black', alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linewidth=1)\n",
    "ax2.axhline(y=mae, color='blue', linestyle='--', linewidth=2, label=f'MAE = {mae:.1f}')\n",
    "ax2.axhline(y=-mae, color='blue', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Campione', fontsize=12)\n",
    "ax2.set_ylabel('Errore (y_true - y_pred)', fontsize=12)\n",
    "ax2.set_title('üìä Distribuzione Errori', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretazione:\")\n",
    "print(f\"   - In media sbagliamo di {mae:.1f}k‚Ç¨ (MAE)\")\n",
    "print(f\"   - RMSE ({rmse:.1f}k‚Ç¨) > MAE ‚Üí ci sono errori pi√π grandi della media\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3aecec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ R¬≤ ‚Äî Coefficiente di Determinazione\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$$\n",
    "\n",
    "### Interpretazione\n",
    "\n",
    "| Valore R¬≤ | Significato |\n",
    "|-----------|-------------|\n",
    "| **1.0** | Predizione perfetta |\n",
    "| **0.8-1.0** | Ottimo |\n",
    "| **0.6-0.8** | Buono |\n",
    "| **0.4-0.6** | Moderato |\n",
    "| **< 0.4** | Scarso |\n",
    "| **< 0** | Peggio della media! |\n",
    "\n",
    "### Cosa Significa R¬≤?\n",
    "\n",
    "> **R¬≤ = 0.75** significa: \"Il modello spiega il 75% della varianza di y\"\n",
    "\n",
    "**Attenzione:** R¬≤ pu√≤ essere ingannevole!\n",
    "- Cresce sempre aggiungendo feature (usa **Adjusted R¬≤**)\n",
    "- Non indica se il modello √® corretto, solo quanto \"spiega\"\n",
    "- R¬≤ alto ‚â† buone predizioni (pu√≤ essere overfitting)\n",
    "\n",
    "### Adjusted R¬≤\n",
    "\n",
    "$$R^2_{adj} = 1 - (1 - R^2) \\cdot \\frac{n-1}{n-p-1}$$\n",
    "\n",
    "Dove p = numero di feature. Penalizza l'aggiunta di feature inutili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO: R¬≤ e Adjusted R¬≤\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Dataset sintetico\n",
    "X, y = make_regression(n_samples=100, n_features=5, n_informative=3, \n",
    "                       noise=10, random_state=42)\n",
    "\n",
    "# Modello\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# R¬≤\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# Adjusted R¬≤\n",
    "n = len(y)\n",
    "p = X.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä R¬≤ e ADJUSTED R¬≤\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìå Dataset:\")\n",
    "print(f\"   - Campioni: {n}\")\n",
    "print(f\"   - Feature: {p}\")\n",
    "print(f\"   - Feature informative reali: 3\")\n",
    "\n",
    "print(f\"\\nüìà Metriche:\")\n",
    "print(f\"   R¬≤     = {r2:.4f}\")\n",
    "print(f\"   R¬≤ adj = {r2_adj:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretazione:\")\n",
    "print(f\"   - Il modello spiega {r2*100:.1f}% della varianza\")\n",
    "print(f\"   - Adjusted R¬≤ penalizza le 2 feature non informative\")\n",
    "\n",
    "# Visualizzazione: cosa significa R¬≤\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predizioni vs Reali\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y, y_pred, alpha=0.6, s=50, c='steelblue', edgecolors='black')\n",
    "ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2, \n",
    "         label='Predizione perfetta')\n",
    "ax1.set_xlabel('Valore Reale', fontsize=12)\n",
    "ax1.set_ylabel('Valore Predetto', fontsize=12)\n",
    "ax1.set_title(f'üéØ R¬≤ = {r2:.3f}', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# R¬≤ con diversi livelli di rumore\n",
    "noise_levels = [5, 20, 50, 100, 200]\n",
    "r2_scores = []\n",
    "\n",
    "for noise in noise_levels:\n",
    "    X_temp, y_temp = make_regression(n_samples=100, n_features=3, n_informative=3,\n",
    "                                      noise=noise, random_state=42)\n",
    "    model_temp = LinearRegression()\n",
    "    model_temp.fit(X_temp, y_temp)\n",
    "    r2_scores.append(r2_score(y_temp, model_temp.predict(X_temp)))\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(len(noise_levels)), r2_scores, color='steelblue', edgecolor='black')\n",
    "ax2.set_xticks(range(len(noise_levels)))\n",
    "ax2.set_xticklabels([f'œÉ={n}' for n in noise_levels])\n",
    "ax2.set_xlabel('Livello di Rumore', fontsize=12)\n",
    "ax2.set_ylabel('R¬≤', fontsize=12)\n",
    "ax2.set_title('üìâ R¬≤ diminuisce con il rumore', fontsize=14)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, r in enumerate(r2_scores):\n",
    "    ax2.text(i, r + 0.02, f'{r:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc385f13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ MAPE ‚Äî Mean Absolute Percentage Error\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$MAPE = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|$$\n",
    "\n",
    "### Interpretazione\n",
    "\n",
    "| Aspetto | Descrizione |\n",
    "|---------|-------------|\n",
    "| **Cosa misura** | Errore percentuale medio |\n",
    "| **Unit√†** | Percentuale (%) |\n",
    "| **Range** | [0%, ‚àû) |\n",
    "| **Vantaggio** | Facilissimo da comunicare! |\n",
    "\n",
    "### Pro e Contro\n",
    "\n",
    "| ‚úÖ Pro | ‚ùå Contro |\n",
    "|--------|----------|\n",
    "| Intuitivo per il business | Non definito se y=0 |\n",
    "| Scala-indipendente | Asimmetrico (sovrastima errori su valori piccoli) |\n",
    "| Confrontabile tra dataset | Non usare se y pu√≤ essere 0 o negativo |\n",
    "\n",
    "### Esempio Business\n",
    "\n",
    "```\n",
    "MAPE = 8%\n",
    "```\n",
    "‚Üí \"In media, le nostre previsioni sbagliano dell'8%\"\n",
    "\n",
    "Questo lo capisce chiunque!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO: MAPE e confronto completo metriche\n",
    "# ============================================\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Usiamo il dataset prezzi di prima\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä MAPE ‚Äî ERRORE PERCENTUALE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MAPE\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred) * 100  # in percentuale\n",
    "\n",
    "print(f\"\\nüìå Dataset: Prezzi immobiliari\")\n",
    "print(f\"   Prezzo medio: {y_true.mean():.0f}k‚Ç¨\")\n",
    "\n",
    "print(f\"\\nüìà Metriche a confronto:\")\n",
    "print(f\"   MAE  = {mae:.2f}k‚Ç¨\")\n",
    "print(f\"   RMSE = {rmse:.2f}k‚Ç¨\")\n",
    "print(f\"   MAPE = {mape:.2f}%\")\n",
    "print(f\"   R¬≤   = {r2_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# Visualizzazione confronto\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Errore assoluto vs percentuale\n",
    "ax1 = axes[0]\n",
    "errori_abs = np.abs(y_true - y_pred)\n",
    "errori_perc = np.abs((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "x_pos = np.arange(len(y_true))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x_pos - width/2, errori_abs, width, label='Errore Assoluto (k‚Ç¨)', \n",
    "                color='steelblue', edgecolor='black')\n",
    "ax1_twin = ax1.twinx()\n",
    "bars2 = ax1_twin.bar(x_pos + width/2, errori_perc, width, label='Errore % ', \n",
    "                     color='coral', edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Campione', fontsize=12)\n",
    "ax1.set_ylabel('Errore Assoluto (k‚Ç¨)', color='steelblue', fontsize=12)\n",
    "ax1_twin.set_ylabel('Errore Percentuale (%)', color='coral', fontsize=12)\n",
    "ax1.set_title('üìä Errore Assoluto vs Percentuale', fontsize=14)\n",
    "\n",
    "# Legenda combinata\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "# Riepilogo metriche\n",
    "ax2 = axes[1]\n",
    "metriche = ['MAE\\n(k‚Ç¨)', 'RMSE\\n(k‚Ç¨)', 'MAPE\\n(%)', 'R¬≤']\n",
    "valori = [mae, rmse, mape, r2_score(y_true, y_pred) * 100]  # R¬≤ scalato per visualizzazione\n",
    "colori = ['#3498db', '#e74c3c', '#27ae60', '#9b59b6']\n",
    "\n",
    "bars = ax2.bar(metriche, valori, color=colori, edgecolor='black')\n",
    "ax2.set_ylabel('Valore', fontsize=12)\n",
    "ax2.set_title('üìä Riepilogo Metriche', fontsize=14)\n",
    "\n",
    "for bar, val in zip(bars, valori):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{val:.2f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Per il business:\")\n",
    "print(f\"   'Le nostre stime dei prezzi sbagliano in media del {mape:.1f}%'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8b277",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Analisi dei Residui\n",
    "\n",
    "### Cosa Sono i Residui?\n",
    "\n",
    "$$residuo_i = y_i - \\hat{y}_i$$\n",
    "\n",
    "I residui sono gli **errori** del modello. Analizzarli ci dice se il modello √® appropriato.\n",
    "\n",
    "### Residui Ideali\n",
    "\n",
    "Un buon modello ha residui che sono:\n",
    "\n",
    "| Propriet√† | Cosa Significa | Come Verificare |\n",
    "|-----------|----------------|-----------------|\n",
    "| **Media zero** | Nessun bias sistematico | mean(residui) ‚âà 0 |\n",
    "| **Omoscedastici** | Varianza costante | Scatter plot uniforme |\n",
    "| **Normali** | Distribuzione gaussiana | Q-Q plot, istogramma |\n",
    "| **Indipendenti** | No pattern | No trend nel tempo |\n",
    "\n",
    "### Segnali di Problemi\n",
    "\n",
    "| Pattern nei Residui | Problema | Soluzione |\n",
    "|---------------------|----------|-----------|\n",
    "| Trend (crescente/decrescente) | Manca una feature | Aggiungi variabili |\n",
    "| Forma a U o arco | Relazione non lineare | Trasformazioni, polinomi |\n",
    "| Cono (varianza crescente) | Eteroschedasticit√† | Log-trasformazione di y |\n",
    "| Cluster | Gruppi diversi | Modelli separati, dummy |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO: Analisi dei Residui\n",
    "# ============================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "# Creiamo un dataset con relazione lineare + rumore\n",
    "np.random.seed(42)\n",
    "X_simple = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_simple = 3 * X_simple.flatten() + 5 + np.random.normal(0, 2, 100)\n",
    "\n",
    "# Fit modello\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_simple, y_simple)\n",
    "y_pred_simple = model_simple.predict(X_simple)\n",
    "residui = y_simple - y_pred_simple\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä ANALISI DEI RESIDUI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìå Statistiche Residui:\")\n",
    "print(f\"   Media: {residui.mean():.4f} (ideale ‚âà 0)\")\n",
    "print(f\"   Std: {residui.std():.4f}\")\n",
    "print(f\"   Min: {residui.min():.2f}, Max: {residui.max():.2f}\")\n",
    "\n",
    "# Visualizzazione completa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Residui vs Predetti\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_pred_simple, residui, alpha=0.6, s=50, c='steelblue', edgecolors='black')\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Valori Predetti', fontsize=12)\n",
    "ax1.set_ylabel('Residui', fontsize=12)\n",
    "ax1.set_title('üìä Residui vs Predetti (deve essere casuale!)', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Q-Q Plot\n",
    "ax2 = axes[0, 1]\n",
    "stats.probplot(residui, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('üìà Q-Q Plot (deve seguire la linea)', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Istogramma residui\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(residui, bins=20, color='steelblue', edgecolor='black', alpha=0.7, density=True)\n",
    "# Overlay normale\n",
    "x_norm = np.linspace(residui.min(), residui.max(), 100)\n",
    "ax3.plot(x_norm, stats.norm.pdf(x_norm, residui.mean(), residui.std()), \n",
    "         'r-', linewidth=2, label='Normale teorica')\n",
    "ax3.set_xlabel('Residui', fontsize=12)\n",
    "ax3.set_ylabel('Densit√†', fontsize=12)\n",
    "ax3.set_title('üìä Distribuzione Residui (deve essere normale)', fontsize=14)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residui vs Ordine (sequenza)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(residui, 'o-', alpha=0.6, markersize=5, color='steelblue')\n",
    "ax4.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('Ordine Osservazione', fontsize=12)\n",
    "ax4.set_ylabel('Residui', fontsize=12)\n",
    "ax4.set_title('üìà Residui nel Tempo (no pattern!)', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test normalit√†\n",
    "_, p_value = stats.shapiro(residui)\n",
    "print(f\"\\nüìà Test di Shapiro-Wilk (normalit√†):\")\n",
    "print(f\"   p-value = {p_value:.4f}\")\n",
    "print(f\"   {'‚úÖ Residui normali (p > 0.05)' if p_value > 0.05 else '‚ùå Residui NON normali'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3cdf72",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Quando Usare Quale Metrica\n",
    "\n",
    "### Flowchart Decisionale\n",
    "\n",
    "```\n",
    "Quale metrica uso?\n",
    "        ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ Vuoi comunicare al business? ‚Üí MAPE (%)\n",
    "        ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ Vuoi penalizzare errori grandi? ‚Üí RMSE\n",
    "        ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ Vuoi robustezza agli outlier? ‚Üí MAE\n",
    "        ‚îÇ\n",
    "        ‚îú‚îÄ‚îÄ Vuoi confrontare modelli su scale diverse? ‚Üí R¬≤\n",
    "        ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ Vuoi diagnosticare il modello? ‚Üí Analisi Residui\n",
    "```\n",
    "\n",
    "### Tabella Riassuntiva\n",
    "\n",
    "| Metrica | Unit√† | Outlier | Uso Principale |\n",
    "|---------|-------|---------|----------------|\n",
    "| **MAE** | Come y | Robusto | Errore tipico |\n",
    "| **MSE** | y¬≤ | Sensibile | Ottimizzazione |\n",
    "| **RMSE** | Come y | Sensibile | Errore \"tipico\" pesato |\n",
    "| **MAPE** | % | Moderato | Comunicazione business |\n",
    "| **R¬≤** | Adimensionale | Moderato | Bont√† complessiva |\n",
    "\n",
    "### Regole Pratiche\n",
    "\n",
    "1. **Report al business** ‚Üí Usa MAPE (\"Sbagliamo del 5%\")\n",
    "2. **Confronto modelli** ‚Üí Usa RMSE o R¬≤\n",
    "3. **Dati con outlier** ‚Üí Preferisci MAE\n",
    "4. **Ottimizzazione** ‚Üí MSE (derivabile)\n",
    "5. **Sempre** ‚Üí Guarda i residui!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf435327",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† Schema Mentale ‚Äî Metriche di Regressione\n",
    "\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ    METRICHE DI REGRESSIONE         ‚îÇ\n",
    "                    ‚îÇ    \"Quanto sbaglio?\"               ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                   ‚îÇ\n",
    "         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "         ‚Üì                         ‚Üì                         ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ ERRORE ASSOLUTO ‚îÇ      ‚îÇ ERRORE RELATIVO ‚îÇ      ‚îÇ BONT√Ä MODELLO   ‚îÇ\n",
    "‚îÇ   MAE, RMSE     ‚îÇ      ‚îÇ     MAPE        ‚îÇ      ‚îÇ      R¬≤         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ                        ‚îÇ                        ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ MAE:    ‚îÇ              ‚îÇ MAPE:   ‚îÇ              ‚îÇ R¬≤:     ‚îÇ\n",
    "    ‚îÇ Robusto ‚îÇ              ‚îÇ Business‚îÇ              ‚îÇ 0-1     ‚îÇ\n",
    "    ‚îÇ k‚Ç¨, kg  ‚îÇ              ‚îÇ talking ‚îÇ              ‚îÇ Varianza‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ RMSE:   ‚îÇ\n",
    "    ‚îÇ Penaliz-‚îÇ\n",
    "    ‚îÇ za gross‚îÇ\n",
    "    ‚îÇ errori  ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddf271",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Esercizi Svolti\n",
    "\n",
    "### Esercizio 18.1 ‚Äî Report Completo su Dataset Boston-like\n",
    "\n",
    "**Obiettivo:** Valutare un modello di regressione sui prezzi delle case.\n",
    "\n",
    "**Consegne:**\n",
    "1. Genera un dataset di prezzi immobiliari\n",
    "2. Addestra una regressione lineare\n",
    "3. Calcola tutte le metriche: MAE, RMSE, MAPE, R¬≤\n",
    "4. Analizza i residui\n",
    "5. Produci un report testuale interpretabile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 18.1 ‚Äî SOLUZIONE COMPLETA\n",
    "# Report Completo Modello di Regressione\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESERCIZIO 18.1 ‚Äî Report Completo Modello di Regressione\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Generazione dataset immobiliare\n",
    "n_case = 500\n",
    "\n",
    "# Feature\n",
    "mq = np.random.normal(100, 30, n_case)  # Metri quadri\n",
    "stanze = np.random.randint(2, 6, n_case)  # Numero stanze\n",
    "eta = np.random.randint(0, 50, n_case)  # Et√† edificio\n",
    "distanza_centro = np.random.exponential(3, n_case)  # Km dal centro\n",
    "\n",
    "# Prezzo (target) = combinazione lineare + rumore\n",
    "prezzo = (\n",
    "    50000 +                    # Base\n",
    "    2000 * mq +               # ‚Ç¨2000/mq\n",
    "    15000 * stanze +          # ‚Ç¨15000/stanza\n",
    "    -500 * eta +              # -‚Ç¨500/anno di et√†\n",
    "    -8000 * distanza_centro + # -‚Ç¨8000/km dal centro\n",
    "    np.random.normal(0, 30000, n_case)  # Rumore\n",
    ")\n",
    "prezzo = np.clip(prezzo, 50000, None)  # Minimo 50k\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'mq': mq,\n",
    "    'stanze': stanze,\n",
    "    'eta_edificio': eta,\n",
    "    'km_centro': distanza_centro,\n",
    "    'prezzo': prezzo\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Dataset:\")\n",
    "print(df.describe().round(2))\n",
    "\n",
    "# 2. Split e addestramento\n",
    "X = df[['mq', 'stanze', 'eta_edificio', 'km_centro']]\n",
    "y = df['prezzo']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 3. Calcolo metriche\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Adjusted R¬≤\n",
    "n = len(y_test)\n",
    "p = X_test.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Residui\n",
    "residui = y_test - y_pred\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä REPORT VALUTAZIONE MODELLO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    METRICHE DI ERRORE                      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  MAE (Mean Absolute Error)     ‚îÇ  ‚Ç¨{mae:>15,.0f}          ‚îÇ\n",
    "‚îÇ  RMSE (Root Mean Squared Error)‚îÇ  ‚Ç¨{rmse:>15,.0f}          ‚îÇ\n",
    "‚îÇ  MAPE (Mean Absolute % Error)  ‚îÇ   {mape:>14.2f}%          ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                    BONT√Ä DEL MODELLO                       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  R¬≤ (Coefficiente Determinazione)  ‚îÇ     {r2:>10.4f}       ‚îÇ\n",
    "‚îÇ  R¬≤ Adjusted                       ‚îÇ     {r2_adj:>10.4f}       ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\")\n",
    "\n",
    "# 4. Analisi residui\n",
    "print(\"üìà ANALISI RESIDUI:\")\n",
    "print(f\"   Media residui: ‚Ç¨{residui.mean():,.0f} (ideale ‚âà 0)\")\n",
    "print(f\"   Std residui: ‚Ç¨{residui.std():,.0f}\")\n",
    "\n",
    "_, shapiro_p = stats.shapiro(residui.sample(min(50, len(residui)), random_state=42))\n",
    "print(f\"   Test normalit√† (Shapiro): p = {shapiro_p:.4f}\")\n",
    "\n",
    "# 5. Visualizzazione\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Predetti vs Reali\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_test, y_pred, alpha=0.5, s=30, c='steelblue', edgecolors='black')\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "ax1.set_xlabel('Prezzo Reale (‚Ç¨)', fontsize=12)\n",
    "ax1.set_ylabel('Prezzo Predetto (‚Ç¨)', fontsize=12)\n",
    "ax1.set_title(f'üéØ Predizioni vs Reali (R¬≤ = {r2:.3f})', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Residui vs Predetti\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_pred, residui, alpha=0.5, s=30, c='steelblue', edgecolors='black')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Prezzo Predetto (‚Ç¨)', fontsize=12)\n",
    "ax2.set_ylabel('Residui (‚Ç¨)', fontsize=12)\n",
    "ax2.set_title('üìä Residui vs Predetti', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuzione residui\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(residui, bins=30, color='steelblue', edgecolor='black', alpha=0.7, density=True)\n",
    "x_norm = np.linspace(residui.min(), residui.max(), 100)\n",
    "ax3.plot(x_norm, stats.norm.pdf(x_norm, residui.mean(), residui.std()), 'r-', linewidth=2)\n",
    "ax3.set_xlabel('Residui (‚Ç¨)', fontsize=12)\n",
    "ax3.set_ylabel('Densit√†', fontsize=12)\n",
    "ax3.set_title('üìä Distribuzione Residui', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Importanza coefficienti\n",
    "ax4 = axes[1, 1]\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficiente': model.coef_\n",
    "}).sort_values('Coefficiente', key=abs, ascending=True)\n",
    "\n",
    "colors = ['green' if c > 0 else 'red' for c in coef_df['Coefficiente']]\n",
    "ax4.barh(coef_df['Feature'], coef_df['Coefficiente'], color=colors, edgecolor='black')\n",
    "ax4.axvline(x=0, color='black', linewidth=1)\n",
    "ax4.set_xlabel('Coefficiente (‚Ç¨)', fontsize=12)\n",
    "ax4.set_title('üìä Coefficienti del Modello', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Report business\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã REPORT PER IL BUSINESS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "üìå SINTESI:\n",
    "   Il modello predice i prezzi con un errore medio del {mape:.1f}%.\n",
    "   In termini assoluti, l'errore tipico √® di ‚Ç¨{mae:,.0f}.\n",
    "   \n",
    "üìà INTERPRETAZIONE COEFFICIENTI:\n",
    "   ‚Ä¢ Ogni mq in pi√π: +‚Ç¨{model.coef_[0]:,.0f}\n",
    "   ‚Ä¢ Ogni stanza in pi√π: +‚Ç¨{model.coef_[1]:,.0f}\n",
    "   ‚Ä¢ Ogni anno di et√†: ‚Ç¨{model.coef_[2]:,.0f}\n",
    "   ‚Ä¢ Ogni km dal centro: ‚Ç¨{model.coef_[3]:,.0f}\n",
    "   \n",
    "‚úÖ QUALIT√Ä: R¬≤ = {r2:.2%} ‚Äî il modello spiega {r2:.0%} della variabilit√† dei prezzi.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05a9a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Esercizio 18.2 ‚Äî Confronto Modelli con Diverse Metriche\n",
    "\n",
    "**Obiettivo:** Confrontare 3 modelli di regressione usando metriche diverse.\n",
    "\n",
    "**Consegne:**\n",
    "1. Addestra Linear Regression, Ridge, Random Forest\n",
    "2. Calcola MAE, RMSE, MAPE, R¬≤ per ciascuno\n",
    "3. Visualizza il confronto\n",
    "4. Quale modello sceglieresti? Dipende dalla metrica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ab432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 18.2 ‚Äî SOLUZIONE COMPLETA\n",
    "# Confronto Modelli con Metriche Diverse\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESERCIZIO 18.2 ‚Äî Confronto Modelli di Regressione\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset (riuso quello dell'esercizio precedente)\n",
    "n_case = 500\n",
    "mq = np.random.normal(100, 30, n_case)\n",
    "stanze = np.random.randint(2, 6, n_case)\n",
    "eta = np.random.randint(0, 50, n_case)\n",
    "distanza_centro = np.random.exponential(3, n_case)\n",
    "\n",
    "prezzo = (50000 + 2000 * mq + 15000 * stanze - 500 * eta - 8000 * distanza_centro +\n",
    "          np.random.normal(0, 30000, n_case))\n",
    "prezzo = np.clip(prezzo, 50000, None)\n",
    "\n",
    "X = np.column_stack([mq, stanze, eta, distanza_centro])\n",
    "y = prezzo\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Definizione modelli\n",
    "modelli = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge (Œ±=1)': Ridge(alpha=1),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# 2. Training e valutazione\n",
    "risultati = []\n",
    "\n",
    "for nome, modello in modelli.items():\n",
    "    modello.fit(X_train, y_train)\n",
    "    y_pred = modello.predict(X_test)\n",
    "    \n",
    "    risultati.append({\n",
    "        'Modello': nome,\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'MAPE': mean_absolute_percentage_error(y_test, y_pred) * 100,\n",
    "        'R¬≤': r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_risultati = pd.DataFrame(risultati)\n",
    "\n",
    "print(\"\\nüìä RISULTATI:\")\n",
    "print(df_risultati.to_string(index=False))\n",
    "\n",
    "# 3. Visualizzazione\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metriche = ['MAE', 'RMSE', 'MAPE', 'R¬≤']\n",
    "titoli = ['üìä MAE (pi√π basso = meglio)', 'üìä RMSE (pi√π basso = meglio)', \n",
    "          'üìä MAPE % (pi√π basso = meglio)', 'üìä R¬≤ (pi√π alto = meglio)']\n",
    "colori = ['#3498db', '#e74c3c', '#27ae60']\n",
    "\n",
    "for idx, (metrica, titolo) in enumerate(zip(metriche, titoli)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    valori = df_risultati[metrica].values\n",
    "    \n",
    "    # Evidenzia il migliore\n",
    "    if metrica == 'R¬≤':\n",
    "        best_idx = np.argmax(valori)\n",
    "    else:\n",
    "        best_idx = np.argmin(valori)\n",
    "    \n",
    "    colors = ['green' if i == best_idx else colori[i] for i in range(len(valori))]\n",
    "    \n",
    "    bars = ax.bar(df_risultati['Modello'], valori, color=colors, edgecolor='black')\n",
    "    ax.set_ylabel(metrica, fontsize=12)\n",
    "    ax.set_title(titolo, fontsize=14)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Etichette\n",
    "    for bar, val in zip(bars, valori):\n",
    "        formato = f'{val:.2f}' if metrica in ['MAPE', 'R¬≤'] else f'{val:,.0f}'\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02 * max(valori),\n",
    "                formato, ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Analisi vincitori\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÜ ANALISI VINCITORI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "vincitori = {\n",
    "    'MAE': df_risultati.loc[df_risultati['MAE'].idxmin(), 'Modello'],\n",
    "    'RMSE': df_risultati.loc[df_risultati['RMSE'].idxmin(), 'Modello'],\n",
    "    'MAPE': df_risultati.loc[df_risultati['MAPE'].idxmin(), 'Modello'],\n",
    "    'R¬≤': df_risultati.loc[df_risultati['R¬≤'].idxmax(), 'Modello']\n",
    "}\n",
    "\n",
    "for metrica, vincitore in vincitori.items():\n",
    "    print(f\"   {metrica}: {vincitore}\")\n",
    "\n",
    "# Conta vittorie\n",
    "from collections import Counter\n",
    "conteggio = Counter(vincitori.values())\n",
    "vincitore_assoluto = conteggio.most_common(1)[0]\n",
    "\n",
    "print(f\"\\nüèÖ Vincitore assoluto: {vincitore_assoluto[0]} ({vincitore_assoluto[1]}/4 metriche)\")\n",
    "\n",
    "print(\"\\nüí° Nota:\")\n",
    "print(\"   Random Forest spesso vince perch√© cattura relazioni non lineari.\")\n",
    "print(\"   Ma √® pi√π lento e meno interpretabile della regressione lineare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a2368",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Esercizio 18.3 ‚Äî Diagnosi Modello con Residui Problematici\n",
    "\n",
    "**Obiettivo:** Identificare problemi in un modello attraverso l'analisi dei residui.\n",
    "\n",
    "**Consegne:**\n",
    "1. Crea un dataset con relazione NON lineare\n",
    "2. Fitta un modello lineare (sbagliato!)\n",
    "3. Analizza i residui e identifica il problema\n",
    "4. Correggi il modello e confronta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e371d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 18.3 ‚Äî SOLUZIONE COMPLETA\n",
    "# Diagnosi con Analisi Residui\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESERCIZIO 18.3 ‚Äî Diagnosi con Analisi Residui\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Creiamo dati con relazione QUADRATICA\n",
    "X = np.linspace(0, 10, 200).reshape(-1, 1)\n",
    "y_true_curve = 5 + 2*X.flatten() + 0.5*X.flatten()**2  # Relazione quadratica!\n",
    "y = y_true_curve + np.random.normal(0, 2, 200)\n",
    "\n",
    "print(\"\\nüìå Dataset: relazione QUADRATICA nascosta\")\n",
    "print(\"   y = 5 + 2x + 0.5x¬≤ + rumore\")\n",
    "\n",
    "# 2. Fittiamo un modello LINEARE (sbagliato!)\n",
    "model_lineare = LinearRegression()\n",
    "model_lineare.fit(X, y)\n",
    "y_pred_lin = model_lineare.predict(X)\n",
    "residui_lin = y - y_pred_lin\n",
    "\n",
    "r2_lin = r2_score(y, y_pred_lin)\n",
    "rmse_lin = np.sqrt(mean_squared_error(y, y_pred_lin))\n",
    "\n",
    "print(f\"\\nüìä Modello Lineare:\")\n",
    "print(f\"   R¬≤ = {r2_lin:.4f}\")\n",
    "print(f\"   RMSE = {rmse_lin:.4f}\")\n",
    "\n",
    "# 3. Visualizzazione problema\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Fit lineare\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(X, y, alpha=0.5, s=20, label='Dati')\n",
    "ax1.plot(X, y_pred_lin, 'r-', linewidth=2, label='Lineare')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('‚ùå Modello Lineare (sbagliato!)', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Residui vs X\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(X, residui_lin, alpha=0.5, s=20, c='red')\n",
    "ax2.axhline(y=0, color='black', linestyle='--')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Residui')\n",
    "ax2.set_title('‚ö†Ô∏è Residui: PATTERN A U!', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Residui vs Predetti\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(y_pred_lin, residui_lin, alpha=0.5, s=20, c='red')\n",
    "ax3.axhline(y=0, color='black', linestyle='--')\n",
    "ax3.set_xlabel('Predetti')\n",
    "ax3.set_ylabel('Residui')\n",
    "ax3.set_title('‚ö†Ô∏è Non casuali = problema!', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Correggiamo: modello POLINOMIALE\n",
    "model_poly = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "model_poly.fit(X, y)\n",
    "y_pred_poly = model_poly.predict(X)\n",
    "residui_poly = y - y_pred_poly\n",
    "\n",
    "r2_poly = r2_score(y, y_pred_poly)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y, y_pred_poly))\n",
    "\n",
    "print(f\"\\nüìä Modello Polinomiale (grado 2):\")\n",
    "print(f\"   R¬≤ = {r2_poly:.4f}\")\n",
    "print(f\"   RMSE = {rmse_poly:.4f}\")\n",
    "\n",
    "# Fit polinomiale\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(X, y, alpha=0.5, s=20, label='Dati')\n",
    "ax4.plot(X, y_pred_poly, 'g-', linewidth=2, label='Polinomiale')\n",
    "ax4.set_xlabel('X')\n",
    "ax4.set_ylabel('y')\n",
    "ax4.set_title('‚úÖ Modello Polinomiale (corretto!)', fontsize=12)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Residui corretti vs X\n",
    "ax5 = axes[1, 1]\n",
    "ax5.scatter(X, residui_poly, alpha=0.5, s=20, c='green')\n",
    "ax5.axhline(y=0, color='black', linestyle='--')\n",
    "ax5.set_xlabel('X')\n",
    "ax5.set_ylabel('Residui')\n",
    "ax5.set_title('‚úÖ Residui: casuali!', fontsize=12)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Confronto metriche\n",
    "ax6 = axes[1, 2]\n",
    "modelli = ['Lineare', 'Polinomiale']\n",
    "r2_vals = [r2_lin, r2_poly]\n",
    "colors = ['red', 'green']\n",
    "\n",
    "bars = ax6.bar(modelli, r2_vals, color=colors, edgecolor='black')\n",
    "ax6.set_ylabel('R¬≤')\n",
    "ax6.set_title('üìä Confronto R¬≤', fontsize=12)\n",
    "ax6.set_ylim(0, 1)\n",
    "\n",
    "for bar, val in zip(bars, r2_vals):\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{val:.3f}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Conclusione\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã DIAGNOSI COMPLETATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "‚ùå PROBLEMA IDENTIFICATO:\n",
    "   I residui del modello lineare mostravano un pattern a U.\n",
    "   Questo indica una relazione NON LINEARE nei dati.\n",
    "\n",
    "‚úÖ SOLUZIONE:\n",
    "   Usando un modello polinomiale (grado 2), i residui diventano\n",
    "   casuali e il R¬≤ passa da {r2_lin:.3f} a {r2_poly:.3f}.\n",
    "\n",
    "üí° LEZIONE:\n",
    "   SEMPRE analizzare i residui! Le metriche da sole non bastano.\n",
    "   Un R¬≤ discreto ({r2_lin:.2f}) pu√≤ nascondere un modello sbagliato.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd89e5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Conclusione e Bignami\n",
    "\n",
    "### ‚úÖ Cosa Abbiamo Imparato\n",
    "\n",
    "1. **MAE** ‚Äî errore medio assoluto, robusto agli outlier\n",
    "2. **RMSE** ‚Äî penalizza errori grandi, stessa unit√† di y\n",
    "3. **MAPE** ‚Äî errore percentuale, perfetto per il business\n",
    "4. **R¬≤** ‚Äî varianza spiegata, occhio all'interpretazione!\n",
    "5. **Residui** ‚Äî SEMPRE analizzarli per diagnosticare il modello\n",
    "\n",
    "---\n",
    "\n",
    "## üìã BIGNAMI ‚Äî Metriche di Regressione\n",
    "\n",
    "| Metrica | Formula | Unit√† | Outlier | Uso |\n",
    "|---------|---------|-------|---------|-----|\n",
    "| **MAE** | Œ£\\|y-≈∑\\|/n | Come y | Robusto | Errore tipico |\n",
    "| **MSE** | Œ£(y-≈∑)¬≤/n | y¬≤ | Sensibile | Ottimizzazione |\n",
    "| **RMSE** | ‚àöMSE | Come y | Sensibile | Errore penalizzato |\n",
    "| **MAPE** | Œ£\\|y-≈∑\\|/y/n | % | Moderato | Report business |\n",
    "| **R¬≤** | 1-SS_res/SS_tot | [-‚àû,1] | Moderato | Bont√† modello |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Checklist Valutazione Modello\n",
    "\n",
    "```\n",
    "‚ñ° Calcola MAE, RMSE, R¬≤ (minimo)\n",
    "‚ñ° Se per business ‚Üí aggiungi MAPE\n",
    "‚ñ° Plotta predetti vs reali (deve essere diagonale)\n",
    "‚ñ° Plotta residui vs predetti (deve essere casuale!)\n",
    "‚ñ° Controlla normalit√† residui (Q-Q plot)\n",
    "‚ñ° Confronta con baseline (media, modello semplice)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Codice Rapido di Riferimento\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "# Tutte le metriche in un colpo\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Adjusted R¬≤\n",
    "n, p = len(y), X.shape[1]\n",
    "r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Residui\n",
    "residui = y_true - y_pred\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Errori Comuni da Evitare\n",
    "\n",
    "| ‚ùå Errore | ‚úÖ Soluzione |\n",
    "|-----------|-------------|\n",
    "| Guardare solo R¬≤ | Analizza anche residui |\n",
    "| Ignorare MAPE | Usalo per comunicare |\n",
    "| Non plottare residui | Pattern = modello sbagliato |\n",
    "| R¬≤ alto = modello perfetto | Pu√≤ essere overfitting! |\n",
    "| Usare MSE per interpretare | Usa RMSE o MAE |\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Prossimi Passi\n",
    "Nella **Lezione 19** vedremo il **Clustering: K-Means e DBSCAN** ‚Äî algoritmi non supervisionati per scoprire gruppi nei dati!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
