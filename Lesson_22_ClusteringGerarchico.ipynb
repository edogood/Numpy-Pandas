{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb7c3c",
   "metadata": {},
   "source": [
    "# Lezione 22 - Clustering Gerarchico\n\n## Sezione 1 - Titolo e obiettivi\n\nObiettivo: imparare a usare il clustering gerarchico per scoprire gruppi senza fissare K a priori, leggendo dendrogrammi e scegliendo il linkage corretto.\n\n### Cosa impari\n- Costruire ed interpretare un dendrogramma.\n- Differenziare i metodi di linkage (single, complete, average, Ward).\n- Tagliare il dendrogramma per ottenere K cluster e valutarli con silhouette.\n- Confrontare gerarchico vs K-Means e capire quando usare l'uno o l'altro.\n\n### Perche serve\nSe non conosci K o vuoi una visione multi-granulare dei cluster, la gerarchia ti mostra tutte le partizioni possibili e ti permette di scegliere il livello piu utile.\n\n### Prerequisiti minimi\n- Conoscere K-Means e distanza euclidea (lezioni precedenti).\n- Sapere applicare StandardScaler.\n- Nozioni base di silhouette score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924e58c",
   "metadata": {},
   "source": [
    "## Sezione 2 - Teoria profonda\n\n### 1.1 Clustering gerarchico: agglomerativo vs divisivo\n- Agglomerativo (bottom-up): ogni punto e un cluster, poi unisci i due cluster piu simili fino a ottenerne uno solo. E l'approccio usato da sklearn.\n- Divisivo (top-down): parti da un unico cluster con tutti i punti e lo dividi iterativamente. Meno comune, non implementato in sklearn.\n\n### 1.2 Dendrogramma: la mappa delle fusioni\n- Asse Y: distanza/dissimilarita alla quale avviene l'unione.\n- Linee orizzontali: fusioni; piu sono alte, piu i cluster erano lontani.\n- Taglio orizzontale: determina il numero di cluster. Taglio alto = pochi cluster generali; taglio basso = molti cluster specifici.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea4408",
   "metadata": {},
   "source": [
    "### 1.3 Metodi di linkage (distanza tra cluster)\n\n| Linkage | Distanza tra cluster | Pro | Contro |\n|---------|---------------------|-----|--------|\n| Single | Distanza minima tra coppie | Rileva forme allungate | Effetto catena (unisce cluster lontani tramite punti ponte) |\n| Complete | Distanza massima tra coppie | Cluster compatti | Sensibile a outlier |\n| Average | Media di tutte le coppie | Compromesso | Piu costoso da intuire |\n| Ward | Aumento di varianza totale | Cluster bilanciati, simile a K-Means | Assume forma quasi sferica |\n\nFormule sintetiche (A, B cluster):\n- Single: $d=\\min_{a\\in A, b\\in B} d(a,b)$\n- Complete: $d=\\max_{a\\in A, b\\in B} d(a,b)$\n- Average: media di tutte le distanze tra i punti dei due cluster\n- Ward: minimizza l'incremento di varianza intra-cluster ($\\propto \\|\bar a-\bar b\\|$)\n\nRegola pratica: prova prima Ward; passa a complete/average se i cluster non sono sferici; evita single se sospetti l'effetto catena.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa59dd6",
   "metadata": {},
   "source": [
    "### 1.4 Confronto gerarchico vs K-Means\n\n| Aspetto | K-Means | Gerarchico |\n|---------|---------|------------|\n| K richiesto a priori | Si | No (lo scegli a posteriori) |\n| Complessita | O(n*K*iter) | O(n^2) o O(n^3) (meno scalabile) |\n| Forma cluster | Sferica | Dipende dal linkage |\n| Determinismo | No (init random) | Si (dato il linkage) |\n| Output | Etichette e centroidi | Albero (dendrogramma) e etichette |\n\nQuando usare gerarchico: dataset piccoli/medi (<10k), vuoi piu livelli di granularita, o esiste una gerarchia naturale. Quando usare K-Means: dataset grandi, hai un K ipotizzato, vuoi velocita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4dd0a1",
   "metadata": {},
   "source": [
    "### 1.5 Come leggere e tagliare un dendrogramma\n\n1) Osserva le altezze delle fusioni: gambe lunghe suggeriscono separazioni naturali.\n2) Decidi un'altezza di taglio: tagliando la linea orizzontale conti quante fusioni attraversi = numero di cluster.\n3) Valida con silhouette score e con il contesto (cluster interpretabili?).\n\nTaglio troppo alto -> pochi cluster (potresti perdere dettaglio). Taglio troppo basso -> molti cluster (rischio over-segmentazione).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee6aa",
   "metadata": {},
   "source": [
    "### 1.6 Gerarchia e silhouette\n\nSilhouette resta utile anche nel gerarchico:\n- Silhouette globale: qualita media della separazione tra cluster.\n- Silhouette plot per cluster: individua cluster sottili o con valori negativi.\n\nUsa silhouette per confrontare altezze di taglio (o valori di K) e scegliere il compromesso migliore tra separazione e interpretabilita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7df6f5",
   "metadata": {},
   "source": [
    "## Sezione 3 - Schema mentale e decision map\n\nWorkflow sintetico dopo lo scaling:\n\n```\nDATI SCALATI\n   |\n   +-- Calcola linkage (scipy.linkage) con metodo scelto\n   +-- Visualizza dendrogramma\n   +-- Scegli altezza di taglio (gambe lunghe, salti nelle fusioni)\n   +-- Estrai cluster (fcluster) o usa AgglomerativeClustering con K\n   +-- Valuta con silhouette e con il contesto\n   +-- Interpreta i cluster\n```\n\nChecklist rapida\n- [ ] Scaling applicato (StandardScaler).\n- [ ] Metodo di linkage scelto e motivato.\n- [ ] Dendrogramma letto (gambe lunghe e salti nelle fusioni).\n- [ ] Altezza di taglio decisa e numero di cluster verificato.\n- [ ] Silhouette calcolata e controllata per cluster deboli.\n- [ ] Cluster interpretati e rinominati in modo leggibile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9c89f",
   "metadata": {},
   "source": [
    "## Sezione 4 - Notebook dimostrativo\n\n### Perche questo passo (Demo 1 - Primo dendrogramma)\nCostruiamo il primo dendrogramma per capire cosa rappresentano distanze e taglio. Ci aspettiamo 3 cluster evidenti e gambe lunghe coerenti con i cluster generati.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904008db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Primo dendrogramma su dati sintetici (attesi 3 cluster)\n",
    "# Perche: vedere come il dendrogramma riflette le fusioni e dove tagliare.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "np.random.seed(42)\n",
    "X, y_true = make_blobs(n_samples=30, centers=3, cluster_std=0.8, random_state=42)\n",
    "assert X.ndim == 2, \"Atteso array 2D\"\n",
    "assert not np.isnan(X).any(), \"Dati con NaN\"\n",
    "\n",
    "# Scaling: rende le feature confrontabili\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "assert X_scaled.shape == X.shape, \"Shape inattesa dopo scaling\"\n",
    "\n",
    "# Calcolo linkage (Ward)\n",
    "Z = linkage(X_scaled, method='ward')\n",
    "assert Z.shape[0] == X_scaled.shape[0] - 1, \"Linkage deve avere n-1 fusioni\"\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} punti, {X.shape[1]} feature\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_true, cmap='viridis', s=80, edgecolors='black')\n",
    "axes[0].set_title('Dati scalati con cluster noti=3')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dendrogramma con linea di taglio suggerita\n",
    "line = dendrogram(Z, ax=axes[1], leaf_rotation=90, leaf_font_size=8)\n",
    "axes[1].axhline(y=5, color='red', linestyle='--', linewidth=2, label='Taglio suggerito')\n",
    "axes[1].set_xlabel('Indice punto (riordinato)')\n",
    "axes[1].set_ylabel('Distanza (Ward)')\n",
    "axes[1].set_title('Dendrogramma (Ward)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check atteso: gambe lunghe prima del taglio a 5 e circa 3 cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829ced5",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 2 - Confronto linkage)\nConfrontiamo single, complete, average, Ward sullo stesso dataset. Obiettivo: vedere differenze visive nei dendrogrammi e nei silhouette, e capire quando un metodo e preferibile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Confronto dei metodi di linkage sullo stesso dataset\n",
    "# Perche: mostrare differenze visive e di silhouette tra single/complete/average/Ward.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "assert 'X_scaled' in globals(), \"Esegui prima Demo 1 per creare X_scaled\"\n",
    "\n",
    "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    Z = linkage(X_scaled, method=method)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust')\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    dendrogram(Z, ax=axes[0, idx], leaf_rotation=90, leaf_font_size=6, truncate_mode='lastp', p=12)\n",
    "    axes[0, idx].set_title(f'{method.upper()} linkage')\n",
    "    axes[0, idx].set_xlabel('Cluster')\n",
    "    axes[0, idx].set_ylabel('Distanza')\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=70, edgecolors='black', alpha=0.8)\n",
    "    axes[1, idx].set_title(f'Silhouette={sil:.3f}')\n",
    "    axes[1, idx].set_xlabel('Feature 1')\n",
    "    axes[1, idx].set_ylabel('Feature 2')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for method in linkage_methods:\n",
    "    Z = linkage(X_scaled, method=method)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust')\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    note = {\n",
    "        'single': 'Rischio catena',\n",
    "        'complete': 'Cluster compatti',\n",
    "        'average': 'Compromesso',\n",
    "        'ward': 'Simile a K-Means'\n",
    "    }[method]\n",
    "    print(f\"{method:<10} silhouette={sil:.3f} note={note}\")\n",
    "\n",
    "# Check: atteso Ward con silhouette piu alta su cluster sferici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609eab6",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 3 - Effetto catena)\nMostriamo il limite del single linkage quando esiste un ponte di punti tra cluster. Obiettivo: riconoscere il sintomo (silhouette basso, cluster allungati) e preferire Ward/complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739baf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: Effetto catena del single linkage\n",
    "# Perche: mostrare come punti ponte possano far collassare due cluster separati con single linkage.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "np.random.seed(42)\n",
    "cluster1 = np.random.randn(30, 2) + np.array([-3, 0])\n",
    "cluster2 = np.random.randn(30, 2) + np.array([3, 0])\n",
    "ponte = np.array([[-2, 0], [-1, 0], [0, 0], [1, 0], [2, 0]])\n",
    "X_chain = np.vstack([cluster1, cluster2, ponte])\n",
    "X_chain_scaled = StandardScaler().fit_transform(X_chain)\n",
    "assert not np.isnan(X_chain_scaled).any(), \"NaN nei dati\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "for idx, method in enumerate(['single', 'ward']):\n",
    "    Z = linkage(X_chain_scaled, method=method)\n",
    "    labels = fcluster(Z, t=2, criterion='maxclust')\n",
    "    sil = silhouette_score(X_chain_scaled, labels)\n",
    "    dendrogram(Z, ax=axes[0, idx], truncate_mode='lastp', p=20, leaf_rotation=90, leaf_font_size=7)\n",
    "    axes[0, idx].set_title(f'Dendrogramma {method}')\n",
    "    axes[0, idx].set_xlabel('Cluster')\n",
    "    axes[0, idx].set_ylabel('Distanza')\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].scatter(X_chain_scaled[:, 0], X_chain_scaled[:, 1], c=labels, cmap='viridis', s=60, edgecolors='black', alpha=0.7)\n",
    "    axes[1, idx].scatter(X_chain_scaled[-5:, 0], X_chain_scaled[-5:, 1], c='orange', s=140, marker='s', edgecolors='black', label='Punti ponte')\n",
    "    axes[1, idx].set_title(f'{method.upper()} silhouette={sil:.3f}')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].legend()\n",
    "\n",
    "axes[0, 2].axis('off')\n",
    "axes[1, 2].text(0.5, 0.5,\n",
    "                \"Single usa la distanza minima:\n",
    "\n",
    "\"\n",
    "                \"Un ponte di pochi punti\n",
    "puo unire cluster lontani.\n",
    "\n",
    "\"\n",
    "                \"Ward minimizza la varianza\n",
    "quindi resiste all'effetto catena.\",\n",
    "                transform=axes[1, 2].transAxes, fontsize=11,\n",
    "                ha='center', va='center', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Conclusione: se esistono punti ponte, single linkage produce cluster allungati; preferire Ward/complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c8866",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 4 - Taglio del dendrogramma)\nMostriamo strategie pratiche per scegliere l'altezza di taglio: gambe lunghe, salti nelle distanze, confronto silhouette.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3178503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: Taglio del dendrogramma e scelta di K\n",
    "# Perche: mostrare metodi pratici (gambe lunghe e salti) per decidere K.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "X_multi, _ = make_blobs(n_samples=100, centers=4, cluster_std=[0.8, 1.0, 0.6, 1.2], center_box=(-10, 10), random_state=42)\n",
    "X_multi_scaled = StandardScaler().fit_transform(X_multi)\n",
    "assert not np.isnan(X_multi_scaled).any()\n",
    "\n",
    "Z = linkage(X_multi_scaled, method='ward')\n",
    "\n",
    "fusion_dist = Z[:, 2]\n",
    "jumps = np.diff(fusion_dist)\n",
    "max_jump_idx = int(np.argmax(jumps))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "dendrogram(Z, ax=axes[0], truncate_mode='lastp', p=25, leaf_rotation=90, leaf_font_size=7)\n",
    "axes[0].axhline(y=5, color='red', linestyle='--', label='Taglio esempio')\n",
    "axes[0].set_title('Dendrogramma (Ward)')\n",
    "axes[0].set_xlabel('Cluster')\n",
    "axes[0].set_ylabel('Distanza')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(range(len(jumps)), jumps, color='steelblue', alpha=0.7)\n",
    "axes[1].bar(max_jump_idx, jumps[max_jump_idx], color='red', alpha=0.8, label='Salto massimo')\n",
    "axes[1].set_title('Salti tra fusioni (aiuta a scegliere K)')\n",
    "axes[1].set_xlabel('Indice fusione')\n",
    "axes[1].set_ylabel('Delta distanza')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "labels = fcluster(Z, t=4, criterion='maxclust')\n",
    "sil = silhouette_score(X_multi_scaled, labels)\n",
    "print(f\"Taglio a 4 cluster -> silhouette={sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdcd84",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 5 - Caso ambiguo)\nDataset con cluster sovrapposti: nessun metodo fornisce un K univoco. Obiettivo: usare silhouette plot e principio di parsimonia (scegliere il K piu semplice e interpretabile).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89152c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 5: Caso ambiguo con cluster sovrapposti\n",
    "# Perche: vedere cosa fare quando silhouette non mostra un picco chiaro.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "X_hard, _ = make_blobs(n_samples=300, centers=5, cluster_std=1.8, random_state=42)\n",
    "X_hard_scaled = StandardScaler().fit_transform(X_hard)\n",
    "assert not np.isnan(X_hard_scaled).any()\n",
    "\n",
    "K_range_sil = range(2, 11)\n",
    "sil_scores_hard = []\n",
    "for k in K_range_sil:\n",
    "    km = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_scores_hard.append(silhouette_score(X_hard_scaled, labels))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "axes[0, 0].plot(K_range_sil, sil_scores_hard, 'go-')\n",
    "axes[0, 0].set_title('Silhouette (caso ambiguo)')\n",
    "axes[0, 0].set_xlabel('K')\n",
    "axes[0, 0].set_ylabel('Silhouette')\n",
    "axes[0, 0].axhline(y=0.25, color='orange', linestyle=':', alpha=0.6)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "Z_hard = linkage(X_hard_scaled, method='ward')\n",
    "dendrogram(Z_hard, ax=axes[0,1], truncate_mode='lastp', p=25, leaf_rotation=90, leaf_font_size=7)\n",
    "axes[0,1].set_title('Dendrogramma (caso ambiguo)')\n",
    "axes[0,1].set_xlabel('Cluster')\n",
    "axes[0,1].set_ylabel('Distanza')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "for idx, k in enumerate([3,4,5]):\n",
    "    km = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_vals = silhouette_samples(X_hard_scaled, labels)\n",
    "    y_lower = 10\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,k))\n",
    "    ax = axes[1, idx]\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        vals.sort()\n",
    "        size = len(vals)\n",
    "        y_upper = y_lower + size\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, vals, facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
    "        ax.text(-0.05, y_lower + size/2, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    ax.axvline(x=np.mean(sil_vals), color='red', linestyle='--')\n",
    "    ax.set_title(f'Silhouette plot K={k}')\n",
    "    ax.set_xlim([-0.1,1])\n",
    "    ax.set_xlabel('Silhouette score')\n",
    "    ax.set_ylabel('Cluster')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Se i metodi non concordano, preferisci il K piu parsimonioso e interpretabile (es. 3).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2384a",
   "metadata": {},
   "source": [
    "## Sezione 5 - Esercizi guidati (step by step)\n\n### Perche questo esercizio (22.1)\nEseguire un'analisi completa con dendrogramma, scelta di K, silhouette e interpretazione su dati medici. Obiettivo: applicare il flusso end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.1 - Analisi completa con dendrogramma\n",
    "# Obiettivo: seguire l'intero flusso (dendrogramma -> scelta K -> silhouette -> profili).\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "eta = [25, 30, 28, 65, 70, 68, 45, 48, 50, 22, 75, 42]\n",
    "pressione = [120, 125, 118, 145, 155, 150, 130, 135, 132, 115, 160, 128]\n",
    "colesterolo = [180, 190, 175, 240, 260, 250, 210, 215, 205, 170, 270, 200]\n",
    "\n",
    "df_pazienti = pd.DataFrame({\n",
    "    'paziente': [f'P{i}' for i in range(1, 13)],\n",
    "    'eta': eta,\n",
    "    'pressione': pressione,\n",
    "    'colesterolo': colesterolo\n",
    "})\n",
    "print(\"Dataset pazienti (head):\")\n",
    "print(df_pazienti.head())\n",
    "\n",
    "X_pazienti = df_pazienti[['eta', 'pressione', 'colesterolo']].values\n",
    "scaler = StandardScaler()\n",
    "X_pazienti_scaled = scaler.fit_transform(X_pazienti)\n",
    "assert X_pazienti_scaled.shape == X_pazienti.shape\n",
    "assert not np.isnan(X_pazienti_scaled).any()\n",
    "\n",
    "Z = linkage(X_pazienti_scaled, method='ward')\n",
    "\n",
    "fusion_dist = Z[:,2]\n",
    "jumps = np.diff(fusion_dist)\n",
    "max_jump_idx = int(np.argmax(jumps))\n",
    "K_suggerito = X_pazienti_scaled.shape[0] - max_jump_idx - 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
    "dendrogram(Z, ax=axes[0], labels=df_pazienti['paziente'].values, leaf_rotation=45)\n",
    "axes[0].axhline(y=fusion_dist[max_jump_idx], color='red', linestyle='--', label=f'K stimato ~{K_suggerito}')\n",
    "axes[0].set_title('Dendrogramma pazienti (Ward)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[1].bar(range(len(jumps)), jumps, color='steelblue')\n",
    "axes[1].bar(max_jump_idx, jumps[max_jump_idx], color='red', label='Salto massimo')\n",
    "axes[1].set_title('Salti nelle distanze')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "K_ottimale = 3\n",
    "labels = fcluster(Z, t=K_ottimale, criterion='maxclust') - 1\n",
    "sil = silhouette_score(X_pazienti_scaled, labels)\n",
    "print(f\"K scelto: {K_ottimale}, silhouette={sil:.3f}\")\n",
    "\n",
    "df_pazienti['cluster'] = labels\n",
    "print(\"Profili medi per cluster:\")\n",
    "print(df_pazienti.groupby('cluster')[['eta','pressione','colesterolo']].mean().round(1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "scatter = ax.scatter(df_pazienti['eta'], df_pazienti['colesterolo'], c=df_pazienti['cluster'], cmap='viridis', s=100, edgecolors='black')\n",
    "for _, row in df_pazienti.iterrows():\n",
    "    ax.annotate(row['paziente'], (row['eta']+1, row['colesterolo']+3), fontsize=8)\n",
    "ax.set_xlabel('Eta')\n",
    "ax.set_ylabel('Colesterolo')\n",
    "ax.set_title(f'Clustering pazienti (K={K_ottimale}, silhouette={sil:.3f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05237c0a",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (22.2)\nConfrontare i metodi di linkage su cluster di forme diverse. Obiettivo: scegliere il metodo migliore motivando con silhouette e struttura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.2 - Confronto metodi di linkage su forme diverse\n",
    "# Obiettivo: vedere quale linkage gestisce meglio cluster ellittici/compatti/sparsi.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "n1, n2, n3 = 20, 20, 20\n",
    "cluster1 = np.column_stack([\n",
    "    np.random.normal(0, 0.5, n1),\n",
    "    np.random.normal(0, 2.5, n1)\n",
    "])\n",
    "cluster2 = np.random.normal(loc=[5, 0], scale=0.5, size=(n2, 2))\n",
    "cluster3 = np.random.normal(loc=[2.5, 5], scale=1.5, size=(n3, 2))\n",
    "X_forme = np.vstack([cluster1, cluster2, cluster3])\n",
    "y_true = np.array([0]*n1 + [1]*n2 + [2]*n3)\n",
    "assert X_forme.shape[0] == 60\n",
    "\n",
    "X_forme_scaled = StandardScaler().fit_transform(X_forme)\n",
    "\n",
    "metodi = ['single', 'complete', 'average', 'ward']\n",
    "fig, axes = plt.subplots(2, 4, figsize=(17, 8))\n",
    "risultati = {}\n",
    "\n",
    "for idx, metodo in enumerate(metodi):\n",
    "    Z = linkage(X_forme_scaled, method=metodo)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust') - 1\n",
    "    sil = silhouette_score(X_forme_scaled, labels)\n",
    "    ari = adjusted_rand_score(y_true, labels)\n",
    "    risultati[metodo] = {'sil': sil, 'ari': ari}\n",
    "    dendrogram(Z, ax=axes[0, idx], truncate_mode='lastp', p=10, leaf_rotation=45, no_labels=True)\n",
    "    axes[0, idx].set_title(metodo.upper())\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].scatter(X_forme[:, 0], X_forme[:, 1], c=labels, cmap='viridis', s=50, edgecolors='black', alpha=0.8)\n",
    "    axes[1, idx].set_title(f'Sil={sil:.3f}, ARI={ari:.3f}')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"{'Metodo':<10} {'Silhouette':>12} {'ARI':>10}\")\n",
    "for m in metodi:\n",
    "    mark = '*' if m == max(risultati, key=lambda x: risultati[x]['sil']) else ' '\n",
    "    print(f\"{mark}{m:<9} {risultati[m]['sil']:>12.3f} {risultati[m]['ari']:>10.3f}\")\n",
    "\n",
    "best = max(risultati, key=lambda x: risultati[x]['sil'])\n",
    "worse = min(risultati, key=lambda x: risultati[x]['sil'])\n",
    "print(f\"Metodo migliore: {best.upper()} (silhouette {risultati[best]['sil']:.3f})\")\n",
    "print(f\"Metodo peggiore: {worse.upper()} (silhouette {risultati[worse]['sil']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb4ee0",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (22.3)\nApplicare AgglomerativeClustering di sklearn a clienti e-commerce testando diversi K e rinominando i cluster in modo interpretabile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f959719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.3 - AgglomerativeClustering su clienti e-commerce\n",
    "# Obiettivo: testare K diversi, scegliere quello con silhouette migliore e nominare i cluster.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "spesa_media = [50, 55, 48, 200, 250, 230, 120, 130, 125, 45, 280, 115]\n",
    "frequenza_acquisti = [2, 3, 2, 8, 10, 9, 5, 6, 5, 2, 12, 4]\n",
    "\n",
    "df_clienti = pd.DataFrame({\n",
    "    'cliente': [f'C{i}' for i in range(1, 13)],\n",
    "    'spesa_media': spesa_media,\n",
    "    'frequenza_acquisti': frequenza_acquisti\n",
    "})\n",
    "print(\"Dataset clienti (describe):\")\n",
    "print(df_clienti[['spesa_media','frequenza_acquisti']].describe().round(1))\n",
    "\n",
    "X_clienti = df_clienti[['spesa_media', 'frequenza_acquisti']].values\n",
    "X_clienti_scaled = StandardScaler().fit_transform(X_clienti)\n",
    "assert X_clienti_scaled.shape[0] == len(df_clienti)\n",
    "\n",
    "K_range = [2, 3, 4]\n",
    "risultati = {}\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, k in enumerate(K_range):\n",
    "    agg = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = agg.fit_predict(X_clienti_scaled)\n",
    "    sil = silhouette_score(X_clienti_scaled, labels)\n",
    "    risultati[k] = {'sil': sil, 'labels': labels}\n",
    "    axes[idx].scatter(df_clienti['spesa_media'], df_clienti['frequenza_acquisti'], c=labels, cmap='viridis', s=100, edgecolors='black', alpha=0.8)\n",
    "    for i, row in df_clienti.iterrows():\n",
    "        axes[idx].annotate(row['cliente'], (row['spesa_media']+3, row['frequenza_acquisti']+0.1), fontsize=8)\n",
    "    axes[idx].set_title(f'K={k}, silhouette={sil:.3f}')\n",
    "    axes[idx].set_xlabel('Spesa media (EUR)')\n",
    "    axes[idx].set_ylabel('Frequenza acquisti')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "K_ottimale = max(risultati, key=lambda x: risultati[x]['sil'])\n",
    "print(f\"K ottimale: {K_ottimale} (silhouette {risultati[K_ottimale]['sil']:.3f})\")\n",
    "\n",
    "df_clienti['cluster'] = risultati[K_ottimale]['labels']\n",
    "profili = df_clienti.groupby('cluster')[['spesa_media','frequenza_acquisti']].mean().round(1)\n",
    "print(\"Profili medi per cluster:\")\n",
    "print(profili)\n",
    "\n",
    "nomi_cluster = {}\n",
    "for cluster_id, row in profili.iterrows():\n",
    "    if row['spesa_media'] > 180 and row['frequenza_acquisti'] > 7:\n",
    "        nome = 'Premium alta spesa'\n",
    "    elif row['spesa_media'] > 90 and row['frequenza_acquisti'] > 4:\n",
    "        nome = 'Clienti fedeli'\n",
    "    else:\n",
    "        nome = 'Occasionali a bassa spesa'\n",
    "    nomi_cluster[cluster_id] = nome\n",
    "\n",
    "print(\"\n",
    "Nomi assegnati:\")\n",
    "for cid, nome in nomi_cluster.items():\n",
    "    clienti = ', '.join(df_clienti[df_clienti['cluster'] == cid]['cliente'].values)\n",
    "    print(f\"Cluster {cid}: {nome} -> {clienti}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(profili)))\n",
    "for cid in profili.index:\n",
    "    mask = df_clienti['cluster'] == cid\n",
    "    ax.scatter(df_clienti.loc[mask, 'spesa_media'], df_clienti.loc[mask, 'frequenza_acquisti'], c=[colors[cid]], s=140, edgecolors='black', alpha=0.85, label=nomi_cluster[cid])\n",
    "for i, row in df_clienti.iterrows():\n",
    "    ax.annotate(row['cliente'], (row['spesa_media']+3, row['frequenza_acquisti']+0.1), fontsize=8)\n",
    "ax.set_xlabel('Spesa media (EUR)')\n",
    "ax.set_ylabel('Frequenza acquisti')\n",
    "ax.set_title(f'AgglomerativeClustering (K={K_ottimale})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593432d",
   "metadata": {},
   "source": [
    "## Sezione 6 - Conclusione operativa\n\n### Cosa portarsi a casa\n- Il dendrogramma mostra tutte le fusioni: taglia dove trovi gambe lunghe e salti marcati nelle distanze.\n- Ward e un buon default; single soffre effetto catena; complete e average sono alternative se i cluster non sono sferici.\n- Valuta sempre il numero scelto di cluster con silhouette e con il contesto.\n\n### Methods explained (cosa fa, input/output, errori tipici, quando usarlo)\n- `StandardScaler`: standardizza feature (input array n_samples x n_features, output stessa shape); errori tipici: NaN o colonne costanti; usalo prima di misurare distanze.\n- `linkage` (scipy): costruisce matrice di fusioni; input X 2D, metodo; output matrice (n-1, 4); errori: NaN o metodo errato rispetto alla distanza; usalo per dendrogrammi.\n- `dendrogram` (scipy): visualizza la gerarchia; input matrice linkage; output grafico; errori: troppi campioni senza truncate_mode; usalo per leggere le gambe lunghe.\n- `fcluster` (scipy): estrae etichette tagliando la gerarchia; input linkage + soglia/numero cluster; output array 1D; errori: soglia incoerente; usalo per ottenere etichette.\n- `AgglomerativeClustering` (sklearn): clustering gerarchico senza dendrogramma; input X 2D, n_clusters, linkage; output labels 1D; errori: n_clusters > n_samples o NaN; usalo quando vuoi solo etichette.\n- `silhouette_score`: valuta separazione; input X 2D e labels 1D; output float; errori: meno di 2 cluster o cluster vuoto; usalo per confrontare tagli/valori di K.\n\n### Common errors and quick debug\n- Dati non scalati: distanze dominate da feature a scala grande. Fix: applica StandardScaler e ricontrolla.\n- Single linkage con punti ponte: cluster allungati e silhouette basso. Fix: passa a Ward/complete o rimuovi i punti ponte.\n- K scelto solo dal dendrogramma senza validazione: rischio cluster deboli. Fix: calcola silhouette e controlla i profili.\n- Molti campioni (n>10k) con dendrogramma completo: memoria/tempo elevati. Fix: campiona o usa metodi piu scalabili (es. K-Means).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f4b98",
   "metadata": {},
   "source": [
    "## Sezione 7 - End-of-lesson checklist e glossario\n\n### Checklist finale\n- [ ] Dati numerici scalati con `StandardScaler`.\n- [ ] Linkage calcolato con metodo motivato (Ward default).\n- [ ] Dendrogramma letto e altezza di taglio scelta osservando gambe lunghe/salti.\n- [ ] Cluster estratti con `fcluster` o `AgglomerativeClustering` e silhouette calcolata.\n- [ ] Cluster interpretati e rinominati con etichette leggibili.\n- [ ] Confronto rapido con K-Means se utile per valutare forma/varianza.\n\n### Glossario (termini usati)\n- Agglomerativo: fusione bottom-up di cluster.\n- Divisivo: divisione top-down di un cluster unico.\n- Dendrogramma: albero delle fusioni con distanza in asse Y.\n- Linkage: criterio di distanza tra cluster (single, complete, average, Ward).\n- Effetto catena: problema del single linkage con punti ponte.\n- Taglio: linea orizzontale che determina il numero di cluster.\n- fcluster: funzione scipy per estrarre etichette da un dendrogramma.\n- AgglomerativeClustering: implementazione sklearn del clustering gerarchico.\n- Silhouette score: misura di separazione media tra cluster.\n- Salto nelle distanze: differenza tra fusioni successive, aiuta a scegliere K.\n- Scalatura: standardizzazione delle feature prima delle distanze.\n- Cluster compatto: gruppo con bassa varianza interna.\n\n## Sezione 8 - Didactic changelog (max 10 voci)\n1. Riorganizzate le sezioni secondo lo schema 1-8 con obiettivi, teoria, schema mentale, demo ed esercizi.\n2. Pulito testo da emoji/caratteri non ASCII e allineato il tono ai notebook canonici.\n3. Aggiunte rationale e checkpoint a demo ed esercizi, con assert su shape/NaN.\n4. Integrati Methods explained, errori comuni, checklist e glossario nelle sezioni previste.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}