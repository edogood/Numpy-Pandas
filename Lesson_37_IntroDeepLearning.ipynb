{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "Lezione 37: Introduzione concettuale al Deep Learning con un MLP minimale.\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa concettuale della lezione\n",
    "\n",
    "```\n",
    "DEEP LEARNING - ARCHITETTURA MLP\n",
    "=================================\n",
    "\n",
    "INPUT LAYER         HIDDEN LAYER        OUTPUT LAYER\n",
    "(features)          (neuroni)           (prediction)\n",
    "\n",
    "  x₁ ──────┐                      \n",
    "           ├───►  h₁ = ReLU(W₁x + b₁)\n",
    "  x₂ ──────┤                            ──────► ŷ = σ(W₂h + b₂)\n",
    "           ├───►  h₂ = ReLU(W₁x + b₁)\n",
    "  x₃ ──────┘                      \n",
    "           └───►  h₃ = ReLU(W₁x + b₁)\n",
    "\n",
    "\n",
    "FORWARD PASS              BACKWARD PASS (BACKPROP)\n",
    "==============            ========================\n",
    "\n",
    "   X ────► W₁,b₁ ────► ReLU ────► W₂,b₂ ────► σ ────► Loss\n",
    "   \n",
    "           ◄──── dW₂ ◄──── dσ ◄──── dLoss\n",
    "           ◄──── dW₁ ◄──── dReLU ◄────────────────────────\n",
    "\n",
    "\n",
    "TRAINING LOOP\n",
    "=============\n",
    "   ┌─────────────────────────────────────────┐\n",
    "   │  for epoch in range(n_epochs):          │\n",
    "   │      ŷ = forward(X)         # predict   │\n",
    "   │      L = loss(y, ŷ)         # evaluate  │\n",
    "   │      grads = backward(L)    # gradient  │\n",
    "   │      W -= lr * grads        # update    │\n",
    "   └─────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi didattici\n",
    "\n",
    "| # | Obiettivo | Livello |\n",
    "|---|-----------|---------|\n",
    "| 1 | Comprendere architettura feed-forward (input → hidden → output) | Fondamentale |\n",
    "| 2 | Implementare forward pass con attivazioni non lineari | Operativo |\n",
    "| 3 | Capire backpropagation come chain rule applicata | Concettuale |\n",
    "| 4 | Confrontare MLP con baseline lineare | Valutativo |\n",
    "| 5 | Riconoscere overfitting e ruolo della complessita' | Critico |\n",
    "| 6 | Preparare transizione verso framework (PyTorch, TensorFlow) | Prospettiva |\n",
    "\n",
    "---\n",
    "\n",
    "## Concetti chiave\n",
    "\n",
    "> **Multilayer Perceptron (MLP)**: rete neurale feed-forward con uno o piu' hidden layer; ogni layer applica trasformazione lineare + attivazione non lineare.\n",
    "\n",
    "> **Backpropagation**: algoritmo che calcola i gradienti della loss rispetto ai pesi applicando la chain rule dal output verso l'input.\n",
    "\n",
    "> **Attivazione non lineare**: senza ReLU/tanh/sigmoid, composizione di layer lineari rimane lineare - nessun vantaggio su regressione logistica.\n",
    "\n",
    "---\n",
    "\n",
    "## Perche' \"deep\" funziona?\n",
    "\n",
    "```\n",
    "MODELLO LINEARE                    MLP (2 layer)\n",
    "===============                    ==============\n",
    "\n",
    "    y = Wx + b                     y = W₂ · ReLU(W₁x + b₁) + b₂\n",
    "\n",
    "    ┌──────────────┐               ┌──────────────┐\n",
    "    │ Decision     │               │ Decision     │\n",
    "    │ boundary:    │               │ boundary:    │\n",
    "    │   LINEA      │               │ CURVA/REGIONE│\n",
    "    └──────────────┘               └──────────────┘\n",
    "\n",
    "Non puo' separare                  Puo' separare\n",
    "dati non linearmente               dati non lineari\n",
    "separabili (es. XOR)               (es. moons, circles)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cosa useremo\n",
    "- `NumPy` per implementazione MLP da zero\n",
    "- `make_moons` per dataset non lineare\n",
    "- `LogisticRegression` come baseline\n",
    "- Funzioni di attivazione: ReLU, sigmoid\n",
    "\n",
    "## Prerequisiti\n",
    "- Regressione logistica (Lezione 06)\n",
    "- Derivate e chain rule\n",
    "- Concetto di loss function (log-loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- Reti feed-forward: composizione di layer lineari + attivazioni non lineari.\n",
    "- Backpropagation: calcolo gradiente per aggiornare i pesi con discesa del gradiente.\n",
    "- Bias-variance: reti piu' grandi possono overfittare; serve regolarizzare/early stopping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Definisci architettura (input-hidden-output) e attivazioni.\n",
    "2. Inizializza pesi piccoli.\n",
    "3. Forward -> loss -> backward -> update.\n",
    "4. Monitora loss train e (se disponibile) valida su hold-out.\n",
    "5. Confronta con baseline lineare per capire il contributo della non linearita'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Demo: MLP NumPy su two moons con poche epoche per mostrare convergenza parziale e confronto con modello lineare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset two moons\n",
    "X, y = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "X = X.T  # shape (2, n)\n",
    "y = y.reshape(1, -1)\n",
    "print(f\"Shape X: {X.shape}, y: {y.shape}\")\n",
    "assert X.shape[0] == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzioni di attivazione e helper\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_deriv(z):\n",
    "    return (z > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione pesi MLP (2 -> 3 -> 1)\n",
    "nh = 3\n",
    "W1 = 0.1 * np.random.randn(nh, 2)\n",
    "b1 = np.zeros((nh, 1))\n",
    "W2 = 0.1 * np.random.randn(1, nh)\n",
    "b2 = np.zeros((1, 1))\n",
    "alpha = 0.1\n",
    "epochs = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    Z1 = W1 @ X + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    m = y.shape[1]\n",
    "    loss = -np.mean(y * np.log(A2 + 1e-8) + (1 - y) * np.log(1 - A2 + 1e-8))\n",
    "    losses.append(loss)\n",
    "\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = (1/m) * dZ2 @ A1.T\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = W2.T @ dZ2\n",
    "    dZ1 = dA1 * relu_deriv(Z1)\n",
    "    dW1 = (1/m) * dZ1 @ X.T\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "\n",
    "print(f\"Loss finale: {losses[-1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione MLP vs baseline logistica\n",
    "A1 = relu(W1 @ X + b1)\n",
    "A2 = sigmoid(W2 @ A1 + b2)\n",
    "preds = (A2 > 0.5).astype(int)\n",
    "acc_mlp = accuracy_score(y.flatten(), preds.flatten())\n",
    "print(f\"Accuracy MLP: {acc_mlp:.3f}\")\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X.T, y.flatten())\n",
    "acc_lin = accuracy_score(y.flatten(), log_reg.predict(X.T))\n",
    "print(f\"Accuracy logistica (lineare): {acc_lin:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osservazioni\n",
    "- Il MLP con ReLU approssima il confine non lineare meglio della logistica lineare.\n",
    "- Poche epoche e nessuna regolarizzazione: possibile overfitting se si aumenta nh/epoche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (step-by-step)\n",
    "## Esercizio 37.1 - Variare hidden size\n",
    "Obiettivo: cambiare `nh` e confrontare la loss finale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 37.1\n",
    "for nh in [2, 4, 8]:\n",
    "    W1 = 0.1 * np.random.randn(nh, 2)\n",
    "    b1 = np.zeros((nh, 1))\n",
    "    W2 = 0.1 * np.random.randn(1, nh)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    for _ in range(1000):\n",
    "        Z1 = W1 @ X + b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = W2 @ A1 + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        m = y.shape[1]\n",
    "        dZ2 = A2 - y\n",
    "        dW2 = (1/m) * dZ2 @ A1.T\n",
    "        db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dA1 = W2.T @ dZ2\n",
    "        dZ1 = dA1 * relu_deriv(Z1)\n",
    "        dW1 = (1/m) * dZ1 @ X.T\n",
    "        db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        W2 -= alpha * dW2\n",
    "        b2 -= alpha * db2\n",
    "        W1 -= alpha * dW1\n",
    "    loss = -np.mean(y * np.log(A2 + 1e-8) + (1 - y) * np.log(1 - A2 + 1e-8))\n",
    "    print(f\"nh={nh}, loss={loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 37.2 - Attivazione tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 37.2\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_deriv(z):\n",
    "    return 1 - np.tanh(z)**2\n",
    "\n",
    "W1 = 0.1 * np.random.randn(nh, 2)\n",
    "b1 = np.zeros((nh, 1))\n",
    "W2 = 0.1 * np.random.randn(1, nh)\n",
    "b2 = np.zeros((1, 1))\n",
    "for _ in range(1000):\n",
    "    Z1 = W1 @ X + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = W2 @ A1 + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    m = y.shape[1]\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = (1/m) * dZ2 @ A1.T\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = W2.T @ dZ2\n",
    "    dZ1 = dA1 * tanh_deriv(Z1)\n",
    "    dW1 = (1/m) * dZ1 @ X.T\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    W1 -= alpha * dW1\n",
    "loss_tanh = -np.mean(y * np.log(A2 + 1e-8) + (1 - y) * np.log(1 - A2 + 1e-8))\n",
    "print(f\"Loss finale con tanh: {loss_tanh:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 37.3 - Baseline lineare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 37.3\n",
    "lin = LogisticRegression()\n",
    "lin.fit(X.T, y.flatten())\n",
    "acc_lin = accuracy_score(y.flatten(), lin.predict(X.T))\n",
    "print(f\"Accuracy baseline lineare: {acc_lin:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa - Bignami Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "## I 5 Take-Home Messages\n",
    "\n",
    "| # | Concetto | Perche' conta |\n",
    "|---|----------|---------------|\n",
    "| 1 | **MLP = Linear + Activation stacked** | Attivazioni non lineari danno potere espressivo |\n",
    "| 2 | **Backprop = chain rule sistematica** | Calcola gradienti per qualsiasi architettura |\n",
    "| 3 | **Piu' neuroni = piu' capacita' = piu' rischio overfitting** | Bilanciare complessita' con validazione |\n",
    "| 4 | **Learning rate critico** | Troppo alto diverge, troppo basso non converge |\n",
    "| 5 | **Baseline lineare obbligatoria** | MLP deve battere logistic/linear per giustificare complessita' |\n",
    "\n",
    "---\n",
    "\n",
    "## Architettura MLP - Componenti\n",
    "\n",
    "```\n",
    "COMPONENTE          RUOLO                       FORMULA\n",
    "==========          =====                       =======\n",
    "\n",
    "Pesi W              Trasformazione lineare      z = Wx + b\n",
    "Bias b              Offset per ogni neurone     \n",
    "\n",
    "Attivazione         Non linearita'              ReLU(z) = max(0, z)\n",
    "                                                σ(z) = 1/(1+e^-z)\n",
    "                                                tanh(z) = (e^z - e^-z)/(e^z + e^-z)\n",
    "\n",
    "Loss                Misura errore               L = -[y·log(ŷ) + (1-y)·log(1-ŷ)]\n",
    "\n",
    "Gradient            Direzione discesa           ∂L/∂W = ∂L/∂ŷ · ∂ŷ/∂z · ∂z/∂W\n",
    "\n",
    "Update              Aggiornamento pesi          W ← W - η · ∂L/∂W\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto attivazioni\n",
    "\n",
    "| Attivazione | Formula | Pro | Contro |\n",
    "|-------------|---------|-----|--------|\n",
    "| ReLU | max(0, z) | Veloce, no vanishing | Dead neurons |\n",
    "| Sigmoid | 1/(1+e^-z) | Output [0,1] | Vanishing gradient |\n",
    "| Tanh | (e^z-e^-z)/(e^z+e^-z) | Zero-centered | Vanishing gradient |\n",
    "| Leaky ReLU | max(0.01z, z) | No dead neurons | Ancora lineare per z<0 |\n",
    "\n",
    "---\n",
    "\n",
    "## Template MLP minimale\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=0.1):\n",
    "        # Xavier initialization\n",
    "        self.W1 = np.random.randn(hidden_dim, input_dim) * np.sqrt(2/input_dim)\n",
    "        self.b1 = np.zeros((hidden_dim, 1))\n",
    "        self.W2 = np.random.randn(output_dim, hidden_dim) * np.sqrt(2/hidden_dim)\n",
    "        self.b2 = np.zeros((output_dim, 1))\n",
    "        self.lr = lr\n",
    "    \n",
    "    def relu(self, z): return np.maximum(0, z)\n",
    "    def relu_grad(self, z): return (z > 0).astype(float)\n",
    "    def sigmoid(self, z): return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = self.W1 @ X + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = self.W2 @ self.a1 + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        dz2 = self.a2 - y\n",
    "        dW2 = (1/m) * dz2 @ self.a1.T\n",
    "        db2 = (1/m) * np.sum(dz2, axis=1, keepdims=True)\n",
    "        dz1 = (self.W2.T @ dz2) * self.relu_grad(self.z1)\n",
    "        dW1 = (1/m) * dz1 @ X.T\n",
    "        db1 = (1/m) * np.sum(dz1, axis=1, keepdims=True)\n",
    "        # Update\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "    \n",
    "    def fit(self, X, y, epochs=1000):\n",
    "        for _ in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e soluzioni\n",
    "\n",
    "| Errore | Conseguenza | Soluzione |\n",
    "|--------|-------------|-----------|\n",
    "| Learning rate troppo alto | Loss esplode/oscilla | Iniziare con 0.01, ridurre se instabile |\n",
    "| Nessuna normalizzazione input | Convergenza lenta | Standardizzare X prima del training |\n",
    "| Inizializzazione pesi grande | Saturazione attivazioni | Xavier o He initialization |\n",
    "| Nessuna baseline | Non sai se MLP serve | Confronta sempre con LogisticRegression |\n",
    "| Troppi neuroni su dati piccoli | Overfitting | Meno neuroni o regularizzazione |\n",
    "\n",
    "---\n",
    "\n",
    "## Metodi e concetti chiave\n",
    "\n",
    "| Elemento | Ruolo |\n",
    "|----------|-------|\n",
    "| Forward pass | Calcola predizioni |\n",
    "| Backward pass | Calcola gradienti |\n",
    "| Chain rule | Propaga errore attraverso layer |\n",
    "| Loss function | Misura distanza target-predizione |\n",
    "| Gradient descent | Aggiorna pesi verso minimo |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho definito architettura e attivazioni.\n",
    "- [ ] Ho verificato forme delle matrici e stabilita' del training.\n",
    "- [ ] Ho confrontato MLP con baseline lineare.\n",
    "- [ ] Ho monitorato loss/accuracy durante il training.\n",
    "- [ ] Ho valutato il rischio di overfitting con piu' neuroni/epoche.\n",
    "\n",
    "Glossario\n",
    "- MLP: multilayer perceptron.\n",
    "- ReLU/tanh: funzioni di attivazione non lineari.\n",
    "- Backpropagation: algoritmo per calcolare i gradienti.\n",
    "- Loss logistica: misura l'errore per classificazione binaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-01-XX | Struttura iniziale 8 sezioni |\n",
    "| 2.0 | 2024-12-XX | Espansione completa Deep Learning |\n",
    "| 2.1 | - | Architettura MLP con diagramma ASCII |\n",
    "| 2.2 | - | Training loop visualizzato (forward/backward) |\n",
    "| 2.3 | - | Spiegazione \"perche' deep funziona\" |\n",
    "| 2.4 | - | Confronto attivazioni (ReLU, sigmoid, tanh) |\n",
    "| 2.5 | - | Classe MLP template completa con backprop |\n",
    "| 2.6 | - | Errori comuni: LR, init, baseline |\n",
    "\n",
    "---\n",
    "\n",
    "## Note di versione\n",
    "\n",
    "**v2.0 - Espansione didattica completa**\n",
    "- Visualizzazione architettura MLP con flusso dati\n",
    "- Backpropagation spiegata come chain rule\n",
    "- Emphasis su confronto con baseline lineare\n",
    "- Template MLP riutilizzabile con Xavier init\n",
    "- Preparazione concettuale per framework (PyTorch/TF)\n",
    "\n",
    "**Dipendenze didattiche**\n",
    "- Richiede: Lezione 06 (regressione logistica), calcolo derivate\n",
    "- Prepara: Lezione 38 (modelli generativi), reti piu' complesse\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
