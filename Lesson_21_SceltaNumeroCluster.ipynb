{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1850e67c",
   "metadata": {},
   "source": [
    "# Lezione 21 - Scelta del Numero di Cluster\n\n## Sezione 1 - Titolo e obiettivi\n\nObiettivo della lezione: scegliere il numero di cluster K in modo sistematico, senza affidarsi al caso.\n\n### Cosa impari\n- Come interpretare inertia e il Metodo del Gomito.\n- Come calcolare e leggere Silhouette Score e Silhouette Plot.\n- Come applicare (anche manualmente) la Gap Statistic.\n- Come combinare piu criteri per scegliere K in modo robusto.\n\n### Perche serve\nK-Means funziona con qualsiasi K, ma solo alcuni valori rivelano la struttura dei dati. Una scelta errata produce cluster inutili o ingannevoli.\n\n### Prerequisiti minimi\n- Aver visto K-Means (Lezione 20): centroidi, inertia, sensibilita agli outlier.\n- Nozioni base di distanza euclidea e standardizzazione.\n\n### Outcome atteso\nAl termine saprai applicare piu metodi, leggerne i segnali, risolvere casi ambigui e motivare la scelta di K con spiegazioni chiare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977d27c",
   "metadata": {},
   "source": [
    "## Sezione 2 - Teoria profonda\n\n### 1.1 Perche scegliere K e critico\n- K troppo piccolo: cluster eterogenei, informazione persa.\n- K troppo grande: over-segmentazione, cluster senza significato.\n- K appropriato: gruppi stabili e interpretabili. K-Means non ti dice quale K usare: serve una metrica esterna.\n\n### 1.2 Approccio multi-criterio\nNessun metodo e perfetto. Combina piu segnali (Elbow, Silhouette, Gap, interpretabilita) e scegli il K piu semplice che resta coerente con il business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc96d9",
   "metadata": {},
   "source": [
    "### 1.3 Metodo del Gomito (Elbow)\n\n**Cosa misura**: l'inertia (WCSS) per K=1..K_max. L'inertia diminuisce sempre aumentando K.\n\n**Formula (ricordo)**: $\\text{Inertia} = \\sum_{k=1}^{K} \\sum_{x_i \\in C_k} \\|x_i - \\mu_k\\|^2$. E la somma delle distanze quadrate dai punti al proprio centroide.\n\n**Come si usa**\n1. Calcola inertia per una griglia di K.\n2. Traccia la curva inertia vs K.\n3. Cerca il gomito: dopo quel punto i miglioramenti sono marginali.\n\n**Quando e utile**: veloce, intuitivo, funziona bene con cluster ben separati. **Limite**: il gomito puo essere poco chiaro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cd9e1",
   "metadata": {},
   "source": [
    "### 1.4 Silhouette Score\n\n**Cosa misura**: quanto ogni punto e piu vicino al proprio cluster che agli altri.\n\n**Formula per un punto i**: $s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}$, dove:\n- $a(i)$ = distanza media di i dai punti del suo cluster (coesione).\n- $b(i)$ = distanza media di i dal cluster piu vicino (separazione).\n\n**Range e lettura**\n- Da -1 a +1.\n- Circa +1: punto ben assegnato; circa 0: al confine; negativo: probabilmente nel cluster sbagliato.\n\n**Score globale**: media di tutti i $s(i)$. Tipico: >0.7 ottimo, 0.5-0.7 buono, 0.25-0.5 moderato, <0.25 debole.\n\n**Quando usarlo**: per confrontare K diversi e per valutare qualita generale. Limite: tende a preferire K piccoli se i cluster sono sbilanciati.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431027db",
   "metadata": {},
   "source": [
    "### 1.5 Silhouette Plot\n\n**Cosa mostra**: distribuzione dei silhouette score per cluster. Scopre problemi che la media nasconde.\n\n**Come leggerlo**\n- Larghezza simile tra cluster: nessun gruppo minuscolo o schiacciato.\n- Pochi valori negativi: poche assegnazioni sbagliate.\n- Barre sopra la media globale: cluster solidi.\n\n**Quando usarlo**: sempre quando Elbow e Silhouette non concordano, o quando vuoi capire quale cluster e debole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329537e7",
   "metadata": {},
   "source": [
    "### 1.6 Gap Statistic\n\n**Idea**: confronta l'inertia dei dati reali con quella di dati uniformi random nello stesso range. Se i dati hanno struttura reale, l'inertia reale e molto piu bassa.\n\n**Definizione**: $\\text{Gap}(K) = \\mathbb{E}[\\log(W_K^*)] - \\log(W_K)$, dove $W_K$ e l'inertia sui dati e $W_K^*$ la media dell'inertia su B dataset random.\n\n**Scelta di K**: scegli il K piu piccolo tale che $\\text{Gap}(K) \\geq \\text{Gap}(K+1) - s_{K+1}$ (s_{K+1} = dev. standard delle simulazioni).\n\n**Quando usarla**: quando vuoi un criterio piu statistico. Limiti: piu costosa (molte simulazioni) e non inclusa nativamente in sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3a515",
   "metadata": {},
   "source": [
    "## Sezione 3 - Schema mentale e decision map\n\nWorkflow per scegliere K (dopo aver scalato i dati):\n\n```\nDATI SCALATI\n    |\n    +--> Elbow: trova il gomito (K1)\n    +--> Silhouette score: trova il massimo (K2)\n    +--> Silhouette plot: verifica cluster problematici\n    +--> Gap statistic (opzionale): verifica robustezza\n           |\n           v\n    I metodi concordano?\n      |               si          no\n      |          |\n      v          v\n   usa K1   preferisci il K piu semplice\n             (leggi silhouette plot e contesto)\n```\n\nChecklist decisionale rapida\n- Elbow calcolato e gomito identificabile? Se ambiguo, annotalo.\n- Silhouette calcolata per piu K? Confronta con Elbow.\n- Silhouette plot analizzato? Segna cluster sottili o con valori negativi.\n- Interpretabilita: il K scelto ha senso per il business? Se no, riduci K.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145948b",
   "metadata": {},
   "source": [
    "## Sezione 4 - Notebook dimostrativo\n\n### Perche questo passo (Demo 1 - Elbow)\nVogliamo vedere come l'inertia decresce con K su dati con 4 cluster noti. Ci aspettiamo un gomito vicino a K=4: un buon esempio di curva chiara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Elbow Method su dati sintetici (gomito atteso a K=4)\n",
    "# Intento: mostrare l'andamento dell'inertia e verificare dove la curva piega.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generiamo dati con 4 cluster ben separati\n",
    "np.random.seed(42)\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.8, random_state=42)\n",
    "assert X.ndim == 2 and X.shape[1] == 2, \"Atteso array 2D con 2 feature\"\n",
    "assert not np.isnan(X).any(), \"Dati contengono NaN\"\n",
    "\n",
    "# Scaling: StandardScaler rende confrontabili le feature\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "assert X_scaled.shape == X.shape, \"Shape inattesa dopo scaling\"\n",
    "\n",
    "# Calcoliamo inertia per K=1..10\n",
    "K_range = range(1, 11)\n",
    "inertias = []\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} punti, {X.shape[1]} feature. Inertia decresce con K: prime 3 {inertias[:3]}...\")\n",
    "\n",
    "# Visualizzazione curva Elbow e cluster veri\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('Numero di cluster (K)')\n",
    "axes[0].set_ylabel('Inertia (WCSS)')\n",
    "axes[0].set_title('Metodo del Gomito')\n",
    "axes[0].axvline(x=4, color='red', linestyle='--', linewidth=2, label='K atteso = 4')\n",
    "axes[0].scatter([4], [inertias[3]], color='red', zorder=5)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "scatter = axes[1].scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_true, cmap='viridis', s=40, alpha=0.7)\n",
    "axes[1].set_title('Dati sintetici (cluster noti = 4)')\n",
    "axes[1].set_xlabel('Feature 1 (scaled)')\n",
    "axes[1].set_ylabel('Feature 2 (scaled)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check qualitativo: ci aspettiamo un gomito netto intorno a K=4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6db970",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 2 - Silhouette score)\nUsiamo lo stesso dataset per confrontare Elbow e Silhouette. Ci aspettiamo che il massimo del silhouette cada su K=4, confermando il gomito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Silhouette Score su griglia di K (verifica concordanza con Elbow)\n",
    "# Intento: confrontare il picco del silhouette con il gomito dell'inertia.\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Sanity check sulla disponibilita di X_scaled\n",
    "assert 'X_scaled' in globals(), \"Esegui prima Demo 1 per generare e scalare i dati\"\n",
    "\n",
    "K_range_sil = range(2, 11)  # silhouette richiede almeno 2 cluster\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in K_range_sil:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "best_k = list(K_range_sil)[int(np.argmax(silhouette_scores))]\n",
    "best_score = max(silhouette_scores)\n",
    "print(f\"Miglior K per silhouette: {best_k} (score={best_score:.3f}). Atteso vicino a 4.\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(list(K_range_sil), silhouette_scores, 'go-', linewidth=2, markersize=6)\n",
    "axes[0].axvline(x=best_k, color='red', linestyle='--', linewidth=2, label=f'K migliore = {best_k}')\n",
    "axes[0].set_xlabel('Numero di cluster (K)')\n",
    "axes[0].set_ylabel('Silhouette score medio')\n",
    "axes[0].set_title('Silhouette score vs K')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "axes[0].axhline(y=0.5, color='orange', linestyle=':', alpha=0.6, label='Struttura buona (~0.5)')\n",
    "axes[0].axhline(y=0.25, color='grey', linestyle=':', alpha=0.6, label='Struttura debole (~0.25)')\n",
    "\n",
    "# Confronto Elbow (inertia) e Silhouette sullo stesso asse X\n",
    "ax2 = axes[1]\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2.plot(list(K_range), inertias, 'b-o', linewidth=2, markersize=6, label='Inertia (Elbow)')\n",
    "ax2_twin.plot(list(K_range_sil), silhouette_scores, 'g-s', linewidth=2, markersize=6, label='Silhouette')\n",
    "ax2.axvline(x=4, color='red', linestyle='--', alpha=0.7)\n",
    "ax2.set_xlabel('Numero di cluster (K)')\n",
    "ax2.set_ylabel('Inertia', color='blue')\n",
    "ax2_twin.set_ylabel('Silhouette', color='green')\n",
    "ax2.set_title('Confronto Elbow vs Silhouette')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticks(list(K_range))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check: ci aspettiamo concordanza tra gomito (K~4) e massimo silhouette (K~4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee9cef",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 3 - Silhouette plot)\nLa media del silhouette puo nascondere cluster deboli. Visualizziamo la distribuzione per K=3,4,5 per capire quale configurazione ha cluster piu equilibrati.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: Silhouette plot per valutare la qualita per cluster\n",
    "# Intento: controllare se singoli cluster risultano deboli per diversi K.\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "assert 'X_scaled' in globals(), \"Esegui prima le demo precedenti\"\n",
    "\n",
    "def plot_silhouette(X, n_clusters, ax, title):\n",
    "    '''\n",
    "    Disegna un silhouette plot per un dato K.\n",
    "    Input: X (array 2D), n_clusters (int), ax (Axes), title (str).\n",
    "    Output: (labels, silhouette_avg). Errori tipici: cluster vuoti o dati con NaN.\n",
    "    '''\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    sil_vals = silhouette_samples(X, labels)\n",
    "    sil_avg = silhouette_score(X, labels)\n",
    "    y_lower = 10\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n",
    "    for i in range(n_clusters):\n",
    "        cluster_vals = sil_vals[labels == i]\n",
    "        cluster_vals.sort()\n",
    "        size = cluster_vals.shape[0]\n",
    "        y_upper = y_lower + size\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_vals,\n",
    "                         facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
    "        ax.text(-0.05, y_lower + 0.5 * size, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    ax.axvline(x=sil_avg, color='red', linestyle='--', label=f'Media={sil_avg:.3f}')\n",
    "    ax.set_xlabel('Silhouette score')\n",
    "    ax.set_ylabel('Cluster')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.legend()\n",
    "    return labels, sil_avg\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Riga superiore: silhouette plots\n",
    "for idx, k in enumerate([3, 4, 5]):\n",
    "    plot_silhouette(X_scaled, k, axes[0, idx], f'Silhouette plot K={k}')\n",
    "\n",
    "# Riga inferiore: scatter per visualizzare cluster\n",
    "for idx, k in enumerate([3, 4, 5]):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    axes[1, idx].scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=40, alpha=0.7)\n",
    "    axes[1, idx].scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "                         c='red', marker='X', s=160, edgecolors='black', linewidths=1.5)\n",
    "    axes[1, idx].set_title(f'K={k}, silhouette={score:.3f}')\n",
    "    axes[1, idx].set_xlabel('Feature 1')\n",
    "    axes[1, idx].set_ylabel('Feature 2')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check: preferiamo K con barre larghe e poche zone negative; ci aspettiamo K=4 migliore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d63fd",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 4 - Gap statistic)\nIntroduciamo un criterio piu statistico per confrontare Elbow e Silhouette. Il gap mette a confronto i dati reali con dati uniformi random per capire se esiste davvero struttura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: Gap Statistic (implementazione manuale)\n",
    "# Intento: stimare K confrontando inertia reale con inertia su dati uniformi.\n",
    "\n",
    "assert 'X_scaled' in globals(), \"Esegui prima le demo precedenti\"\n",
    "\n",
    "def compute_gap_statistic(X, k_max=10, n_refs=10):\n",
    "    '''\n",
    "    Calcola Gap(K) per K=1..k_max.\n",
    "    Input: X array 2D scalato; k_max int; n_refs repliche random.\n",
    "    Output: gaps (list), sk (std list), optimal_k (int).\n",
    "    Errori tipici: k_max troppo grande rispetto a n_samples; presenza di NaN.\n",
    "    '''\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    gaps, sks = [], []\n",
    "    for k in range(1, k_max + 1):\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(X)\n",
    "        log_wk = np.log(km.inertia_)\n",
    "        ref_logs = []\n",
    "        for _ in range(n_refs):\n",
    "            X_rand = np.random.uniform(mins, maxs, size=X.shape)\n",
    "            km_ref = KMeans(n_clusters=k, random_state=None, n_init=10)\n",
    "            km_ref.fit(X_rand)\n",
    "            ref_logs.append(np.log(km_ref.inertia_))\n",
    "        ref_mean = np.mean(ref_logs)\n",
    "        ref_std = np.std(ref_logs) * np.sqrt(1 + 1/n_refs)\n",
    "        gaps.append(ref_mean - log_wk)\n",
    "        sks.append(ref_std)\n",
    "    optimal_k = 1\n",
    "    for k in range(1, k_max):\n",
    "        if gaps[k-1] >= gaps[k] - sks[k]:\n",
    "            optimal_k = k\n",
    "            break\n",
    "    return gaps, sks, optimal_k\n",
    "\n",
    "# Calcolo gap per il dataset sintetico\n",
    "k_max = 8\n",
    "gaps, sks, optimal_k = compute_gap_statistic(X_scaled, k_max=k_max, n_refs=8)\n",
    "print(f\"Gap statistic calcolata fino a K={k_max}. Primo K che soddisfa la regola: {optimal_k}\")\n",
    "\n",
    "# Visualizzazione gap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(range(1, k_max+1), gaps, 'mo-', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('Gap(K)')\n",
    "axes[0].set_title('Gap statistic')\n",
    "axes[0].axvline(x=optimal_k, color='red', linestyle='--', label=f'K ottimale = {optimal_k}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confronto normalizzato tra inertia, silhouette, gap\n",
    "inert_norm = (np.array(inertias) - np.min(inertias)) / (np.max(inertias) - np.min(inertias))\n",
    "sil_norm = (np.array(silhouette_scores) - np.min(silhouette_scores)) / (np.max(silhouette_scores) - np.min(silhouette_scores))\n",
    "gap_norm = (np.array(gaps) - np.min(gaps)) / (np.max(gaps) - np.min(gaps))\n",
    "axes[1].plot(range(1, len(inert_norm)+1), 1 - inert_norm, 'b-o', label='Inertia (ribaltata)')\n",
    "axes[1].plot(range(2, len(sil_norm)+2), sil_norm, 'g-s', label='Silhouette (norm)')\n",
    "axes[1].plot(range(1, len(gap_norm)+1), gap_norm, 'm-^', label='Gap (norm)')\n",
    "axes[1].axvline(x=4, color='red', linestyle='--', linewidth=2, label='K atteso=4')\n",
    "axes[1].set_xlabel('Numero di cluster (K)')\n",
    "axes[1].set_ylabel('Score (normalizzato)')\n",
    "axes[1].set_title('Confronto metodi (normalizzati)')\n",
    "axes[1].set_xticks(range(1, 11))\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check: Elbow, Silhouette e Gap dovrebbero suggerire K circa 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de72dc",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 5 - Caso ambiguo)\nMostriamo un dataset con cluster sovrapposti. Qui Elbow e Silhouette sono meno chiari: usiamo il silhouette plot e il principio di parsimonia per scegliere K.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911689e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 5: caso ambiguo con cluster sovrapposti\n",
    "# Intento: vedere cosa succede quando i metodi non danno un segnale netto.\n",
    "\n",
    "np.random.seed(42)\n",
    "X_hard, _ = make_blobs(n_samples=300, centers=5, cluster_std=1.8, random_state=42)\n",
    "X_hard_scaled = StandardScaler().fit_transform(X_hard)\n",
    "assert not np.isnan(X_hard_scaled).any(), \"Dati contengono NaN\"\n",
    "\n",
    "# Elbow e silhouette su dati difficili\n",
    "K_range = range(1, 11)\n",
    "inertias_hard = []\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_hard_scaled)\n",
    "    inertias_hard.append(km.inertia_)\n",
    "\n",
    "K_range_sil = range(2, 11)\n",
    "sil_scores_hard = []\n",
    "for k in K_range_sil:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_scores_hard.append(silhouette_score(X_hard_scaled, labels))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes[0, 0].plot(K_range, inertias_hard, 'bo-')\n",
    "axes[0, 0].set_title('Elbow su caso ambiguo')\n",
    "axes[0, 0].set_xlabel('K')\n",
    "axes[0, 0].set_ylabel('Inertia')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(list(K_range_sil), sil_scores_hard, 'go-')\n",
    "axes[0, 1].set_title('Silhouette su caso ambiguo')\n",
    "axes[0, 1].set_xlabel('K')\n",
    "axes[0, 1].set_ylabel('Silhouette')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=0.25, color='orange', linestyle=':', alpha=0.6)\n",
    "\n",
    "# Silhouette plot per K=3,4,5 per decidere\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "for idx, k in enumerate([3, 4, 5]):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_vals = silhouette_samples(X_hard_scaled, labels)\n",
    "    y_lower = 10\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "    ax = axes[1, idx]\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        vals.sort()\n",
    "        size = len(vals)\n",
    "        y_upper = y_lower + size\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, vals,\n",
    "                         facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
    "        ax.text(-0.05, y_lower + size/2, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    ax.axvline(x=np.mean(sil_vals), color='red', linestyle='--')\n",
    "    ax.set_title(f'Silhouette plot K={k}')\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.set_xlabel('Silhouette score')\n",
    "    ax.set_ylabel('Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Nota interpretativa: se i metodi non concordano, preferisci il K piu semplice (es. 3) salvo esigenze di business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f60d6",
   "metadata": {},
   "source": [
    "## Sezione 5 - Esercizi guidati (step by step)\n\n### Perche questo esercizio (21.1)\nCostruiamo una funzione riutilizzabile che combina Elbow e Silhouette in un unico report. Obiettivo: automatizzare i calcoli mantenendo i controlli di qualita (shape e NaN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86867d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 21.1 - funzione per Elbow + Silhouette\n",
    "# Intento: creare una funzione riutilizzabile con controlli base e grafico doppio asse.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def analisi_k_ottimale(X, k_min=2, k_max=10):\n",
    "    '''\n",
    "    Calcola inertia e silhouette per K in [k_min, k_max].\n",
    "    Input: X (array 2D scalato), k_min>=2, k_max>k_min.\n",
    "    Output: k_ottimale (int) secondo silhouette.\n",
    "    '''\n",
    "    assert X.ndim == 2, \"X deve essere 2D\"\n",
    "    assert not np.isnan(X).any(), \"X contiene NaN\"\n",
    "    K_range = range(k_min, k_max + 1)\n",
    "    inertias, silhouettes = [], []\n",
    "    for k in K_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X)\n",
    "        inertias.append(km.inertia_)\n",
    "        silhouettes.append(silhouette_score(X, labels))\n",
    "    k_ottimale = list(K_range)[int(np.argmax(silhouettes))]\n",
    "    best_sil = max(silhouettes)\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(list(K_range), inertias, 'bo-', label='Inertia (Elbow)')\n",
    "    ax2.plot(list(K_range), silhouettes, 'go-', label='Silhouette')\n",
    "    ax1.axvline(x=k_ottimale, color='red', linestyle='--', label=f'K ottimale = {k_ottimale}')\n",
    "    ax1.set_xlabel('K')\n",
    "    ax1.set_ylabel('Inertia', color='blue')\n",
    "    ax2.set_ylabel('Silhouette', color='green')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title('Elbow + Silhouette')\n",
    "    ax1.legend(loc='center right')\n",
    "    plt.xticks(list(K_range))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Report tabellare\n",
    "    print(f\"\n",
    "Risultati (k_min={k_min}, k_max={k_max}):\")\n",
    "    print(f\"{'K':<5} {'Inertia':<12} {'Silhouette':<12}\")\n",
    "    print('-'*32)\n",
    "    for k, inert, sil in zip(K_range, inertias, silhouettes):\n",
    "        marker = '<- migliore' if k == k_ottimale else ''\n",
    "        print(f\"{k:<5} {inert:<12.2f} {sil:<12.3f} {marker}\")\n",
    "    print(f\"\n",
    "Raccomandazione: K = {k_ottimale} (silhouette={best_sil:.3f})\")\n",
    "    return k_ottimale\n",
    "\n",
    "# Test rapido con dati sintetici a 3 cluster\n",
    "X_test, _ = make_blobs(n_samples=200, centers=3, cluster_std=0.8, random_state=42)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "assert X_test_scaled.shape[0] == 200\n",
    "k_risultato = analisi_k_ottimale(X_test_scaled, k_min=2, k_max=8)\n",
    "print(f\"Test: la funzione trova K={k_risultato} (atteso circa 3)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf125e",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (21.2)\nAlleniamo la lettura del silhouette plot: la funzione deve evidenziare cluster problematici (silhouette media bassa) e fornire statistiche sintetiche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d73ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 21.2 - funzione per silhouette plot dettagliato\n",
    "# Intento: evidenziare cluster problematici con silhouette media < 0.25.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def visualizza_silhouette_clusters(X, k):\n",
    "    '''\n",
    "    Disegna silhouette plot e restituisce statistiche per cluster.\n",
    "    Input: X (array 2D scalato), k (int >=2).\n",
    "    Output: dict cluster -> statistiche.\n",
    "    '''\n",
    "    assert X.ndim == 2, \"X deve essere 2D\"\n",
    "    assert not np.isnan(X).any(), \"X contiene NaN\"\n",
    "\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    sil_vals = silhouette_samples(X, labels)\n",
    "    sil_avg = silhouette_score(X, labels)\n",
    "\n",
    "    # Statistiche per cluster\n",
    "    cluster_stats = {}\n",
    "    print(f\"Cluster | N punti | Sil media | Sil min | Flag problema\")\n",
    "    print('-'*55)\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        stats = {\n",
    "            'n_punti': len(vals),\n",
    "            'sil_mean': vals.mean(),\n",
    "            'sil_min': vals.min(),\n",
    "            'sil_max': vals.max(),\n",
    "            'problematico': vals.mean() < 0.25\n",
    "        }\n",
    "        cluster_stats[i] = stats\n",
    "        flag = 'PROBLEMA' if stats['problematico'] else 'OK'\n",
    "        print(f\"{i:<7} {stats['n_punti']:<8} {stats['sil_mean']:<9.3f} {stats['sil_min']:<8.3f} {flag}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "    y_lower = 10\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        vals.sort()\n",
    "        size = len(vals)\n",
    "        y_upper = y_lower + size\n",
    "        axes[0].fill_betweenx(np.arange(y_lower, y_upper), 0, vals,\n",
    "                              facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
    "        axes[0].text(-0.05, y_lower + 0.5*size, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    axes[0].axvline(x=sil_avg, color='red', linestyle='--', label=f'Media={sil_avg:.3f}')\n",
    "    axes[0].axvline(x=0.25, color='orange', linestyle=':', label='Soglia 0.25')\n",
    "    axes[0].set_xlabel('Silhouette score')\n",
    "    axes[0].set_ylabel('Cluster')\n",
    "    axes[0].set_xlim([-0.2, 1])\n",
    "    axes[0].legend(loc='lower right')\n",
    "\n",
    "    axes[1].scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=40, alpha=0.7)\n",
    "    axes[1].scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "                    c='red', marker='X', s=160, edgecolors='black', linewidths=1.5)\n",
    "    axes[1].set_title(f'Cluster trovati (silhouette media={sil_avg:.3f})')\n",
    "    axes[1].set_xlabel('Feature 1')\n",
    "    axes[1].set_ylabel('Feature 2')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    problematici = [i for i, s in cluster_stats.items() if s['problematico']]\n",
    "    if problematici:\n",
    "        print(f\"Cluster problematici (silhouette media < 0.25): {problematici}\")\n",
    "    else:\n",
    "        print(\"Nessun cluster problematico individuato.\")\n",
    "    return cluster_stats\n",
    "\n",
    "# Test con cluster di dimensioni diverse\n",
    "np.random.seed(42)\n",
    "cluster1 = np.random.randn(150, 2) + np.array([0, 0])\n",
    "cluster2 = np.random.randn(30, 2) * 0.5 + np.array([5, 5])\n",
    "cluster3 = np.random.randn(70, 2) * 1.2 + np.array([2, 5])\n",
    "X_unbalanced = np.vstack([cluster1, cluster2, cluster3])\n",
    "X_unbalanced_scaled = StandardScaler().fit_transform(X_unbalanced)\n",
    "visualizza_silhouette_clusters(X_unbalanced_scaled, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0e19c",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (21.3)\nApplichiamo i metodi a un mini dataset reale (soddisfazione, frequenza, spesa). Obiettivo: seguire il flusso completo e motivare la scelta di K con dati e grafici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88916364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 21.3 - Analisi completa su mini dataset reale\n",
    "# Intento: seguire tutto il flusso (Elbow, Silhouette, plot) e motivare la scelta di K.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dati del sondaggio\n",
    "soddisfazione = [8,7,9,3,2,4,6,5,7,9,8,2,3,4,6,7,8,9,1,2]\n",
    "frequenza_acquisto = [5,4,6,1,2,1,3,3,4,5,6,1,1,2,3,4,5,6,1,1]\n",
    "spesa_mensile = [200,180,250,50,40,60,100,80,150,220,200,30,45,55,90,160,190,230,25,35]\n",
    "\n",
    "df_clienti = pd.DataFrame({\n",
    "    'soddisfazione': soddisfazione,\n",
    "    'frequenza': frequenza_acquisto,\n",
    "    'spesa': spesa_mensile\n",
    "})\n",
    "print(\"Dataset iniziale (describe):\")\n",
    "print(df_clienti.describe().round(1))\n",
    "\n",
    "# Scaling\n",
    "X_clienti = df_clienti.values\n",
    "scaler = StandardScaler()\n",
    "X_clienti_scaled = scaler.fit_transform(X_clienti)\n",
    "assert X_clienti_scaled.shape == X_clienti.shape\n",
    "\n",
    "# Elbow e silhouette per K=2..7\n",
    "K_range = range(2, 8)\n",
    "inertias, silhouettes = [], []\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_clienti_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_clienti_scaled, labels))\n",
    "    assert len(labels) == X_clienti_scaled.shape[0]\n",
    "\n",
    "best_k_sil = list(K_range)[int(np.argmax(silhouettes))]\n",
    "print(f\"Miglior K per silhouette: {best_k_sil}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_title('Elbow (dataset reale)')\n",
    "axes[0].set_xlabel('K')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(list(K_range))\n",
    "\n",
    "axes[1].plot(list(K_range), silhouettes, 'go-')\n",
    "axes[1].axvline(x=best_k_sil, color='red', linestyle='--', label=f'Migliore: K={best_k_sil}')\n",
    "axes[1].set_title('Silhouette score')\n",
    "axes[1].set_xlabel('K')\n",
    "axes[1].set_ylabel('Silhouette')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(list(K_range))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Silhouette plot per K candidati\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for idx, k in enumerate([2, 3, 4]):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_clienti_scaled)\n",
    "    sil_vals = silhouette_samples(X_clienti_scaled, labels)\n",
    "    sil_avg = silhouette_score(X_clienti_scaled, labels)\n",
    "    y_lower = 10\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        vals.sort()\n",
    "        size = len(vals)\n",
    "        y_upper = y_lower + size\n",
    "        axes[idx].fill_betweenx(np.arange(y_lower, y_upper), 0, vals,\n",
    "                                facecolor=colors[i], alpha=0.7)\n",
    "        axes[idx].text(-0.05, y_lower + size/2, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    axes[idx].axvline(x=sil_avg, color='red', linestyle='--')\n",
    "    axes[idx].axvline(x=0, color='black', linestyle='-')\n",
    "    axes[idx].set_xlim([-0.2, 1])\n",
    "    axes[idx].set_title(f'K={k} (avg={sil_avg:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decisione finale e profili cluster\n",
    "km_finale = KMeans(n_clusters=best_k_sil, random_state=42, n_init=10)\n",
    "df_clienti['cluster'] = km_finale.fit_predict(X_clienti_scaled)\n",
    "print(\"\n",
    "Cluster scelto:\", best_k_sil)\n",
    "print(\"Profili medi per cluster:\")\n",
    "print(df_clienti.groupby('cluster').mean().round(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3784dc5e",
   "metadata": {},
   "source": [
    "## Sezione 6 - Conclusione operativa\n\n### Cosa portarsi a casa\n- Elbow mostra rendimenti decrescenti dell'inertia: cerca il gomito, ma se e ambiguo passa alla silhouette.\n- Silhouette score identifica la separazione media: controlla sempre anche il silhouette plot per vedere i cluster deboli.\n- Gap statistic aiuta quando vuoi un controllo statistico aggiuntivo, ma ha costo computazionale maggiore.\n- In caso di disaccordo tra metodi, preferisci il K piu semplice e interpretabile.\n\n### Methods explained (input/output, quando usarli)\n- `StandardScaler`: standardizza features a media 0 e dev. std 1; input array (n_samples, n_features), output stessa shape; errore tipico: NaN o colonne costanti; usalo prima di K-Means.\n- `KMeans`: clustering con distanza euclidea; input array 2D, output etichette 1D; errori tipici: n_clusters > n_samples o dati con NaN; usalo con dati scalati e n_init >=10.\n- `silhouette_score`: media dei silhouette; input X 2D e labels 1D; output float; errore tipico: meno di 2 cluster o un cluster vuoto; usalo per confrontare K.\n- `silhouette_samples`: silhouette per punto; input X 2D e labels 1D; output array 1D; errore tipico: cluster vuoti; usalo per costruire silhouette plot.\n- `make_blobs`: genera dati sintetici; input n_samples, centers, cluster_std; output X e y; usalo per esempi controllati.\n\n### Common errors and quick debug\n- **Dati non scalati**: silhouette basso e cluster distorti. Soluzione: applica `StandardScaler` e ricontrolla.\n- **K troppo alto**: silhouette plot con cluster sottili e valori negativi. Soluzione: riduci K e verifica di nuovo.\n- **Gomito assente**: curva monotona senza piega. Soluzione: passa a silhouette e plot; scegli il K piu semplice che resta interpretabile.\n- **NaN nei dati**: KMeans fallisce. Soluzione: verifica `np.isnan(X).sum()` e ripulisci prima di scalare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b349374",
   "metadata": {},
   "source": [
    "## Sezione 7 - End-of-lesson checklist\n- [ ] Dati numerici e scalati con `StandardScaler`.\n- [ ] Elbow calcolato su una griglia di K e gomito valutato.\n- [ ] Silhouette score calcolato per piu K e confrontato con Elbow.\n- [ ] Silhouette plot letto per individuare cluster deboli o negativi.\n- [ ] Gap statistic (se usata) calcolata con almeno 5-10 repliche.\n- [ ] K scelto motivato con grafici + interpretabilita business.\n\n### Glossario (termini usati)\n- Inertia (WCSS): somma delle distanze quadrate ai centroidi.\n- Elbow Method: criterio grafico per trovare il gomito nella curva inertia.\n- Silhouette score: media della separazione relativa tra cluster.\n- Silhouette plot: grafico dei silhouette per cluster.\n- Gap statistic: confronto tra dati reali e uniformi per stimare K.\n- StandardScaler: standardizzazione feature-wise.\n- Centroide: media dei punti di un cluster.\n- n_init: numero di inizializzazioni di K-Means.\n- k-means++: inizializzazione che disperde i centroidi iniziali.\n- Over-segmentazione: troppi cluster con poco significato.\n- Parsimonia: scegliere il K piu semplice coerente con i dati.\n\n## Sezione 8 - Didactic changelog (max 10 voci)\n1. Riorganizzata la lezione nelle 8 sezioni obbligatorie con heading chiari.\n2. Ripulito il testo da emoji e caratteri non ASCII; chiarite le definizioni teoriche.\n3. Aggiunte rationale e micro-checkpoint a tutte le demo e agli esercizi 21.1-21.3.\n4. Inserite Methods explained, Common errors, Checklist e Glossario all'interno delle sezioni previste.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}