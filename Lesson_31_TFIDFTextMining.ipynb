{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb898b19",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "\n",
    "Lezione 31: TF-IDF e Text Mining - Pesare le parole per importanza\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa della lezione\n",
    "\n",
    "| Sezione | Contenuto | Tempo stimato |\n",
    "|---------|-----------|---------------|\n",
    "| 1 | Titolo, obiettivi, perché TF-IDF | 5 min |\n",
    "| 2 | Teoria: TF, IDF, formula, normalizzazione | 15 min |\n",
    "| 3 | Schema mentale: workflow TF-IDF | 5 min |\n",
    "| 4 | Demo: calcolo manuale, cosine similarity, classificazione | 30 min |\n",
    "| 5 | Esercizi guidati + keyword extraction | 15 min |\n",
    "| 6 | Conclusione operativa | 10 min |\n",
    "| 7 | Checklist di fine lezione + glossario | 5 min |\n",
    "| 8 | Changelog didattico | 2 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "| # | Obiettivo | Verifica |\n",
    "|---|-----------|----------|\n",
    "| 1 | Calcolare **TF-IDF manualmente** | Sai applicare la formula? |\n",
    "| 2 | Usare **TfidfVectorizer** di sklearn | Sai settare parametri? |\n",
    "| 3 | Misurare **similarità coseno** | Sai confrontare documenti? |\n",
    "| 4 | Confrontare **BoW vs TF-IDF** in classificazione | Sai interpretare F1? |\n",
    "| 5 | Estrarre **keyword** con coefficienti | Sai leggere coef_ di LogReg? |\n",
    "\n",
    "---\n",
    "\n",
    "## L'idea centrale: perché TF-IDF\n",
    "\n",
    "```\n",
    "PROBLEMA CON BOW:                    SOLUZIONE TF-IDF:\n",
    "\n",
    "\"the\" appare 50 volte                \"the\" ha IDF basso\n",
    "→ peso 50 (troppo alto!)             → peso finale basso\n",
    "\n",
    "\"algorithm\" appare 2 volte           \"algorithm\" ha IDF alto  \n",
    "→ peso 2 (troppo basso!)             → peso finale alto\n",
    "\n",
    "TF-IDF = TF × IDF\n",
    "       = frequenza locale × rarità globale\n",
    "```\n",
    "\n",
    "**Intuizione:** parole rare ma presenti = importanti!\n",
    "\n",
    "---\n",
    "\n",
    "## La formula TF-IDF\n",
    "\n",
    "```\n",
    "TF(t, d) = numero occorrenze di t in documento d\n",
    "           ─────────────────────────────────────\n",
    "           totale parole in d (opzionale)\n",
    "\n",
    "IDF(t) = log( N / (1 + df(t)) )\n",
    "         dove N = numero documenti, df(t) = documenti con t\n",
    "\n",
    "TF-IDF(t, d) = TF(t, d) × IDF(t)\n",
    "\n",
    "Normalizzazione L2: divide ogni vettore per la sua norma\n",
    "→ tutti i documenti hanno \"lunghezza\" 1\n",
    "→ confronto equo tra doc lunghi e corti\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Similarità coseno: confrontare documenti\n",
    "\n",
    "```\n",
    "         doc A                    doc B\n",
    "           ↗                        ↗\n",
    "          /                        /\n",
    "         / θ (angolo)             /\n",
    "        ╱─────────────────────────╱\n",
    "       origine\n",
    "\n",
    "cosine(A, B) = (A · B) / (||A|| × ||B||)\n",
    "\n",
    "Valori:\n",
    "- 1.0 = identici (angolo = 0°)\n",
    "- 0.0 = ortogonali (angolo = 90°)\n",
    "- -1.0 = opposti (raro in NLP)\n",
    "```\n",
    "\n",
    "**Uso tipico:** ranking documenti simili, ricerca, deduplicazione.\n",
    "\n",
    "---\n",
    "\n",
    "## BoW vs TF-IDF: quando usare cosa\n",
    "\n",
    "| Aspetto | BoW | TF-IDF |\n",
    "|---------|-----|--------|\n",
    "| **Formula** | Conteggi raw | Conteggi × IDF |\n",
    "| **Parole comuni** | Peso alto | Peso basso |\n",
    "| **Parole rare** | Peso basso | Peso alto |\n",
    "| **Classificazione** | OK su testi corti | Meglio su testi lunghi |\n",
    "| **Velocità** | Leggermente più veloce | Simile |\n",
    "| **Interpretabilità** | Diretta (conteggio) | Indiretta (peso) |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "| Concetto | Dove lo trovi | Verifica |\n",
    "|----------|---------------|----------|\n",
    "| Bag of Words | Lezione 30 | Sai usare CountVectorizer? |\n",
    "| Matrici sparse | scipy | Sai cos'è CSR? |\n",
    "| Classificazione testo | Lezione 30 | Sai usare MultinomialNB? |\n",
    "| Regressione logistica | Lezioni 5-6 | Sai leggere coef_? |\n",
    "\n",
    "**Cosa useremo:** CountVectorizer, TfidfVectorizer, cosine_similarity, MultinomialNB, LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f83642",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale\n",
    "- TF (term frequency): quante volte appare una parola in un documento.\n",
    "- IDF (inverse document frequency): quanto la parola e' rara nel corpus; piu' rara = peso maggiore.\n",
    "- TF-IDF = TF * IDF con normalizzazione L2 per confrontare documenti di lunghezza diversa.\n",
    "- Similarita' coseno: misura di vicinanza tra vettori TF-IDF (0=ortogonali, 1=identici).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0c6a0",
   "metadata": {},
   "source": [
    "## Quando usare TF-IDF vs BoW\n",
    "- TF-IDF: preferibile per classificazione/testo lungo per attenuare parole frequenti poco informative.\n",
    "- BoW: semplice e veloce su testi brevi/lessico limitato.\n",
    "- Entrambi richiedono vocabolario fissato sul training e `transform` sui nuovi dati.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e100b",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Pulisci e tokenizza testi (minuscolo, punteggiatura, stopword).\n",
    "2. Scelta rappresentazione: BoW se vocab piccolo, TF-IDF se vuoi pesi informativi.\n",
    "3. Calcola similarita' coseno per confronti/ricerca.\n",
    "4. Per classificazione: split train/test, prova BoW e TF-IDF, confronta metriche.\n",
    "5. Per interpretazione: usa pesi/coef per estrarre keyword per classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a871b",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "- Demo 1: calcolo manuale TF-IDF e verifica con sklearn.\n",
    "- Demo 2: similarita' coseno tra documenti.\n",
    "- Demo 3: confronto BoW vs TF-IDF in classificazione testi.\n",
    "- Demo 4: parole piu' importanti per classe con Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648ba27",
   "metadata": {},
   "source": [
    "## Demo 1 - Calcolo manuale TF-IDF\n",
    "Perche': capire le formule prima di usare il vectorizer. Checkpoint: stesse forme e valori simili a sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60143224",
   "metadata": {},
   "source": [
    "## Demo 2 - Similarita' coseno\n",
    "Perche': misurare vicinanza tra documenti nello spazio TF-IDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1b078",
   "metadata": {},
   "source": [
    "## Demo 3 e 4 - Classificazione e interpretazione\n",
    "Perche': confrontare BoW vs TF-IDF su sentiment e leggere le parole piu' influenti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "corpus = [\n",
    "    \"il gatto mangia il pesce\",\n",
    "    \"il cane mangia la carne\",\n",
    "    \"il gatto dorme sul divano\",\n",
    "    \"il cane gioca nel parco\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d47ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: calcolo manuale TF-IDF - vocabolario e token\n",
    "print(\"Manuale TF-IDF: vocabolario e token\")\n",
    "all_words = set()\n",
    "tokenized_docs = []\n",
    "for doc in corpus:\n",
    "    tokens = doc.split()\n",
    "    tokenized_docs.append(tokens)\n",
    "    all_words.update(tokens)\n",
    "vocab = sorted(all_words)\n",
    "print(f\"Vocab: {vocab}\")\n",
    "N = len(corpus)\n",
    "V = len(vocab)\n",
    "assert V > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: matrice TF (conteggi)\n",
    "word_to_idx = {w:i for i,w in enumerate(vocab)}\n",
    "tf_matrix = np.zeros((N, V))\n",
    "for d_i, tokens in enumerate(tokenized_docs):\n",
    "    for t in tokens:\n",
    "        tf_matrix[d_i, word_to_idx[t]] += 1\n",
    "print(\"TF grezzi:\", pd.DataFrame(tf_matrix, columns=vocab))\n",
    "assert tf_matrix.shape == (N, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab662439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: IDF\n",
    "# df = in quanti documenti appare il termine\n",
    "df_counts = np.sum(tf_matrix > 0, axis=0)\n",
    "idf_values = np.log((N + 1) / (df_counts + 1)) + 1\n",
    "idf_df = pd.DataFrame({'parola': vocab, 'df': df_counts, 'idf': idf_values})\n",
    "print(idf_df)\n",
    "assert idf_values.shape[0] == V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: TF-IDF e normalizzazione L2\n",
    "# TF-IDF non normalizzato\n",
    "tfidf_matrix = tf_matrix * idf_values\n",
    "# normalizzazione riga per riga\n",
    "norms = np.linalg.norm(tfidf_matrix, axis=1, keepdims=True)\n",
    "tfidf_norm = tfidf_matrix / norms\n",
    "print(pd.DataFrame(tfidf_norm.round(3), columns=vocab))\n",
    "assert tfidf_norm.shape == (N, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19240f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: verifica con sklearn\n",
    "vec_tfidf = TfidfVectorizer()\n",
    "X_skl = vec_tfidf.fit_transform(corpus)\n",
    "vocab_skl = vec_tfidf.get_feature_names_out()\n",
    "df_skl = pd.DataFrame(X_skl.toarray().round(3), columns=vocab_skl)\n",
    "print(df_skl)\n",
    "assert df_skl.shape[1] == len(vocab_skl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: similarita' coseno\n",
    "sim_matrix = cosine_similarity(X_skl)\n",
    "df_sim = pd.DataFrame(sim_matrix.round(3), index=[f\"D{i+1}\" for i in range(N)], columns=[f\"D{i+1}\" for i in range(N)])\n",
    "print(df_sim)\n",
    "assert df_sim.shape == (N, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: dataset di sentiment per confronto BoW vs TF-IDF\n",
    "recensioni = [\n",
    "    (\"Prodotto eccezionale, lo consiglio a tutti\", 1),\n",
    "    (\"Ottimo acquisto, sono molto soddisfatto\", 1),\n",
    "    (\"Qualita superiore, prezzo giusto\", 1),\n",
    "    (\"Spedizione veloce, prodotto perfetto\", 1),\n",
    "    (\"Fantastico, supera le aspettative\", 1),\n",
    "    (\"Pessimo, arrivato rotto\", 0),\n",
    "    (\"Non funziona, soldi sprecati\", 0),\n",
    "    (\"Esperienza terribile, non comprare\", 0),\n",
    "    (\"Prodotto difettoso e assistenza assente\", 0),\n",
    "    (\"Deluso, qualita bassa\", 0)\n",
    "]\n",
    "texts, labels = zip(*recensioni)\n",
    "X_train_txt, X_test_txt, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f202732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: BoW vs TF-IDF con due classificatori\n",
    "bow_vec = CountVectorizer()\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "X_train_bow = bow_vec.fit_transform(X_train_txt)\n",
    "X_test_bow = bow_vec.transform(X_test_txt)\n",
    "X_train_tfidf = tfidf_vec.fit_transform(X_train_txt)\n",
    "X_test_tfidf = tfidf_vec.transform(X_test_txt)\n",
    "\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for rep_name, (X_tr, X_te) in {'BoW': (X_train_bow, X_test_bow), 'TF-IDF': (X_train_tfidf, X_test_tfidf)}.items():\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_tr, y_train)\n",
    "        acc = accuracy_score(y_test, clf.predict(X_te))\n",
    "        rows.append({'rappresentazione': rep_name, 'modello': clf_name, 'accuracy': acc})\n",
    "res_cls = pd.DataFrame(rows)\n",
    "print(res_cls)\n",
    "assert not res_cls.empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: parole piu' importanti per classe (Logistic Regression su TF-IDF)\n",
    "X_full = tfidf_vec.fit_transform(texts)\n",
    "clf_full = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf_full.fit(X_full, labels)\n",
    "feature_names = tfidf_vec.get_feature_names_out()\n",
    "coef = clf_full.coef_[0]\n",
    "\n",
    "def top_terms(coefs, feature_names, top=5):\n",
    "    idx_sorted = np.argsort(coefs)\n",
    "    neg = [(feature_names[i], coefs[i]) for i in idx_sorted[:top]]\n",
    "    pos = [(feature_names[i], coefs[i]) for i in idx_sorted[-top:][::-1]]\n",
    "    return neg, pos\n",
    "\n",
    "neg_terms, pos_terms = top_terms(coef, feature_names, top=5)\n",
    "print(\"Top parole classe negativa:\", neg_terms)\n",
    "print(\"Top parole classe positiva:\", pos_terms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f07fc",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (passo-passo)\n",
    "## Esercizio 31.1 - Calcolo TF-IDF step-by-step\n",
    "Obiettivo: replicare il calcolo TF-IDF su un mini-corpus per verificare formule e normalizzazione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 31.1\n",
    "mini_corpus = [\n",
    "    \"machine learning is great\",\n",
    "    \"deep learning is a subset of machine learning\",\n",
    "    \"neural networks power deep learning\"\n",
    "]\n",
    "vec = TfidfVectorizer()\n",
    "X_mini = vec.fit_transform(mini_corpus)\n",
    "print(pd.DataFrame(X_mini.toarray().round(3), columns=vec.get_feature_names_out()))\n",
    "assert X_mini.shape[0] == len(mini_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79747252",
   "metadata": {},
   "source": [
    "## Esercizio 31.2 - Mini motore di ricerca\n",
    "Obiettivo: indicizzare documenti con TF-IDF e rispondere a una query ordinando per similarita'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 31.2\n",
    "corpus_docs = [\n",
    "    \"Introduzione al machine learning e ai modelli di classificazione\",\n",
    "    \"Deep learning con reti neurali e tecniche di ottimizzazione\",\n",
    "    \"Metodi di clustering e riduzione dimensionale\",\n",
    "    \"Tecniche di text mining e NLP\"\n",
    "]\n",
    "vec_search = TfidfVectorizer()\n",
    "X_docs = vec_search.fit_transform(corpus_docs)\n",
    "\n",
    "query = \"reti neurali per deep learning\"\n",
    "q_vec = vec_search.transform([query])\n",
    "scores = cosine_similarity(q_vec, X_docs).flatten()\n",
    "order = scores.argsort()[::-1]\n",
    "print(\"Ranking risultati:\")\n",
    "for idx in order:\n",
    "    print(f\"Doc {idx+1} score {scores[idx]:.3f}: {corpus_docs[idx]}\")\n",
    "assert scores.shape[0] == len(corpus_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 31.3 - Estrazione keywords\n",
    "Obiettivo: usare TF-IDF per estrarre le parole piu' pesanti da un documento rispetto a un corpus di riferimento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esecuzione estrazione keywords con TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soluzione esercizio 31.3\n",
    "vec_kw = TfidfVectorizer()\n",
    "vec_kw.fit(corpus_docs)\n",
    "\n",
    "def extract_keywords(document: str, vectorizer, top_n: int = 5) -> list:\n",
    "    vec = vectorizer.transform([document])\n",
    "    scores = vec.toarray().flatten()\n",
    "    idx = scores.argsort()[::-1][:top_n]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    return [(terms[i], scores[i]) for i in idx if scores[i] > 0]\n",
    "\n",
    "sample_doc = corpus_docs[0]\n",
    "print(extract_keywords(sample_doc, vec_kw, top_n=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa\n",
    "\n",
    "## 5 take-home messages\n",
    "\n",
    "| # | Messaggio | Perché importante |\n",
    "|---|-----------|-------------------|\n",
    "| 1 | **TF-IDF pesa per rarità** | Parole comuni → peso basso |\n",
    "| 2 | **Cosine similarity per confronti** | Indipendente dalla lunghezza |\n",
    "| 3 | **Normalizzazione L2 inclusa** | TfidfVectorizer la applica automaticamente |\n",
    "| 4 | **Confronta sempre BoW vs TF-IDF** | Non assumere che uno sia sempre meglio |\n",
    "| 5 | **coef_ per keyword extraction** | LogReg interpreta quali parole contano |\n",
    "\n",
    "---\n",
    "\n",
    "## Confronto sintetico: parametri TfidfVectorizer\n",
    "\n",
    "| Parametro | Default | Effetto | Quando cambiare |\n",
    "|-----------|---------|---------|-----------------|\n",
    "| `ngram_range` | (1,1) | Solo unigrammi | (1,2) per bigrammi |\n",
    "| `max_features` | None | Tutti i termini | 5000-10000 per limitare |\n",
    "| `min_df` | 1 | Anche termini rari | 2-5 per rimuovere rari |\n",
    "| `max_df` | 1.0 | Anche troppo comuni | 0.9 per rimuovere \"the\" |\n",
    "| `norm` | 'l2' | Normalizza vettori | None per valori raw |\n",
    "| `sublinear_tf` | False | TF = 1 + log(tf) | True per corpus grandi |\n",
    "\n",
    "---\n",
    "\n",
    "## Perché questi concetti funzionano\n",
    "\n",
    "### 1) IDF come filtro informativo\n",
    "\n",
    "```\n",
    "Parola      DF (doc con parola)    IDF = log(N/DF)\n",
    "─────────   ─────────────────      ───────────────\n",
    "\"the\"       1000/1000              log(1) = 0 (inutile!)\n",
    "\"algorithm\" 10/1000                log(100) = 2 (informativa!)\n",
    "\"quantum\"   1/1000                 log(1000) = 3 (molto rara!)\n",
    "```\n",
    "\n",
    "### 2) Cosine vs distanza euclidea\n",
    "\n",
    "```\n",
    "Doc A: [1, 0, 0, 5]  (50 parole)\n",
    "Doc B: [2, 0, 0, 10] (100 parole)\n",
    "\n",
    "Euclidea: ||A - B|| = grande (sembrano diversi!)\n",
    "Cosine:   cos(A, B) = 1.0 (sono IDENTICI in direzione!)\n",
    "\n",
    "TF-IDF + cosine = invariante alla lunghezza\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Reference card metodi\n",
    "\n",
    "| Metodo | Input | Output | Note |\n",
    "|--------|-------|--------|------|\n",
    "| `TfidfVectorizer()` | - | vectorizer | Configura |\n",
    "| `.fit_transform(docs)` | lista stringhe | sparse matrix | TF-IDF |\n",
    "| `.transform(docs)` | lista stringhe | sparse matrix | Nuovo testo |\n",
    "| `cosine_similarity(X, Y)` | matrici | similarity matrix | 0-1 |\n",
    "| `LogisticRegression().coef_` | - | array pesi | Per interpretazione |\n",
    "| `.get_feature_names_out()` | - | array termini | Vocabolario |\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e debug rapido\n",
    "\n",
    "| Errore | Perché sbagliato | Fix |\n",
    "|--------|-----------------|-----|\n",
    "| Refit su test | Vocabolario/IDF diversi | Solo transform() |\n",
    "| Cosine su BoW non normalizzato | Lunghezza influisce | Usa TF-IDF o normalizza |\n",
    "| Ignorare stopwords | \"the\" domina | stop_words='english' |\n",
    "| sublinear_tf non usato | TF troppo alto su parole ripetute | sublinear_tf=True |\n",
    "| Confrontare doc con vocabolario diverso | Dimensioni non matchano | Stesso vectorizer |\n",
    "\n",
    "---\n",
    "\n",
    "## Template TF-IDF + classificazione\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Vettorizza\n",
    "vec = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=2)\n",
    "X = vec.fit_transform(train_docs)\n",
    "X_test = vec.transform(test_docs)\n",
    "\n",
    "# 2) Classifica\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# 3) Estrai keyword per classe\n",
    "feature_names = vec.get_feature_names_out()\n",
    "for i, class_name in enumerate(clf.classes_):\n",
    "    top_idx = clf.coef_[i].argsort()[-10:][::-1]\n",
    "    keywords = [feature_names[j] for j in top_idx]\n",
    "    print(f\"{class_name}: {keywords}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prossimi passi\n",
    "\n",
    "| Lezione | Argomento | Collegamento |\n",
    "|---------|-----------|--------------|\n",
    "| 32 | Sentiment Analysis | Polarità positiva/negativa |\n",
    "| 33 | Named Entity Recognition | Estrazione entità |\n",
    "| 34+ | Document Intelligence | Struttura documenti |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho calcolato TF-IDF e confrontato i risultati con sklearn.\n",
    "- [ ] Ho usato cosine similarity per verificare vicinanza tra documenti.\n",
    "- [ ] Ho confrontato BoW e TF-IDF in un task di classificazione.\n",
    "- [ ] Ho estratto keyword o coefficienti per interpretare i modelli.\n",
    "- [ ] Ho mantenuto lo stesso vectorizer per train/test e query.\n",
    "\n",
    "Glossario\n",
    "- TF: term frequency, conteggio nel documento.\n",
    "- IDF: inverse document frequency, peso inverso alla frequenza nei documenti.\n",
    "- TF-IDF: prodotto TF e IDF, normalizzato.\n",
    "- Cosine similarity: misura di angolo tra vettori.\n",
    "- BoW: rappresentazione a conteggi.\n",
    "- Vocabolario: insieme di termini indicizzati.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-02-05 | Creazione: TF-IDF base e sklearn |\n",
    "| 1.1 | 2024-02-12 | Aggiunta cosine similarity |\n",
    "| 2.0 | 2024-02-18 | Integrato confronto BoW vs TF-IDF |\n",
    "| 2.1 | 2024-02-22 | Refactor con keyword extraction |\n",
    "| **2.3** | **2024-12-19** | **ESPANSIONE COMPLETA:** mappa lezione 8 sezioni, tabella obiettivi, ASCII formula TF-IDF, intuizione IDF come filtro, cosine vs euclidea diagram, BoW vs TF-IDF comparison table, 5 take-home messages, tabella parametri TfidfVectorizer, template completo classificazione + keyword, reference card |\n",
    "\n",
    "---\n",
    "\n",
    "## Note per lo studente\n",
    "\n",
    "TF-IDF è la rappresentazione standard per NLP classico:\n",
    "\n",
    "| Tecnica | Uso principale |\n",
    "|---------|----------------|\n",
    "| BoW | Baseline, testi corti |\n",
    "| TF-IDF | Classificazione, ricerca |\n",
    "| Word embeddings | Semantica, deep learning |\n",
    "\n",
    "**Workflow NLP consolidato:**\n",
    "1. Pulizia → 2. TF-IDF → 3. Modello → 4. Interpretazione\n",
    "\n",
    "**Prossima tappa:** Lesson 32 - Sentiment Analysis (classificazione polarità)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
