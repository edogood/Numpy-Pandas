{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb898b19",
   "metadata": {},
   "source": [
    "# Lezione 31 ‚Äî TF-IDF e Text Mining\n",
    "\n",
    "## Obiettivi di Apprendimento\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "1. **Comprendere** i limiti del semplice Bag of Words e perch√© serve TF-IDF\n",
    "2. **Calcolare** TF, IDF e TF-IDF sia manualmente che con sklearn\n",
    "3. **Applicare** TF-IDF per classificazione e similarity testuale\n",
    "4. **Interpretare** i pesi TF-IDF per capire quali parole sono importanti\n",
    "5. **Configurare** TfidfVectorizer per diversi casi d'uso\n",
    "\n",
    "## Importanza per il Data Analyst\n",
    "\n",
    "TF-IDF √® la tecnica pi√π usata nel text mining classico perch√©:\n",
    "- Pesa le parole per **importanza reale** nel corpus\n",
    "- Penalizza parole troppo comuni (stopwords implicite)\n",
    "- Migliora le prestazioni di classificazione rispetto al semplice BoW\n",
    "- √à alla base di motori di ricerca e sistemi di recommendation\n",
    "\n",
    "## Posizione nel Percorso\n",
    "\n",
    "```\n",
    "BLOCCO 4: AI & NLP\n",
    "‚îú‚îÄ‚îÄ Lezione 29: Fondamenti AI ‚úì\n",
    "‚îú‚îÄ‚îÄ Lezione 30: Rappresentare il Testo ‚úì\n",
    "‚îú‚îÄ‚îÄ Lezione 31: TF-IDF e Text Mining ‚óÑ‚îÄ‚îÄ SEI QUI\n",
    "‚îú‚îÄ‚îÄ Lezione 32: Sentiment Analysis\n",
    "‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f83642",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Teoria Concettuale\n",
    "\n",
    "## 1.1 Il Problema del Bag of Words\n",
    "\n",
    "### Limite Fondamentale\n",
    "\n",
    "Il Bag of Words tratta tutte le parole allo stesso modo: ogni occorrenza vale 1.\n",
    "\n",
    "Ma non tutte le parole sono ugualmente **informative**:\n",
    "\n",
    "| Parola | Frequenza | Informazione |\n",
    "|--------|-----------|--------------|\n",
    "| \"il\" | Altissima | Nulla (appare ovunque) |\n",
    "| \"prodotto\" | Alta | Bassa (comune nel dominio) |\n",
    "| \"eccezionale\" | Bassa | Alta (discriminante) |\n",
    "\n",
    "### Esempio Concreto\n",
    "\n",
    "**Corpus di recensioni prodotti**:\n",
    "- Doc 1: \"Il prodotto √® buono\"\n",
    "- Doc 2: \"Il prodotto √® ottimo\"\n",
    "- Doc 3: \"Il prodotto √® pessimo\"\n",
    "\n",
    "Con BoW, la parola \"il\" e \"prodotto\" dominano la rappresentazione, ma sono **inutili** per distinguere i documenti. L'informazione reale √® in \"buono\", \"ottimo\", \"pessimo\".\n",
    "\n",
    "### Intuizione TF-IDF\n",
    "\n",
    "L'idea √® semplice:\n",
    "- Una parola √® importante se appare **spesso nel documento** (TF alto)\n",
    "- Ma **raramente negli altri documenti** (IDF alto)\n",
    "\n",
    "$$\\text{Importanza} = \\text{Frequenza locale} \\times \\text{Rarit√† globale}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0c6a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 Term Frequency (TF)\n",
    "\n",
    "### Definizione\n",
    "\n",
    "**TF (Term Frequency)** misura quanto spesso una parola appare in un documento.\n",
    "\n",
    "Esistono diverse varianti:\n",
    "\n",
    "| Variante | Formula | Caratteristica |\n",
    "|----------|---------|----------------|\n",
    "| **Raw count** | $tf(t,d) = f_{t,d}$ | Conteggio grezzo |\n",
    "| **Boolean** | $tf(t,d) = 1$ se $t \\in d$, else $0$ | Presenza/assenza |\n",
    "| **Term frequency** | $tf(t,d) = \\frac{f_{t,d}}{\\sum_{t' \\in d} f_{t',d}}$ | Normalizzata per lunghezza doc |\n",
    "| **Log normalization** | $tf(t,d) = 1 + \\log(f_{t,d})$ | Smorza differenze grandi |\n",
    "\n",
    "### Esempio\n",
    "\n",
    "Documento: \"il gatto mangia il pesce il pesce\"\n",
    "\n",
    "| Parola | Raw count | Normalized TF |\n",
    "|--------|-----------|---------------|\n",
    "| il | 3 | 3/7 = 0.43 |\n",
    "| gatto | 1 | 1/7 = 0.14 |\n",
    "| mangia | 1 | 1/7 = 0.14 |\n",
    "| pesce | 2 | 2/7 = 0.29 |\n",
    "\n",
    "### Problema di TF da Solo\n",
    "\n",
    "TF da solo non basta: la parola \"il\" ha TF massimo ma zero valore informativo. Serve un fattore che penalizzi parole comuni ‚Üí IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e100b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Inverse Document Frequency (IDF)\n",
    "\n",
    "### Definizione\n",
    "\n",
    "**IDF (Inverse Document Frequency)** misura quanto una parola √® **rara** nel corpus.\n",
    "\n",
    "$$idf(t, D) = \\log\\left(\\frac{N}{df_t}\\right)$$\n",
    "\n",
    "Dove:\n",
    "- $N$ = numero totale di documenti nel corpus\n",
    "- $df_t$ = numero di documenti che contengono il termine $t$\n",
    "\n",
    "### Intuizione\n",
    "\n",
    "| Parola | In quanti doc? | IDF | Interpretazione |\n",
    "|--------|----------------|-----|-----------------|\n",
    "| \"il\" | 1000/1000 | log(1000/1000) = 0 | Inutile |\n",
    "| \"prodotto\" | 800/1000 | log(1000/800) = 0.097 | Poco informativa |\n",
    "| \"eccezionale\" | 10/1000 | log(1000/10) = 2.0 | Molto informativa |\n",
    "\n",
    "### Variante sklearn\n",
    "\n",
    "sklearn usa una formula leggermente diversa per evitare divisioni per zero:\n",
    "\n",
    "$$idf(t) = \\log\\left(\\frac{N + 1}{df_t + 1}\\right) + 1$$\n",
    "\n",
    "Questa formula:\n",
    "- Aggiunge 1 al numeratore e denominatore (smoothing)\n",
    "- Aggiunge 1 al risultato (garantisce IDF ‚â• 1)\n",
    "\n",
    "### Effetto dell'IDF\n",
    "\n",
    "```\n",
    "Parole comuni ‚Üí IDF basso ‚Üí peso finale basso\n",
    "Parole rare   ‚Üí IDF alto  ‚Üí peso finale alto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a871b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 TF-IDF Combinato\n",
    "\n",
    "### Formula Finale\n",
    "\n",
    "$$tfidf(t, d, D) = tf(t, d) \\times idf(t, D)$$\n",
    "\n",
    "In sklearn con le varianti di default:\n",
    "\n",
    "$$tfidf(t, d) = f_{t,d} \\times \\left(\\log\\frac{N+1}{df_t+1} + 1\\right)$$\n",
    "\n",
    "Seguito da normalizzazione L2 del vettore risultante.\n",
    "\n",
    "### Esempio Completo\n",
    "\n",
    "**Corpus** (N=4 documenti):\n",
    "- D1: \"il gatto mangia\"\n",
    "- D2: \"il cane mangia\"\n",
    "- D3: \"il gatto dorme\"\n",
    "- D4: \"il pesce nuota\"\n",
    "\n",
    "**Calcolo per D1**:\n",
    "\n",
    "| Parola | tf(D1) | df | idf | tf-idf |\n",
    "|--------|--------|-----|-----|--------|\n",
    "| il | 1 | 4 | log(5/5)+1 = 1.0 | 1.0 |\n",
    "| gatto | 1 | 2 | log(5/3)+1 = 1.51 | 1.51 |\n",
    "| mangia | 1 | 2 | log(5/3)+1 = 1.51 | 1.51 |\n",
    "\n",
    "Dopo normalizzazione L2: il vettore viene diviso per la sua norma.\n",
    "\n",
    "### Propriet√† Risultanti\n",
    "\n",
    "1. **Parole comuni** (alto df) ‚Üí basso tf-idf ‚Üí poco peso\n",
    "2. **Parole rare ma frequenti nel doc** ‚Üí alto tf-idf ‚Üí molto peso\n",
    "3. **Parole uniche nel corpus** (df=1) ‚Üí tf-idf massimo\n",
    "4. **Vettori normalizzati** ‚Üí confrontabili con cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648ba27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Cosine Similarity\n",
    "\n",
    "### Il Problema della Similarit√†\n",
    "\n",
    "Data la rappresentazione TF-IDF, come misuriamo quanto due documenti sono \"simili\"?\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "Misura l'angolo tra due vettori nello spazio:\n",
    "\n",
    "$$\\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\times \\|B\\|} = \\frac{\\sum_{i=1}^{n} A_i \\times B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\times \\sqrt{\\sum_{i=1}^{n} B_i^2}}$$\n",
    "\n",
    "### Interpretazione\n",
    "\n",
    "| Valore | Significato |\n",
    "|--------|-------------|\n",
    "| 1.0 | Documenti identici (stessa direzione) |\n",
    "| 0.0 | Documenti ortogonali (nessuna parola in comune) |\n",
    "| -1.0 | Documenti opposti (raro con TF-IDF, che √® ‚â•0) |\n",
    "\n",
    "### Perch√© Cosine e non Euclidea?\n",
    "\n",
    "| Metrica | Problema |\n",
    "|---------|----------|\n",
    "| Distanza Euclidea | Sensibile alla lunghezza del documento |\n",
    "| Cosine Similarity | Indipendente dalla lunghezza (normalizzata) |\n",
    "\n",
    "Un documento lungo e uno corto sullo stesso argomento:\n",
    "- Distanza Euclidea: grandi differenze (magnitudini diverse)\n",
    "- Cosine: alta similarit√† (stessa direzione)\n",
    "\n",
    "### Visualizzazione\n",
    "\n",
    "```\n",
    "        ‚îÇ B (doc lungo)\n",
    "        ‚îÇ‚ï±\n",
    "        ‚îÇ\n",
    "        ‚îÇ  A (doc corto)\n",
    "        ‚îÇ‚ï±\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "Angolo piccolo = alta cosine similarity\n",
    "Anche se |B| >> |A|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60143224",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Schema Mentale\n",
    "\n",
    "## Mappa Decisionale: BoW vs TF-IDF\n",
    "\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ   HAI TESTO DA VETTORIZZARE?       ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                       ‚îÇ\n",
    "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "              ‚îÇ                        ‚îÇ                        ‚îÇ\n",
    "              ‚ñº                        ‚ñº                        ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Solo conteggi   ‚îÇ    ‚îÇ Pesatura per    ‚îÇ    ‚îÇ Semantica       ‚îÇ\n",
    "    ‚îÇ (baseline)      ‚îÇ    ‚îÇ importanza      ‚îÇ    ‚îÇ avanzata        ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "             ‚îÇ                      ‚îÇ                      ‚îÇ\n",
    "             ‚ñº                      ‚ñº                      ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ CountVectorizer ‚îÇ    ‚îÇ TfidfVectorizer ‚îÇ    ‚îÇ Word Embeddings ‚îÇ\n",
    "    ‚îÇ (BoW)           ‚îÇ    ‚îÇ (TF-IDF)        ‚îÇ    ‚îÇ (Word2Vec,BERT) ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Quando Usare TF-IDF\n",
    "\n",
    "| Scenario | Usa TF-IDF? | Motivazione |\n",
    "|----------|-------------|-------------|\n",
    "| Classificazione documenti | ‚úì S√¨ | Pesa parole discriminanti |\n",
    "| Ricerca/Information retrieval | ‚úì S√¨ | Caso d'uso originale |\n",
    "| Document similarity | ‚úì S√¨ | Con cosine similarity |\n",
    "| Topic modeling | ‚úì Spesso | Ma LDA pu√≤ usare BoW |\n",
    "| Sentiment analysis | ‚úì Pu√≤ aiutare | Ma BoW spesso ok |\n",
    "| Sequenze (NER, POS) | ‚úó No | Serve ordine, usa embeddings |\n",
    "\n",
    "## Parametri Chiave TfidfVectorizer\n",
    "\n",
    "| Parametro | Significato | Quando Usarlo |\n",
    "|-----------|-------------|---------------|\n",
    "| `sublinear_tf=True` | Usa 1+log(tf) | Corpus con termini molto ripetuti |\n",
    "| `norm='l2'` | Normalizzazione L2 | Default, ok per similarity |\n",
    "| `use_idf=True` | Applica IDF | Quasi sempre |\n",
    "| `smooth_idf=True` | Smoothing IDF | Evita log(0), sempre on |\n",
    "| `max_df=0.9` | Ignora in >90% docs | Stopwords automatiche |\n",
    "| `min_df=2` | Ignora in <2 docs | Rimuovi typo e rare |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1b078",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Notebook Dimostrativo\n",
    "\n",
    "## TF-IDF in Pratica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1015cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP: Importazione librerie\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Librerie importate correttamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d47ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CALCOLO MANUALE TF-IDF\n",
    "# ============================================================\n",
    "# Per capire esattamente cosa fa TfidfVectorizer\n",
    "\n",
    "# Corpus di esempio\n",
    "corpus = [\n",
    "    \"il gatto mangia il pesce\",\n",
    "    \"il cane mangia la carne\",\n",
    "    \"il gatto dorme sul divano\",\n",
    "    \"il cane gioca nel parco\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CALCOLO MANUALE TF-IDF\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nCORPUS:\")\n",
    "for i, doc in enumerate(corpus, 1):\n",
    "    print(f\"  D{i}: \\\"{doc}\\\"\")\n",
    "\n",
    "# Step 1: Costruiamo il vocabolario\n",
    "all_words = set()\n",
    "tokenized_docs = []\n",
    "for doc in corpus:\n",
    "    tokens = doc.lower().split()\n",
    "    tokenized_docs.append(tokens)\n",
    "    all_words.update(tokens)\n",
    "\n",
    "vocab = sorted(list(all_words))\n",
    "print(f\"\\nVocabolario ({len(vocab)} parole): {vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 2: Calcolo TF (Term Frequency)\n",
    "# ============================================================\n",
    "\n",
    "N = len(corpus)  # Numero documenti\n",
    "\n",
    "# Calcoliamo TF per ogni documento\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: TERM FREQUENCY (TF)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Matrice TF (raw counts)\n",
    "tf_matrix = np.zeros((N, len(vocab)))\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "for doc_idx, tokens in enumerate(tokenized_docs):\n",
    "    for token in tokens:\n",
    "        tf_matrix[doc_idx, word_to_idx[token]] += 1\n",
    "\n",
    "print(\"\\nMatrice TF (conteggi grezzi):\")\n",
    "df_tf = pd.DataFrame(tf_matrix.astype(int), columns=vocab,\n",
    "                     index=[f\"D{i+1}\" for i in range(N)])\n",
    "print(df_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab662439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 3: Calcolo IDF (Inverse Document Frequency)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: INVERSE DOCUMENT FREQUENCY (IDF)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# df = document frequency (in quanti documenti appare ogni termine)\n",
    "df_counts = np.sum(tf_matrix > 0, axis=0)\n",
    "\n",
    "# IDF formula sklearn: log((N+1)/(df+1)) + 1\n",
    "idf_values = np.log((N + 1) / (df_counts + 1)) + 1\n",
    "\n",
    "print(\"\\nDocument Frequency (df) e IDF per ogni parola:\")\n",
    "print(\"-\" * 50)\n",
    "idf_df = pd.DataFrame({\n",
    "    'Parola': vocab,\n",
    "    'df (in quanti doc)': df_counts.astype(int),\n",
    "    'IDF': idf_values.round(3)\n",
    "}).set_index('Parola')\n",
    "\n",
    "print(idf_df)\n",
    "\n",
    "print(\"\\nOSSERVAZIONE:\")\n",
    "print(\"‚Ä¢ 'il' appare in tutti i doc ‚Üí IDF basso (1.0)\")\n",
    "print(\"‚Ä¢ 'gatto','cane','mangia' in 2 doc ‚Üí IDF medio\")\n",
    "print(\"‚Ä¢ 'pesce','divano','parco'... in 1 doc ‚Üí IDF alto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Step 4: Calcolo TF-IDF e Normalizzazione L2\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: TF-IDF = TF √ó IDF\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TF-IDF = TF * IDF\n",
    "tfidf_matrix = tf_matrix * idf_values\n",
    "\n",
    "print(\"\\nMatrice TF-IDF (prima di normalizzazione):\")\n",
    "df_tfidf_raw = pd.DataFrame(tfidf_matrix.round(3), columns=vocab,\n",
    "                            index=[f\"D{i+1}\" for i in range(N)])\n",
    "print(df_tfidf_raw)\n",
    "\n",
    "# Normalizzazione L2 (ogni riga divisa per la sua norma)\n",
    "norms = np.sqrt(np.sum(tfidf_matrix ** 2, axis=1, keepdims=True))\n",
    "tfidf_normalized = tfidf_matrix / norms\n",
    "\n",
    "print(\"\\nMatrice TF-IDF (dopo normalizzazione L2):\")\n",
    "df_tfidf = pd.DataFrame(tfidf_normalized.round(3), columns=vocab,\n",
    "                        index=[f\"D{i+1}\" for i in range(N)])\n",
    "print(df_tfidf)\n",
    "\n",
    "# Verifica: la norma di ogni riga deve essere 1\n",
    "print(\"\\nVerifica normalizzazione (norma di ogni riga):\")\n",
    "for i in range(N):\n",
    "    norm = np.sqrt(np.sum(tfidf_normalized[i] ** 2))\n",
    "    print(f\"  ||D{i+1}|| = {norm:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19240f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFRONTO CON SKLEARN TfidfVectorizer\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICA: CONFRONTO CON sklearn TfidfVectorizer\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Usiamo TfidfVectorizer con stesse impostazioni\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "X_sklearn = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "# Convertiamo in DataFrame per confronto\n",
    "vocab_sklearn = tfidf_vec.get_feature_names_out()\n",
    "df_sklearn = pd.DataFrame(X_sklearn.toarray().round(3), \n",
    "                          columns=vocab_sklearn,\n",
    "                          index=[f\"D{i+1}\" for i in range(N)])\n",
    "\n",
    "print(\"\\nMatrice TF-IDF da sklearn:\")\n",
    "print(df_sklearn)\n",
    "\n",
    "# Confronto\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Le due matrici sono identiche:\", end=\" \")\n",
    "\n",
    "# Riordiniamo le colonne del nostro calcolo manuale\n",
    "df_manual_sorted = df_tfidf[vocab_sklearn]\n",
    "match = np.allclose(df_manual_sorted.values, df_sklearn.values, atol=1e-3)\n",
    "print(\"‚úì S√å\" if match else \"‚úó NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COSINE SIMILARITY TRA DOCUMENTI\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COSINE SIMILARITY TRA DOCUMENTI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcoliamo la matrice di similarit√†\n",
    "sim_matrix = cosine_similarity(X_sklearn)\n",
    "\n",
    "# Visualizziamo come DataFrame\n",
    "df_sim = pd.DataFrame(sim_matrix.round(3),\n",
    "                      columns=[f\"D{i+1}\" for i in range(N)],\n",
    "                      index=[f\"D{i+1}\" for i in range(N)])\n",
    "\n",
    "print(\"\\nMatrice di Similarit√† Coseno:\")\n",
    "print(df_sim)\n",
    "\n",
    "# Interpretazione\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"INTERPRETAZIONE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "‚Ä¢ D1 ('gatto mangia pesce') vs D3 ('gatto dorme divano')\n",
    "  Similarit√†: {:.3f} - condividono 'il', 'gatto'\n",
    "  \n",
    "‚Ä¢ D2 ('cane mangia carne') vs D4 ('cane gioca parco')\n",
    "  Similarit√†: {:.3f} - condividono 'il', 'cane'\n",
    "  \n",
    "‚Ä¢ D1 vs D4: {:.3f} - condividono solo 'il' (bassa sim)\n",
    "\"\"\".format(sim_matrix[0,2], sim_matrix[1,3], sim_matrix[0,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFRONTO BOW vs TF-IDF PER CLASSIFICAZIONE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFRONTO BoW vs TF-IDF PER CLASSIFICAZIONE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset pi√π grande per confronto significativo\n",
    "recensioni = [\n",
    "    # Positive (1)\n",
    "    (\"Prodotto eccezionale, lo consiglio a tutti\", 1),\n",
    "    (\"Ottimo acquisto, sono molto soddisfatto\", 1),\n",
    "    (\"Qualit√† superiore, prezzo giusto\", 1),\n",
    "    (\"Spedizione veloce, prodotto perfetto\", 1),\n",
    "    (\"Fantastico, supera le aspettative\", 1),\n",
    "    (\"Molto buono, lo ricomprerei sicuramente\", 1),\n",
    "    (\"Ottima qualit√†, consigliato vivamente\", 1),\n",
    "    (\"Prodotto top, veramente eccellente\", 1),\n",
    "    (\"Bellissimo prodotto, funziona benissimo\", 1),\n",
    "    (\"Soddisfatto dell'acquisto, davvero ottimo\", 1),\n",
    "    (\"Qualit√† prezzo imbattibile, consiglio\", 1),\n",
    "    (\"Funziona perfettamente, acquisto azzeccato\", 1),\n",
    "    \n",
    "    # Negative (0)\n",
    "    (\"Prodotto scadente, non funziona affatto\", 0),\n",
    "    (\"Pessima qualit√†, soldi completamente sprecati\", 0),\n",
    "    (\"Non lo consiglio, totalmente deludente\", 0),\n",
    "    (\"Arrivato rotto, pessimo servizio clienti\", 0),\n",
    "    (\"Qualit√† scarsa, non vale assolutamente il prezzo\", 0),\n",
    "    (\"Terribile esperienza, da evitare assolutamente\", 0),\n",
    "    (\"Prodotto difettoso, ho chiesto reso immediato\", 0),\n",
    "    (\"Brutta esperienza, non comprate mai qui\", 0),\n",
    "    (\"Deluso totalmente, prodotto completamente inutile\", 0),\n",
    "    (\"Pessimo acquisto, assolutamente sconsigliato\", 0),\n",
    "    (\"Non funziona come descritto, truffa\", 0),\n",
    "    (\"Rottura dopo una settimana, qualit√† zero\", 0)\n",
    "]\n",
    "\n",
    "texts = [r[0] for r in recensioni]\n",
    "labels = np.array([r[1] for r in recensioni])\n",
    "\n",
    "# Split\n",
    "X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train_txt)}, Test: {len(X_test_txt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f202732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFRONTO VETTORIZZAZIONI\n",
    "# ============================================================\n",
    "\n",
    "# Vectorizers\n",
    "bow_vec = CountVectorizer()\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Trasformazione\n",
    "X_train_bow = bow_vec.fit_transform(X_train_txt)\n",
    "X_test_bow = bow_vec.transform(X_test_txt)\n",
    "\n",
    "X_train_tfidf = tfidf_vec.fit_transform(X_train_txt)\n",
    "X_test_tfidf = tfidf_vec.transform(X_test_txt)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"RISULTATI CLASSIFICAZIONE\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Testiamo con due classificatori\n",
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    # BoW\n",
    "    clf_bow = clf.__class__(**clf.get_params())\n",
    "    clf_bow.fit(X_train_bow, y_train)\n",
    "    acc_bow = accuracy_score(y_test, clf_bow.predict(X_test_bow))\n",
    "    \n",
    "    # TF-IDF\n",
    "    clf_tfidf = clf.__class__(**clf.get_params())\n",
    "    clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "    acc_tfidf = accuracy_score(y_test, clf_tfidf.predict(X_test_tfidf))\n",
    "    \n",
    "    results.append({\n",
    "        'Classificatore': clf_name,\n",
    "        'BoW': f\"{acc_bow:.2%}\",\n",
    "        'TF-IDF': f\"{acc_tfidf:.2%}\",\n",
    "        'Differenza': f\"{(acc_tfidf - acc_bow)*100:+.1f}%\"\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\"\"\n",
    "NOTA: Con dataset piccoli le differenze possono variare.\n",
    "Su dataset reali (1000+ documenti), TF-IDF tipicamente \n",
    "migliora le performance rispetto a BoW grezzo.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANALISI: PAROLE PI√ô IMPORTANTI PER CLASSE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PAROLE PI√ô IMPORTANTI PER CLASSE (TF-IDF)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Alleniamo logistic regression su tutto il dataset\n",
    "tfidf_full = TfidfVectorizer()\n",
    "X_full = tfidf_full.fit_transform(texts)\n",
    "clf_full = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf_full.fit(X_full, labels)\n",
    "\n",
    "# I coefficienti indicano l'importanza delle parole\n",
    "feature_names = tfidf_full.get_feature_names_out()\n",
    "coefficients = clf_full.coef_[0]\n",
    "\n",
    "# Top parole positive e negative\n",
    "top_k = 8\n",
    "sorted_idx = np.argsort(coefficients)\n",
    "\n",
    "print(\"\\nTOP PAROLE INDICATIVE di NEGATIVO (coef < 0):\")\n",
    "print(\"-\" * 40)\n",
    "for idx in sorted_idx[:top_k]:\n",
    "    print(f\"  '{feature_names[idx]}': {coefficients[idx]:.3f}\")\n",
    "\n",
    "print(\"\\nTOP PAROLE INDICATIVE di POSITIVO (coef > 0):\")\n",
    "print(\"-\" * 40)\n",
    "for idx in sorted_idx[-top_k:][::-1]:\n",
    "    print(f\"  '{feature_names[idx]}': {coefficients[idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f07fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Esercizi Svolti\n",
    "\n",
    "## Esercizio 1: Calcolo TF-IDF Step-by-Step\n",
    "\n",
    "**Problema**: Dato un mini-corpus di 3 documenti, calcola manualmente TF, IDF e TF-IDF per ogni termine, poi verifica con sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 1 - SOLUZIONE\n",
    "# Calcolo TF-IDF step-by-step\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 1: CALCOLO TF-IDF STEP-BY-STEP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Mini-corpus\n",
    "mini_corpus = [\n",
    "    \"machine learning is great\",\n",
    "    \"deep learning is a subset of machine learning\",\n",
    "    \"neural networks power deep learning\"\n",
    "]\n",
    "\n",
    "print(\"\\nCORPUS:\")\n",
    "for i, doc in enumerate(mini_corpus, 1):\n",
    "    print(f\"  D{i}: \\\"{doc}\\\"\")\n",
    "\n",
    "N_docs = len(mini_corpus)\n",
    "\n",
    "# Step 1: Tokenizzazione e vocabolario\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STEP 1: VOCABOLARIO\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "tokenized = [doc.lower().split() for doc in mini_corpus]\n",
    "vocab_set = set()\n",
    "for tokens in tokenized:\n",
    "    vocab_set.update(tokens)\n",
    "vocabulary = sorted(list(vocab_set))\n",
    "\n",
    "print(f\"Vocabolario ({len(vocabulary)} termini): {vocabulary}\")\n",
    "\n",
    "# Step 2: Calcolo TF\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STEP 2: TERM FREQUENCY (TF)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "word_to_idx = {w: i for i, w in enumerate(vocabulary)}\n",
    "tf_mat = np.zeros((N_docs, len(vocabulary)))\n",
    "\n",
    "for doc_idx, tokens in enumerate(tokenized):\n",
    "    for token in tokens:\n",
    "        tf_mat[doc_idx, word_to_idx[token]] += 1\n",
    "\n",
    "print(\"\\nMatrice TF (conteggi):\")\n",
    "print(pd.DataFrame(tf_mat.astype(int), columns=vocabulary, \n",
    "                   index=[f\"D{i}\" for i in range(1, N_docs+1)]))\n",
    "\n",
    "# Step 3: Calcolo IDF\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STEP 3: INVERSE DOCUMENT FREQUENCY (IDF)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df_counts = np.sum(tf_mat > 0, axis=0)\n",
    "idf_vals = np.log((N_docs + 1) / (df_counts + 1)) + 1\n",
    "\n",
    "idf_table = pd.DataFrame({\n",
    "    'Termine': vocabulary,\n",
    "    'df': df_counts.astype(int),\n",
    "    'IDF': idf_vals.round(4)\n",
    "}).set_index('Termine')\n",
    "print(idf_table)\n",
    "\n",
    "# Step 4: TF-IDF\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STEP 4: TF-IDF = TF √ó IDF (con normalizzazione L2)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "tfidf_raw = tf_mat * idf_vals\n",
    "norms = np.sqrt(np.sum(tfidf_raw ** 2, axis=1, keepdims=True))\n",
    "tfidf_norm = tfidf_raw / norms\n",
    "\n",
    "print(\"\\nMatrice TF-IDF normalizzata:\")\n",
    "print(pd.DataFrame(tfidf_norm.round(4), columns=vocabulary,\n",
    "                   index=[f\"D{i}\" for i in range(1, N_docs+1)]))\n",
    "\n",
    "# Step 5: Verifica con sklearn\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STEP 5: VERIFICA CON sklearn\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "sklearn_vec = TfidfVectorizer()\n",
    "sklearn_tfidf = sklearn_vec.fit_transform(mini_corpus)\n",
    "sklearn_vocab = sklearn_vec.get_feature_names_out()\n",
    "\n",
    "# Riordiniamo le nostre colonne per confronto\n",
    "my_tfidf_reordered = pd.DataFrame(tfidf_norm, columns=vocabulary)[sklearn_vocab].values\n",
    "sklearn_arr = sklearn_tfidf.toarray()\n",
    "\n",
    "match = np.allclose(my_tfidf_reordered, sklearn_arr, atol=1e-4)\n",
    "print(f\"\\nCalcolo manuale = sklearn TfidfVectorizer? {'‚úì S√å' if match else '‚úó NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79747252",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 2: Sistema di Ricerca Documenti\n",
    "\n",
    "**Problema**: Implementa un mini motore di ricerca che, data una query, restituisce i documenti pi√π rilevanti ordinati per similarit√† TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 2 - SOLUZIONE\n",
    "# Mini motore di ricerca con TF-IDF\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 2: MINI MOTORE DI RICERCA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Corpus di documenti (articoli fittizi)\n",
    "documents = [\n",
    "    {\"id\": 1, \"title\": \"Introduzione al Machine Learning\", \n",
    "     \"content\": \"Il machine learning √® un campo dell'intelligenza artificiale che permette ai computer di apprendere dai dati senza essere esplicitamente programmati.\"},\n",
    "    \n",
    "    {\"id\": 2, \"title\": \"Deep Learning e Reti Neurali\",\n",
    "     \"content\": \"Il deep learning utilizza reti neurali profonde per apprendere rappresentazioni gerarchiche dei dati. √à particolarmente efficace per immagini e testo.\"},\n",
    "    \n",
    "    {\"id\": 3, \"title\": \"Python per Data Science\",\n",
    "     \"content\": \"Python √® il linguaggio pi√π usato per data science e machine learning grazie a librerie come pandas, numpy e scikit-learn.\"},\n",
    "    \n",
    "    {\"id\": 4, \"title\": \"Analisi dei Dati con Pandas\",\n",
    "     \"content\": \"Pandas √® una libreria Python fondamentale per l'analisi e manipolazione dei dati. Offre strutture dati efficienti come DataFrame.\"},\n",
    "    \n",
    "    {\"id\": 5, \"title\": \"Intelligenza Artificiale nel Business\",\n",
    "     \"content\": \"L'intelligenza artificiale sta trasformando il business. Le aziende usano AI per automazione, analisi predittiva e customer service.\"}\n",
    "]\n",
    "\n",
    "# Prepariamo il corpus\n",
    "doc_contents = [d[\"content\"] for d in documents]\n",
    "\n",
    "# Costruiamo l'indice TF-IDF\n",
    "search_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=None  # Per italiano custom\n",
    ")\n",
    "doc_vectors = search_vectorizer.fit_transform(doc_contents)\n",
    "\n",
    "print(f\"Indice costruito: {doc_vectors.shape[0]} documenti, {doc_vectors.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea15642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNZIONE DI RICERCA\n",
    "# ============================================================\n",
    "\n",
    "def search(query: str, vectorizer, doc_vectors, documents, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Cerca documenti rilevanti per una query.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query : str\n",
    "        Query di ricerca\n",
    "    vectorizer : TfidfVectorizer\n",
    "        Vectorizer addestrato sul corpus\n",
    "    doc_vectors : sparse matrix\n",
    "        Vettori TF-IDF dei documenti\n",
    "    documents : list\n",
    "        Lista di documenti originali\n",
    "    top_k : int\n",
    "        Numero di risultati da restituire\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : Lista di (documento, score) ordinati per rilevanza\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Vettorizza la query con lo stesso vectorizer\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Step 2: Calcola similarit√† coseno con tutti i documenti\n",
    "    similarities = cosine_similarity(query_vector, doc_vectors)[0]\n",
    "    \n",
    "    # Step 3: Ordina per similarit√† decrescente\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Step 4: Restituisci top-k risultati\n",
    "    results = []\n",
    "    for idx in sorted_indices[:top_k]:\n",
    "        if similarities[idx] > 0:  # Solo se c'√® match\n",
    "            results.append({\n",
    "                'doc': documents[idx],\n",
    "                'score': similarities[idx]\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ‚îÄ‚îÄ TEST DELLA RICERCA ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TEST RICERCA\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "queries = [\n",
    "    \"machine learning intelligenza artificiale\",\n",
    "    \"python pandas dataframe\",\n",
    "    \"reti neurali deep learning\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nüîç QUERY: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    results = search(query, search_vectorizer, doc_vectors, documents, top_k=3)\n",
    "    \n",
    "    if results:\n",
    "        for rank, res in enumerate(results, 1):\n",
    "            print(f\"  {rank}. [{res['score']:.3f}] {res['doc']['title']}\")\n",
    "    else:\n",
    "        print(\"  Nessun risultato trovato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e18a68",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 3: Estrazione Keywords con TF-IDF\n",
    "\n",
    "**Problema**: Usa TF-IDF per estrarre automaticamente le parole chiave pi√π importanti da un documento rispetto a un corpus di riferimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 3 - SOLUZIONE\n",
    "# Estrazione keywords con TF-IDF\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ESERCIZIO 3: ESTRAZIONE KEYWORDS CON TF-IDF\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def extract_keywords(document: str, vectorizer, top_n: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Estrae le top-n keywords da un documento basandosi sui pesi TF-IDF.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    document : str\n",
    "        Documento da analizzare\n",
    "    vectorizer : TfidfVectorizer\n",
    "        Vectorizer gi√† fit su un corpus di riferimento\n",
    "    top_n : int\n",
    "        Numero di keywords da estrarre\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : Lista di (keyword, score)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Vettorizza il documento\n",
    "    doc_vector = vectorizer.transform([document])\n",
    "    \n",
    "    # Ottieni feature names e scores\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = doc_vector.toarray()[0]\n",
    "    \n",
    "    # Trova indici con score > 0, ordinati per score decrescente\n",
    "    nonzero_idx = np.where(scores > 0)[0]\n",
    "    sorted_idx = nonzero_idx[np.argsort(scores[nonzero_idx])[::-1]]\n",
    "    \n",
    "    # Estrai top-n\n",
    "    keywords = []\n",
    "    for idx in sorted_idx[:top_n]:\n",
    "        keywords.append((feature_names[idx], scores[idx]))\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Corpus di riferimento per calcolare IDF\n",
    "reference_corpus = [\n",
    "    \"L'apprendimento automatico √® una branca dell'intelligenza artificiale\",\n",
    "    \"Python √® un linguaggio di programmazione versatile\",\n",
    "    \"Il deep learning usa reti neurali profonde\",\n",
    "    \"I dati sono fondamentali per il machine learning\",\n",
    "    \"Gli algoritmi di clustering raggruppano dati simili\",\n",
    "    \"La classificazione predice categorie discrete\",\n",
    "    \"La regressione predice valori continui\",\n",
    "    \"Feature engineering migliora le performance dei modelli\"\n",
    "]\n",
    "\n",
    "# Fit vectorizer sul corpus di riferimento\n",
    "kw_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "kw_vectorizer.fit(reference_corpus)\n",
    "\n",
    "# Documenti da analizzare\n",
    "test_docs = [\n",
    "    \"Il deep learning e le reti neurali profonde stanno rivoluzionando l'intelligenza artificiale, permettendo ai computer di apprendere rappresentazioni complesse dei dati.\",\n",
    "    \n",
    "    \"Python √® il linguaggio preferito per data science grazie a librerie come pandas per la manipolazione dati e scikit-learn per il machine learning.\"\n",
    "]\n",
    "\n",
    "print(\"\\nESTRAZIONE KEYWORDS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, doc in enumerate(test_docs, 1):\n",
    "    print(f\"\\nDOCUMENTO {i}:\")\n",
    "    print(f\"\\\"{doc[:80]}...\\\"\")\n",
    "    \n",
    "    keywords = extract_keywords(doc, kw_vectorizer, top_n=6)\n",
    "    \n",
    "    print(f\"\\nKeywords estratte (top 6):\")\n",
    "    for kw, score in keywords:\n",
    "        print(f\"  ‚Ä¢ '{kw}': {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7947899",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Conclusione Operativa\n",
    "\n",
    "## Cosa Abbiamo Imparato\n",
    "\n",
    "| Concetto | Implicazione Pratica |\n",
    "|----------|---------------------|\n",
    "| **TF (Term Frequency)** | Misura frequenza locale di un termine nel documento |\n",
    "| **IDF (Inverse Doc Freq)** | Pesa la rarit√† del termine nel corpus (parole comuni ‚Üí peso basso) |\n",
    "| **TF-IDF** | Combina TF√óIDF per dare peso a parole localmente frequenti ma globalmente rare |\n",
    "| **Normalizzazione L2** | Permette confronto equo tra documenti di lunghezza diversa |\n",
    "| **Cosine Similarity** | Metrica standard per similarit√† tra vettori TF-IDF |\n",
    "\n",
    "## Vantaggi di TF-IDF rispetto a BoW\n",
    "\n",
    "| Aspetto | BoW | TF-IDF |\n",
    "|---------|-----|--------|\n",
    "| Parole comuni | Peso uguale a tutte | Peso ridotto automaticamente |\n",
    "| Parole discriminanti | Trattate come le altre | Peso maggiore |\n",
    "| Classificazione | Baseline | Tipicamente migliore |\n",
    "| Information Retrieval | Meno efficace | Standard di riferimento |\n",
    "\n",
    "## Workflow Operativo\n",
    "\n",
    "```\n",
    "1. PREPROCESSING\n",
    "   ‚îî‚îÄ‚îÄ Tokenizzazione, pulizia (come per BoW)\n",
    "\n",
    "2. VETTORIZZAZIONE TF-IDF\n",
    "   ‚îú‚îÄ‚îÄ TfidfVectorizer con parametri appropriati\n",
    "   ‚îú‚îÄ‚îÄ fit_transform su train\n",
    "   ‚îî‚îÄ‚îÄ transform su test/query\n",
    "\n",
    "3. APPLICAZIONE\n",
    "   ‚îú‚îÄ‚îÄ Classificazione ‚Üí passa matrice a classifier\n",
    "   ‚îú‚îÄ‚îÄ Similarity ‚Üí cosine_similarity tra vettori\n",
    "   ‚îî‚îÄ‚îÄ Keywords ‚Üí ordina features per peso TF-IDF\n",
    "```\n",
    "\n",
    "## Errori Comuni da Evitare\n",
    "\n",
    "1. ‚ùå Ignorare che IDF viene calcolato sul corpus di training\n",
    "2. ‚ùå Non normalizzare quando si confrontano documenti di lunghezze diverse\n",
    "3. ‚ùå Usare distanza Euclidea invece di cosine similarity\n",
    "4. ‚ùå Dimenticare che parole nuove (OOV) hanno score 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8e2ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Bignami ‚Äî Scheda di Riferimento Rapido\n",
    "\n",
    "## Formule Chiave\n",
    "\n",
    "**Term Frequency (raw):**\n",
    "$$tf(t,d) = f_{t,d}$$\n",
    "\n",
    "**Inverse Document Frequency (sklearn):**\n",
    "$$idf(t) = \\log\\frac{N+1}{df_t+1} + 1$$\n",
    "\n",
    "**TF-IDF:**\n",
    "$$tfidf(t,d) = tf(t,d) \\times idf(t)$$\n",
    "\n",
    "**Cosine Similarity:**\n",
    "$$\\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\times \\|B\\|}$$\n",
    "\n",
    "## Codice Essenziale\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Configurazione tipica\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,     # Limita vocabolario\n",
    "    ngram_range=(1, 2),     # Unigram + bigram\n",
    "    min_df=2,               # Ignora termini in < 2 docs\n",
    "    max_df=0.95,            # Ignora termini in > 95% docs\n",
    "    sublinear_tf=False,     # True per log(tf)\n",
    "    norm='l2'               # Normalizzazione\n",
    ")\n",
    "\n",
    "# Fit e transform\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Similarit√† tra documenti\n",
    "similarity = cosine_similarity(X_train[0:1], X_train)\n",
    "\n",
    "# Keywords per documento\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_scores = X_train[0].toarray()[0]\n",
    "top_indices = np.argsort(tfidf_scores)[::-1][:10]\n",
    "keywords = [feature_names[i] for i in top_indices]\n",
    "```\n",
    "\n",
    "## Parametri TfidfVectorizer\n",
    "\n",
    "| Parametro | Effetto |\n",
    "|-----------|---------|\n",
    "| `sublinear_tf=True` | Usa $1 + \\log(tf)$ invece di tf grezzo |\n",
    "| `smooth_idf=True` | Evita divisione per zero in IDF |\n",
    "| `use_idf=True` | Applica IDF (False = solo TF normalizzato) |\n",
    "| `norm='l2'` | Normalizza vettori a norma 1 |\n",
    "\n",
    "---\n",
    "*Fine Lezione 31 ‚Äî TF-IDF e Text Mining*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
