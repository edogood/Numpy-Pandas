{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59457317",
   "metadata": {},
   "source": [
    "# Lezione 32 â€” Sentiment Analysis\n",
    "\n",
    "## BLOCCO 4: Artificial Intelligence & NLP\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi di Apprendimento\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "1. **Definire** cosa si intende per Sentiment Analysis e le sue applicazioni pratiche\n",
    "2. **Distinguere** tra approcci rule-based e approcci machine learning\n",
    "3. **Implementare** un classificatore di sentiment con sklearn\n",
    "4. **Valutare** le performance con metriche appropriate per testo\n",
    "5. **Gestire** le sfide pratiche: negazione, sarcasmo, dominio-specificitÃ \n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "- Lezione 30: Rappresentazione del testo (BoW, CountVectorizer)\n",
    "- Lezione 31: TF-IDF e Text Mining\n",
    "- Lezione 5-6: Classificazione supervisionata\n",
    "\n",
    "---\n",
    "\n",
    "## Indice\n",
    "\n",
    "1. Teoria â€” Cos'Ã¨ la Sentiment Analysis\n",
    "2. Approcci e Sfide\n",
    "3. Schema Mentale\n",
    "4. Notebook Dimostrativo\n",
    "5. Esercizi Svolti\n",
    "6. Conclusione e Bignami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed083ef8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Teoria â€” Cos'Ã¨ la Sentiment Analysis\n",
    "\n",
    "## 1.1 Definizione Formale\n",
    "\n",
    "La **Sentiment Analysis** (o Opinion Mining) Ã¨ il task di NLP che consiste nell'identificare e classificare l'orientamento emotivo o valutativo espresso in un testo.\n",
    "\n",
    "```\n",
    "Input: \"Questo prodotto Ã¨ eccellente, lo consiglio vivamente!\"\n",
    "Output: POSITIVO (confidence: 0.92)\n",
    "\n",
    "Input: \"Pessima esperienza, mai piÃ¹.\"\n",
    "Output: NEGATIVO (confidence: 0.95)\n",
    "```\n",
    "\n",
    "## 1.2 Livelli di Analisi\n",
    "\n",
    "| Livello | GranularitÃ  | Esempio |\n",
    "|---------|-------------|---------|\n",
    "| **Document-level** | Intero documento | Recensione: Positiva/Negativa |\n",
    "| **Sentence-level** | Singola frase | \"Il cibo era buono, ma il servizio pessimo\" |\n",
    "| **Aspect-level** | Caratteristica specifica | \"Batteria: 4/5, Schermo: 2/5\" |\n",
    "| **Entity-level** | EntitÃ  menzionata | \"Apple: positivo, Samsung: neutro\" |\n",
    "\n",
    "## 1.3 Schemi di Classificazione\n",
    "\n",
    "**Schema Binario:**\n",
    "- Positivo / Negativo\n",
    "\n",
    "**Schema Ternario:**\n",
    "- Positivo / Neutro / Negativo\n",
    "\n",
    "**Schema Continuo:**\n",
    "- Score da -1 (molto negativo) a +1 (molto positivo)\n",
    "\n",
    "**Schema Multi-classe:**\n",
    "- Molto negativo / Negativo / Neutro / Positivo / Molto positivo\n",
    "\n",
    "## 1.4 Applicazioni nel Business\n",
    "\n",
    "| Dominio | Applicazione | Valore |\n",
    "|---------|--------------|--------|\n",
    "| E-commerce | Analisi recensioni prodotti | Product improvement |\n",
    "| Social Media | Brand monitoring | Reputation management |\n",
    "| Finance | News sentiment per trading | Investment signals |\n",
    "| Customer Service | Prioritizzazione ticket | Efficiency |\n",
    "| HR | Analisi survey dipendenti | Employee satisfaction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73f10a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Approcci alla Sentiment Analysis\n",
    "\n",
    "### Approccio 1: Rule-Based (Lexicon-Based)\n",
    "\n",
    "Utilizza dizionari di parole con polaritÃ  predefinita.\n",
    "\n",
    "**Come funziona:**\n",
    "1. Tokenizza il testo\n",
    "2. Cerca ogni token nel lexicon\n",
    "3. Somma gli score di polaritÃ \n",
    "4. Classifica in base allo score totale\n",
    "\n",
    "```\n",
    "Lexicon esempio:\n",
    "  \"eccellente\": +3\n",
    "  \"buono\": +2\n",
    "  \"pessimo\": -3\n",
    "  \"terribile\": -4\n",
    "  \n",
    "Testo: \"Prodotto eccellente ma prezzo pessimo\"\n",
    "Score: +3 + (-3) = 0 â†’ Neutro\n",
    "```\n",
    "\n",
    "**Pro:**\n",
    "- Interpretabile\n",
    "- Non richiede dati di training\n",
    "- Funziona out-of-the-box\n",
    "\n",
    "**Contro:**\n",
    "- Non cattura il contesto\n",
    "- Problemi con negazione (\"non Ã¨ buono\")\n",
    "- Dominio-dipendente\n",
    "- Ignora sarcasmo\n",
    "\n",
    "### Approccio 2: Machine Learning Supervisionato\n",
    "\n",
    "Addestra un classificatore su dati etichettati.\n",
    "\n",
    "**Pipeline tipica:**\n",
    "```\n",
    "Testi etichettati â†’ Preprocessing â†’ Vectorization â†’ Classificatore â†’ Predizione\n",
    "                                   (TF-IDF)        (Naive Bayes,\n",
    "                                                    Logistic Reg,\n",
    "                                                    SVM)\n",
    "```\n",
    "\n",
    "**Pro:**\n",
    "- Cattura pattern complessi\n",
    "- Adattabile al dominio\n",
    "- Performance superiori con dati sufficienti\n",
    "\n",
    "**Contro:**\n",
    "- Richiede dati etichettati\n",
    "- Meno interpretabile\n",
    "- Richiede ritraining per nuovi domini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36413cc8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.6 Le Sfide della Sentiment Analysis\n",
    "\n",
    "### Sfida 1: Negazione\n",
    "\n",
    "```\n",
    "\"Il film non Ã¨ male\" â†’ Positivo (doppia negazione)\n",
    "\"Non mi piace affatto\" â†’ Negativo\n",
    "\"Non posso non consigliarlo\" â†’ Positivo\n",
    "```\n",
    "\n",
    "**Tecniche di mitigazione:**\n",
    "- Prefisso \"NOT_\" ai token dopo negazione\n",
    "- Finestre di negazione (3-5 token)\n",
    "- Modelli che capiscono contesto (LSTM, Transformers)\n",
    "\n",
    "### Sfida 2: Sarcasmo e Ironia\n",
    "\n",
    "```\n",
    "\"Fantastico, un'altra giornata di pioggia\" â†’ Negativo (sarcasmo)\n",
    "\"Che bella sorpresa, il treno Ã¨ in ritardo\" â†’ Negativo (ironia)\n",
    "```\n",
    "\n",
    "Approcci base non catturano queste sfumature.\n",
    "\n",
    "### Sfida 3: Comparazioni\n",
    "\n",
    "```\n",
    "\"Meglio di Samsung ma peggio di Apple\" â†’ Dipende dal target\n",
    "\"Non male come gli altri\" â†’ Relativamente positivo\n",
    "```\n",
    "\n",
    "### Sfida 4: Dominio-specificitÃ \n",
    "\n",
    "```\n",
    "Recensione film: \"La trama Ã¨ prevedibile\" â†’ Negativo\n",
    "Recensione software: \"Il comportamento Ã¨ prevedibile\" â†’ Positivo\n",
    "```\n",
    "\n",
    "Lo stesso termine ha polaritÃ  diverse in contesti diversi.\n",
    "\n",
    "### Sfida 5: SoggettivitÃ  vs OggettivitÃ \n",
    "\n",
    "```\n",
    "\"Il telefono ha 128GB di memoria\" â†’ Oggettivo (no sentiment)\n",
    "\"Il telefono ha troppa poca memoria\" â†’ Soggettivo (negativo)\n",
    "```\n",
    "\n",
    "Distinguere fatti da opinioni Ã¨ un pre-task importante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae527427",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.7 Metriche per Sentiment Analysis\n",
    "\n",
    "### Quando le classi sono bilanciate\n",
    "\n",
    "**Accuracy** Ã¨ sufficiente:\n",
    "$$Accuracy = \\frac{Predizioni\\ Corrette}{Totale\\ Predizioni}$$\n",
    "\n",
    "### Quando le classi sono sbilanciate (comune)\n",
    "\n",
    "**Precision per classe:**\n",
    "$$Precision_c = \\frac{TP_c}{TP_c + FP_c}$$\n",
    "\n",
    "**Recall per classe:**\n",
    "$$Recall_c = \\frac{TP_c}{TP_c + FN_c}$$\n",
    "\n",
    "**F1-Score (media armonica):**\n",
    "$$F1_c = 2 \\times \\frac{Precision_c \\times Recall_c}{Precision_c + Recall_c}$$\n",
    "\n",
    "### Aggregazione Multi-classe\n",
    "\n",
    "| Metodo | Formula | Uso |\n",
    "|--------|---------|-----|\n",
    "| **Macro** | Media semplice per classe | Tutte le classi ugualmente importanti |\n",
    "| **Weighted** | Media pesata per supporto | Classi sbilanciate |\n",
    "| **Micro** | Aggregazione globale | Focus su accuracy generale |\n",
    "\n",
    "### Interpretazione Pratica\n",
    "\n",
    "| Obiettivo | PrioritÃ  |\n",
    "|-----------|----------|\n",
    "| Evitare falsi positivi | Alta Precision |\n",
    "| Evitare falsi negativi | Alta Recall |\n",
    "| Bilanciare entrambi | Alto F1-Score |\n",
    "\n",
    "Per il sentiment: spesso preferiamo alta **recall sulla classe negativa** (non perdere clienti insoddisfatti)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0945201",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Schema Mentale â€” Mappa Logica\n",
    "\n",
    "## Pipeline Completa Sentiment Analysis\n",
    "\n",
    "```\n",
    "                    SENTIMENT ANALYSIS PIPELINE\n",
    "                    \n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      INPUT: Testo Raw                       â”‚\n",
    "â”‚              \"Prodotto fantastico, ma spedizione lenta\"     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    PREPROCESSING                            â”‚\n",
    "â”‚  â€¢ Lowercase                                                â”‚\n",
    "â”‚  â€¢ Rimozione punteggiatura                                  â”‚\n",
    "â”‚  â€¢ Tokenizzazione                                           â”‚\n",
    "â”‚  â€¢ Rimozione stopwords (opzionale)                          â”‚\n",
    "â”‚  â€¢ Gestione negazione (opzionale)                           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   VECTORIZATION                             â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚    Bag of Words         TF-IDF          N-grams            â”‚\n",
    "â”‚    (CountVectorizer)    (TfidfVec)      (ngram_range)      â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚    Matrice sparsa: (n_docs, vocab_size)                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    CLASSIFICATORE                           â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\n",
    "â”‚   â”‚   Naive   â”‚  â”‚ Logistic  â”‚  â”‚    SVM    â”‚              â”‚\n",
    "â”‚   â”‚   Bayes   â”‚  â”‚ Regressionâ”‚  â”‚  (Linear) â”‚              â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚   Baseline       Interpretabile   Alte performance          â”‚\n",
    "â”‚   Veloce         ProbabilitÃ       Margini                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                              â”‚\n",
    "                              â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     OUTPUT                                  â”‚\n",
    "â”‚           Classe: POSITIVO  |  ProbabilitÃ : 0.78            â”‚\n",
    "â”‚           (o score continuo: +0.56)                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Scelta del Classificatore\n",
    "\n",
    "```\n",
    "                    QUALE CLASSIFICATORE?\n",
    "                    \n",
    "              VelocitÃ  importante?\n",
    "                     â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚ SÃ¬                    â”‚ No\n",
    "         â–¼                       â–¼\n",
    "    Naive Bayes            Dataset grande?\n",
    "    (baseline)                   â”‚\n",
    "                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                     â”‚ SÃ¬                    â”‚ No\n",
    "                     â–¼                       â–¼\n",
    "                   SVM               Logistic Regression\n",
    "              (LinearSVC)              (interpretabile)\n",
    "```\n",
    "\n",
    "## Checklist Operativa\n",
    "\n",
    "```\n",
    "â–¡ Dati etichettati sufficienti (>1000 per classe)\n",
    "â–¡ Classi bilanciate (o stratificazione)\n",
    "â–¡ Preprocessing coerente train/test\n",
    "â–¡ Vectorizer fittato SOLO su train\n",
    "â–¡ Cross-validation per tuning\n",
    "â–¡ Metriche appropriate (F1 se sbilanciato)\n",
    "â–¡ Analisi errori (confusion matrix)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3050f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Notebook Dimostrativo\n",
    "\n",
    "## Setup e Dati di Esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfcae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 1: Creazione Dataset di Recensioni\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, f1_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dataset di recensioni in italiano (simulato ma realistico)\n",
    "recensioni = [\n",
    "    # Positive\n",
    "    (\"Prodotto eccellente, super consigliato!\", \"positivo\"),\n",
    "    (\"Ottima qualitÃ , sono molto soddisfatto\", \"positivo\"),\n",
    "    (\"Spedizione veloce e prodotto conforme\", \"positivo\"),\n",
    "    (\"Il migliore acquisto che abbia mai fatto\", \"positivo\"),\n",
    "    (\"Fantastico, lo ricomprerei subito\", \"positivo\"),\n",
    "    (\"QualitÃ  prezzo imbattibile\", \"positivo\"),\n",
    "    (\"Funziona perfettamente, molto contento\", \"positivo\"),\n",
    "    (\"Servizio clienti impeccabile\", \"positivo\"),\n",
    "    (\"Bellissimo, esattamente come in foto\", \"positivo\"),\n",
    "    (\"Top, consiglio vivamente a tutti\", \"positivo\"),\n",
    "    (\"Arrivo puntuale, qualitÃ  ottima\", \"positivo\"),\n",
    "    (\"Sono rimasto piacevolmente sorpreso\", \"positivo\"),\n",
    "    (\"Rapporto qualitÃ  prezzo eccezionale\", \"positivo\"),\n",
    "    (\"Prodotto robusto e ben fatto\", \"positivo\"),\n",
    "    (\"Supera le aspettative\", \"positivo\"),\n",
    "    \n",
    "    # Negative\n",
    "    (\"Prodotto scadente, non lo consiglio\", \"negativo\"),\n",
    "    (\"Pessima qualitÃ , si Ã¨ rotto subito\", \"negativo\"),\n",
    "    (\"Spedizione lentissima, mai piÃ¹\", \"negativo\"),\n",
    "    (\"Deluso totalmente, soldi buttati\", \"negativo\"),\n",
    "    (\"Non funziona come descritto\", \"negativo\"),\n",
    "    (\"QualitÃ  scarsa, materiali economici\", \"negativo\"),\n",
    "    (\"Servizio clienti inesistente\", \"negativo\"),\n",
    "    (\"Prodotto difettoso, reso immediato\", \"negativo\"),\n",
    "    (\"Non vale assolutamente il prezzo\", \"negativo\"),\n",
    "    (\"Esperienza terribile, da evitare\", \"negativo\"),\n",
    "    (\"Arrivato danneggiato, vergognoso\", \"negativo\"),\n",
    "    (\"Totale delusione, non corrisponde\", \"negativo\"),\n",
    "    (\"Materiale scadente, si rompe facilmente\", \"negativo\"),\n",
    "    (\"Mai piÃ¹, assistenza pessima\", \"negativo\"),\n",
    "    (\"Prodotto inutile, non lo ricompro\", \"negativo\"),\n",
    "]\n",
    "\n",
    "# Creazione DataFrame\n",
    "# Ogni riga Ã¨ una recensione con la sua etichetta\n",
    "df = pd.DataFrame(recensioni, columns=['testo', 'sentiment'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET RECENSIONI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDimensione dataset: {len(df)} recensioni\")\n",
    "print(f\"\\nDistribuzione classi:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"\\nEsempi di recensioni:\")\n",
    "print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87649942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 2: Approccio Rule-Based (Lexicon)\n",
    "# ============================================================\n",
    "# Implementazione semplice di sentiment lexicon-based\n",
    "# per capire il concetto prima del ML\n",
    "\n",
    "# Dizionario di polaritÃ  italiano (semplificato)\n",
    "lexicon = {\n",
    "    # Parole positive\n",
    "    'eccellente': 3, 'ottimo': 2, 'ottima': 2, 'fantastico': 3,\n",
    "    'consigliato': 2, 'soddisfatto': 2, 'contento': 2, 'bellissimo': 3,\n",
    "    'perfettamente': 2, 'impeccabile': 3, 'top': 2, 'sorpreso': 1,\n",
    "    'migliore': 2, 'robusto': 1, 'veloce': 1, 'puntuale': 1,\n",
    "    'eccezionale': 3, 'imbattibile': 2, 'vivamente': 1,\n",
    "    \n",
    "    # Parole negative\n",
    "    'scadente': -2, 'pessima': -3, 'pessimo': -3, 'lentissima': -2,\n",
    "    'deluso': -2, 'delusione': -2, 'buttati': -2, 'terribile': -3,\n",
    "    'difettoso': -2, 'vergognoso': -3, 'inesistente': -2,\n",
    "    'scarsa': -2, 'economici': -1, 'rotto': -2, 'danneggiato': -2,\n",
    "    'inutile': -2, 'evitare': -2,\n",
    "}\n",
    "\n",
    "def sentiment_lexicon(testo, lexicon):\n",
    "    \"\"\"\n",
    "    Calcola sentiment score basato su lexicon.\n",
    "    \n",
    "    Args:\n",
    "        testo: stringa da analizzare\n",
    "        lexicon: dizionario {parola: score}\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (score_totale, classe_predetta, parole_trovate)\n",
    "    \"\"\"\n",
    "    # Tokenizzazione semplice: lowercase e split\n",
    "    tokens = testo.lower().split()\n",
    "    \n",
    "    # Calcolo score\n",
    "    score = 0\n",
    "    parole_trovate = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Rimuovi punteggiatura dal token\n",
    "        token_pulito = ''.join(c for c in token if c.isalnum())\n",
    "        \n",
    "        if token_pulito in lexicon:\n",
    "            score += lexicon[token_pulito]\n",
    "            parole_trovate.append((token_pulito, lexicon[token_pulito]))\n",
    "    \n",
    "    # Classificazione basata sullo score\n",
    "    if score > 0:\n",
    "        classe = 'positivo'\n",
    "    elif score < 0:\n",
    "        classe = 'negativo'\n",
    "    else:\n",
    "        classe = 'neutro'\n",
    "    \n",
    "    return score, classe, parole_trovate\n",
    "\n",
    "# Test su alcune recensioni\n",
    "print(\"=\"*60)\n",
    "print(\"APPROCCIO LEXICON-BASED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_reviews = [\n",
    "    \"Prodotto eccellente, super consigliato!\",\n",
    "    \"Pessima qualitÃ , si Ã¨ rotto subito\",\n",
    "    \"Prodotto normale, niente di speciale\",  # Neutro\n",
    "    \"Non Ã¨ male, ma nemmeno eccezionale\",    # Difficile\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    score, classe, parole = sentiment_lexicon(review, lexicon)\n",
    "    print(f\"\\nTesto: '{review}'\")\n",
    "    print(f\"  Score: {score:+d} â†’ Classe: {classe.upper()}\")\n",
    "    print(f\"  Parole rilevate: {parole}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 3: Pipeline ML con Naive Bayes\n",
    "# ============================================================\n",
    "# Approccio supervisionato: addestramento su dati etichettati\n",
    "\n",
    "# Separazione testi e labels\n",
    "X = df['testo'].values  # Feature: testi\n",
    "y = df['sentiment'].values  # Target: etichette\n",
    "\n",
    "# Split train/test con stratificazione\n",
    "# stratify=y mantiene proporzione classi in entrambi i set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,  # 30% per test\n",
    "    random_state=42,\n",
    "    stratify=y  # Mantiene proporzione positivo/negativo\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SPLIT TRAIN/TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set: {len(X_train)} documenti\")\n",
    "print(f\"Test set: {len(X_test)} documenti\")\n",
    "\n",
    "# Verifica bilanciamento dopo split\n",
    "from collections import Counter\n",
    "print(f\"\\nDistribuzione training: {Counter(y_train)}\")\n",
    "print(f\"Distribuzione test: {Counter(y_test)}\")\n",
    "\n",
    "# Step 1: Vectorization con TF-IDF\n",
    "# fit_transform su train, solo transform su test\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  # Limita vocabolario\n",
    "    ngram_range=(1, 2),  # Unigram e bigram\n",
    "    min_df=1,  # Minimo 1 documento (dataset piccolo)\n",
    ")\n",
    "\n",
    "# IMPORTANTE: fit SOLO sul training set\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)  # Solo transform!\n",
    "\n",
    "print(f\"\\nDimensioni matrice TF-IDF:\")\n",
    "print(f\"  Training: {X_train_tfidf.shape}\")\n",
    "print(f\"  Test: {X_test_tfidf.shape}\")\n",
    "\n",
    "# Step 2: Addestramento Naive Bayes\n",
    "# Multinomial NB Ã¨ ideale per dati di testo (counts/frequencies)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 3: Predizione e Valutazione\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RISULTATI NAIVE BAYES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55334666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 4: Confronto Classificatori\n",
    "# ============================================================\n",
    "# Testiamo piÃ¹ classificatori per vedere quale performa meglio\n",
    "\n",
    "# Dizionario classificatori da testare\n",
    "classificatori = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Linear SVM': LinearSVC(random_state=42, max_iter=1000),\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFRONTO CLASSIFICATORI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "risultati = []\n",
    "\n",
    "for nome, clf in classificatori.items():\n",
    "    # Addestramento\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predizione\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    # Metriche\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='positivo')\n",
    "    \n",
    "    risultati.append({\n",
    "        'Classificatore': nome,\n",
    "        'Accuracy': f\"{acc:.2%}\",\n",
    "        'F1-Score': f\"{f1:.2%}\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{nome}:\")\n",
    "    print(f\"  Accuracy: {acc:.2%}\")\n",
    "    print(f\"  F1 (positivo): {f1:.2%}\")\n",
    "\n",
    "# Tabella riassuntiva\n",
    "df_risultati = pd.DataFrame(risultati)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TABELLA RIASSUNTIVA\")\n",
    "print(\"=\"*60)\n",
    "print(df_risultati.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 5: Confusion Matrix e Analisi Errori\n",
    "# ============================================================\n",
    "# Visualizziamo dove il modello sbaglia\n",
    "\n",
    "# Usiamo Logistic Regression come modello finale\n",
    "clf_finale = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf_finale.fit(X_train_tfidf, y_train)\n",
    "y_pred_finale = clf_finale.predict(X_test_tfidf)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_finale, labels=['negativo', 'positivo'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "                    PREDETTO\n",
    "                  Neg    Pos\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "REALE  Neg  â”‚   {cm[0,0]:^3}   â”‚   {cm[0,1]:^3}   â”‚\n",
    "            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "       Pos  â”‚   {cm[1,0]:^3}   â”‚   {cm[1,1]:^3}   â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "# Interpretazione\n",
    "print(\"Interpretazione:\")\n",
    "print(f\"  â€¢ True Negatives (Negâ†’Neg): {cm[0,0]}\")\n",
    "print(f\"  â€¢ False Positives (Negâ†’Pos): {cm[0,1]} - Tipo I error\")\n",
    "print(f\"  â€¢ False Negatives (Posâ†’Neg): {cm[1,0]} - Tipo II error\")\n",
    "print(f\"  â€¢ True Positives (Posâ†’Pos): {cm[1,1]}\")\n",
    "\n",
    "# Analisi errori: quali testi sono stati classificati male?\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANALISI ERRORI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "errori = []\n",
    "for i, (testo, pred, reale) in enumerate(zip(X_test, y_pred_finale, y_test)):\n",
    "    if pred != reale:\n",
    "        errori.append({\n",
    "            'Testo': testo[:50] + '...' if len(testo) > 50 else testo,\n",
    "            'Reale': reale,\n",
    "            'Predetto': pred\n",
    "        })\n",
    "\n",
    "if errori:\n",
    "    print(\"\\nTesti classificati erroneamente:\")\n",
    "    for e in errori:\n",
    "        print(f\"\\n  '{e['Testo']}'\")\n",
    "        print(f\"    Reale: {e['Reale']} | Predetto: {e['Predetto']}\")\n",
    "else:\n",
    "    print(\"\\nNessun errore nel test set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 6: InterpretabilitÃ  - Parole piÃ¹ Importanti\n",
    "# ============================================================\n",
    "# Quali parole influenzano di piÃ¹ la classificazione?\n",
    "\n",
    "# Logistic Regression ha coefficienti interpretabili\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = clf_finale.coef_[0]  # Coefficienti del modello\n",
    "\n",
    "# Creiamo DataFrame con feature e coefficienti\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Ordiniamo per coefficiente\n",
    "# Coefficienti positivi â†’ favoriscono classe \"positivo\"\n",
    "# Coefficienti negativi â†’ favoriscono classe \"negativo\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PAROLE PIÃ™ INDICATIVE PER SENTIMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top 10 parole per sentiment POSITIVO\n",
    "top_positive = importance_df.nlargest(10, 'coefficient')\n",
    "print(\"\\nðŸ“ˆ Top 10 parole â†’ POSITIVO:\")\n",
    "for _, row in top_positive.iterrows():\n",
    "    print(f\"  {row['feature']:25} (coef: {row['coefficient']:+.3f})\")\n",
    "\n",
    "# Top 10 parole per sentiment NEGATIVO\n",
    "top_negative = importance_df.nsmallest(10, 'coefficient')\n",
    "print(\"\\nðŸ“‰ Top 10 parole â†’ NEGATIVO:\")\n",
    "for _, row in top_negative.iterrows():\n",
    "    print(f\"  {row['feature']:25} (coef: {row['coefficient']:+.3f})\")\n",
    "\n",
    "# Insight operativo\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Il modello ha imparato automaticamente quali parole indicano\n",
    "sentiment positivo o negativo, senza bisogno di un lexicon manuale.\n",
    "\n",
    "I coefficienti mostrano l'importanza relativa di ogni termine:\n",
    "  â€¢ Coefficiente alto positivo â†’ forte indicatore positivo\n",
    "  â€¢ Coefficiente alto negativo â†’ forte indicatore negativo\n",
    "  â€¢ Coefficiente vicino a 0 â†’ parola neutrale\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 7: Predizione su Nuovi Testi\n",
    "# ============================================================\n",
    "# Come usare il modello addestrato su testi nuovi\n",
    "\n",
    "def predici_sentiment(testo, vectorizer, classifier):\n",
    "    \"\"\"\n",
    "    Predice il sentiment di un nuovo testo.\n",
    "    \n",
    "    Args:\n",
    "        testo: stringa o lista di stringhe\n",
    "        vectorizer: TfidfVectorizer giÃ  fittato\n",
    "        classifier: classificatore giÃ  addestrato\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predizione, probabilitÃ ) se disponibile\n",
    "    \"\"\"\n",
    "    # Se Ã¨ una singola stringa, convertila in lista\n",
    "    if isinstance(testo, str):\n",
    "        testo = [testo]\n",
    "    \n",
    "    # Trasforma il testo (NON fit!)\n",
    "    X_new = vectorizer.transform(testo)\n",
    "    \n",
    "    # Predizione\n",
    "    predizioni = classifier.predict(X_new)\n",
    "    \n",
    "    # ProbabilitÃ  (se disponibili)\n",
    "    if hasattr(classifier, 'predict_proba'):\n",
    "        probabilita = classifier.predict_proba(X_new)\n",
    "        return list(zip(predizioni, probabilita.max(axis=1)))\n",
    "    else:\n",
    "        return list(zip(predizioni, [None]*len(predizioni)))\n",
    "\n",
    "# Test su nuovi testi\n",
    "nuovi_testi = [\n",
    "    \"Un prodotto davvero eccezionale, lo adoro!\",\n",
    "    \"Mai piÃ¹, esperienza pessima dall'inizio alla fine\",\n",
    "    \"Normale, niente di che\",\n",
    "    \"Il prezzo Ã¨ giusto ma la qualitÃ  poteva essere migliore\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREDIZIONE SU NUOVI TESTI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for testo in nuovi_testi:\n",
    "    risultato = predici_sentiment(testo, vectorizer, clf_finale)\n",
    "    pred, prob = risultato[0]\n",
    "    print(f\"\\nTesto: '{testo}'\")\n",
    "    print(f\"  â†’ Sentiment: {pred.upper()}\")\n",
    "    if prob is not None:\n",
    "        print(f\"  â†’ Confidenza: {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e93872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 8: Cross-Validation per Robustezza\n",
    "# ============================================================\n",
    "# La valutazione su un solo split puÃ² essere instabile\n",
    "# Cross-validation dÃ  una stima piÃ¹ robusta\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Usiamo TUTTI i dati per cross-validation\n",
    "X_all = vectorizer.fit_transform(df['testo'].values)\n",
    "y_all = df['sentiment'].values\n",
    "\n",
    "# Definizione strategia di split\n",
    "# StratifiedKFold mantiene proporzione classi in ogni fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CROSS-VALIDATION (5-Fold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for nome, clf in classificatori.items():\n",
    "    # Cross-validation con accuracy\n",
    "    scores = cross_val_score(clf, X_all, y_all, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"\\n{nome}:\")\n",
    "    print(f\"  Scores per fold: {[f'{s:.2%}' for s in scores]}\")\n",
    "    print(f\"  Media Â± Std: {scores.mean():.2%} Â± {scores.std():.2%}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"INTERPRETAZIONE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "La cross-validation divide i dati in K fold e addestra K modelli,\n",
    "ognuno usando K-1 fold per training e 1 per test.\n",
    "\n",
    "â€¢ Media alta + Std bassa = Modello stabile e affidabile\n",
    "â€¢ Media alta + Std alta = Modello instabile\n",
    "â€¢ Std < 5% Ã¨ generalmente accettabile\n",
    "\n",
    "Con dataset piccoli, la varianza puÃ² essere alta.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c2659",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Esercizi Svolti\n",
    "\n",
    "## Esercizio 1: Pipeline Completa di Sentiment Analysis\n",
    "\n",
    "**Obiettivo:** Costruire una pipeline completa di sentiment analysis su un dataset piÃ¹ ampio, includendo preprocessing, training, valutazione e analisi degli errori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72087a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 1 - SOLUZIONE\n",
    "# Pipeline Completa di Sentiment Analysis\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Dataset esteso (simula dati reali)\n",
    "recensioni_estese = [\n",
    "    # Positive (20)\n",
    "    (\"Prodotto fantastico, qualitÃ  eccezionale\", \"positivo\"),\n",
    "    (\"Consegna rapidissima, tutto perfetto\", \"positivo\"),\n",
    "    (\"Miglior acquisto dell'anno, super soddisfatto\", \"positivo\"),\n",
    "    (\"Ottimo rapporto qualitÃ  prezzo\", \"positivo\"),\n",
    "    (\"Funziona benissimo, come descritto\", \"positivo\"),\n",
    "    (\"Materiali di prima scelta, molto robusto\", \"positivo\"),\n",
    "    (\"Servizio clienti eccellente e disponibile\", \"positivo\"),\n",
    "    (\"Prodotto superiore alle aspettative\", \"positivo\"),\n",
    "    (\"Lo consiglio assolutamente a tutti\", \"positivo\"),\n",
    "    (\"Bellissimo design, funzionale\", \"positivo\"),\n",
    "    (\"Arrivo puntuale, packaging perfetto\", \"positivo\"),\n",
    "    (\"QualitÃ  top, prezzo giusto\", \"positivo\"),\n",
    "    (\"Molto soddisfatto dell'acquisto\", \"positivo\"),\n",
    "    (\"Funziona alla perfezione ogni volta\", \"positivo\"),\n",
    "    (\"Prodotto robusto e ben costruito\", \"positivo\"),\n",
    "    (\"Supera ogni aspettativa, consigliatissimo\", \"positivo\"),\n",
    "    (\"Servizio impeccabile dall'inizio alla fine\", \"positivo\"),\n",
    "    (\"Acquisto che rifarei subito\", \"positivo\"),\n",
    "    (\"Ottima scelta, nessun rimpianto\", \"positivo\"),\n",
    "    (\"Prodotto di qualitÃ  premium\", \"positivo\"),\n",
    "    \n",
    "    # Negative (20)\n",
    "    (\"Prodotto scadente, si Ã¨ rotto subito\", \"negativo\"),\n",
    "    (\"Pessima qualitÃ , non vale il prezzo\", \"negativo\"),\n",
    "    (\"Spedizione lentissima, pacco danneggiato\", \"negativo\"),\n",
    "    (\"Totale delusione, non corrisponde alle foto\", \"negativo\"),\n",
    "    (\"Materiale economico, si graffia facilmente\", \"negativo\"),\n",
    "    (\"Assistenza inesistente, nessuna risposta\", \"negativo\"),\n",
    "    (\"Prodotto difettoso, devo renderlo\", \"negativo\"),\n",
    "    (\"Mai piÃ¹, esperienza terribile\", \"negativo\"),\n",
    "    (\"Non funziona come promesso\", \"negativo\"),\n",
    "    (\"QualitÃ  pessima, soldi buttati\", \"negativo\"),\n",
    "    (\"Arrivato in ritardo e rotto\", \"negativo\"),\n",
    "    (\"Servizio clienti inutile e scortese\", \"negativo\"),\n",
    "    (\"Prodotto fragile, durato una settimana\", \"negativo\"),\n",
    "    (\"Non lo consiglio a nessuno\", \"negativo\"),\n",
    "    (\"Peggiore acquisto della mia vita\", \"negativo\"),\n",
    "    (\"Truffa totale, prodotto diverso\", \"negativo\"),\n",
    "    (\"QualitÃ  scadentissima, evitate\", \"negativo\"),\n",
    "    (\"Reso immediato, inaccettabile\", \"negativo\"),\n",
    "    (\"Prodotto inutilizzabile\", \"negativo\"),\n",
    "    (\"Esperienza da dimenticare\", \"negativo\"),\n",
    "]\n",
    "\n",
    "# Creazione DataFrame\n",
    "df_ext = pd.DataFrame(recensioni_estese, columns=['testo', 'sentiment'])\n",
    "\n",
    "# Step 2: Funzione di preprocessing\n",
    "def preprocess_text(testo):\n",
    "    \"\"\"\n",
    "    Preprocessing standard per testo italiano.\n",
    "    \n",
    "    Steps:\n",
    "    1. Lowercase\n",
    "    2. Rimozione caratteri speciali (mantiene lettere e spazi)\n",
    "    3. Rimozione spazi multipli\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    testo = testo.lower()\n",
    "    \n",
    "    # Rimuovi caratteri speciali (mantieni lettere accentate italiane)\n",
    "    testo = re.sub(r'[^a-zÃ Ã¨Ã©Ã¬Ã²Ã¹\\s]', '', testo)\n",
    "    \n",
    "    # Rimuovi spazi multipli\n",
    "    testo = re.sub(r'\\s+', ' ', testo).strip()\n",
    "    \n",
    "    return testo\n",
    "\n",
    "# Applica preprocessing\n",
    "df_ext['testo_clean'] = df_ext['testo'].apply(preprocess_text)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 1: PIPELINE COMPLETA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: {len(df_ext)} documenti\")\n",
    "print(f\"Distribuzione: {df_ext['sentiment'].value_counts().to_dict()}\")\n",
    "print(f\"\\nEsempio preprocessing:\")\n",
    "print(f\"  Originale: '{df_ext.iloc[0]['testo']}'\")\n",
    "print(f\"  Pulito:    '{df_ext.iloc[0]['testo_clean']}'\")\n",
    "\n",
    "# Step 3: Split con stratificazione\n",
    "X = df_ext['testo_clean'].values\n",
    "y = df_ext['sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 4: Pipeline sklearn\n",
    "# Combina vectorizer e classificatore in un unico oggetto\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=500)),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Addestramento pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Valutazione\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RISULTATI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 6: Analisi errori\n",
    "print(f\"{'='*60}\")\n",
    "print(\"ANALISI ERRORI\")\n",
    "print(\"=\"*60)\n",
    "errori_idx = np.where(y_pred != y_test)[0]\n",
    "print(f\"\\nNumero errori: {len(errori_idx)} su {len(y_test)}\")\n",
    "\n",
    "for idx in errori_idx[:5]:  # Mostra max 5 errori\n",
    "    print(f\"\\n  Testo: '{X_test[idx][:60]}...'\")\n",
    "    print(f\"  Reale: {y_test[idx]} | Predetto: {y_pred[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ef7e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 2: Confronto BoW vs TF-IDF per Sentiment\n",
    "\n",
    "**Obiettivo:** Confrontare le performance di Bag of Words e TF-IDF nella classificazione del sentiment, usando lo stesso classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40cf352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 2 - SOLUZIONE\n",
    "# Confronto BoW vs TF-IDF per Sentiment\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Uso lo stesso dataset dell'esercizio 1\n",
    "X = df_ext['testo_clean'].values\n",
    "y = df_ext['sentiment'].values\n",
    "\n",
    "# Split (stesso seed per confronto equo)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Configurazioni da testare\n",
    "configurazioni = {\n",
    "    'BoW (unigram)': CountVectorizer(ngram_range=(1, 1)),\n",
    "    'BoW (bigram)': CountVectorizer(ngram_range=(1, 2)),\n",
    "    'TF-IDF (unigram)': TfidfVectorizer(ngram_range=(1, 1)),\n",
    "    'TF-IDF (bigram)': TfidfVectorizer(ngram_range=(1, 2)),\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 2: CONFRONTO BoW vs TF-IDF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "risultati = []\n",
    "\n",
    "for nome, vectorizer in configurazioni.items():\n",
    "    # Fit su training, transform su entrambi\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Stesso classificatore per tutti\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    \n",
    "    # Valutazione\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='positivo')\n",
    "    \n",
    "    risultati.append({\n",
    "        'Configurazione': nome,\n",
    "        'Vocab Size': X_train_vec.shape[1],\n",
    "        'Accuracy': f\"{acc:.2%}\",\n",
    "        'F1-Score': f\"{f1:.2%}\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{nome}:\")\n",
    "    print(f\"  Dimensione vocabolario: {X_train_vec.shape[1]}\")\n",
    "    print(f\"  Accuracy: {acc:.2%}\")\n",
    "    print(f\"  F1 (positivo): {f1:.2%}\")\n",
    "\n",
    "# Tabella comparativa\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TABELLA COMPARATIVA\")\n",
    "print(\"=\"*60)\n",
    "df_confronto = pd.DataFrame(risultati)\n",
    "print(df_confronto.to_string(index=False))\n",
    "\n",
    "# Insight\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"INSIGHT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "Osservazioni tipiche:\n",
    "â€¢ TF-IDF spesso supera BoW perchÃ© penalizza parole troppo comuni\n",
    "â€¢ I bigram catturano pattern come \"non buono\", \"molto soddisfatto\"\n",
    "â€¢ Con dataset piccoli, le differenze possono essere minime\n",
    "â€¢ TF-IDF + bigram Ã¨ spesso la scelta migliore per sentiment\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c68cafc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 3: Sistema di Alert per Recensioni Negative\n",
    "\n",
    "**Obiettivo:** Creare un sistema che identifica le recensioni piÃ¹ negative per prioritizzare l'intervento del customer service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 3 - SOLUZIONE\n",
    "# Sistema di Alert per Recensioni Negative\n",
    "# ============================================================\n",
    "\n",
    "class SentimentAlertSystem:\n",
    "    \"\"\"\n",
    "    Sistema di monitoraggio sentiment per customer service.\n",
    "    \n",
    "    FunzionalitÃ :\n",
    "    1. Classifica nuove recensioni\n",
    "    2. Calcola score di negativitÃ \n",
    "    3. Prioritizza interventi basandosi su confidence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Pipeline TF-IDF + Logistic Regression\n",
    "        self.pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=1000)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ])\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def train(self, testi, labels):\n",
    "        \"\"\"Addestra il sistema su dati storici.\"\"\"\n",
    "        self.pipeline.fit(testi, labels)\n",
    "        self.is_trained = True\n",
    "        print(f\"Sistema addestrato su {len(testi)} recensioni\")\n",
    "    \n",
    "    def analyze(self, testi):\n",
    "        \"\"\"\n",
    "        Analizza un batch di recensioni.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame con: testo, sentiment, probabilitÃ , prioritÃ \n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Sistema non addestrato!\")\n",
    "        \n",
    "        # Predizioni e probabilitÃ \n",
    "        predizioni = self.pipeline.predict(testi)\n",
    "        probabilita = self.pipeline.predict_proba(testi)\n",
    "        \n",
    "        # Costruisci risultati\n",
    "        risultati = []\n",
    "        for testo, pred, probs in zip(testi, predizioni, probabilita):\n",
    "            # prob[0] = negativo, prob[1] = positivo (ordine alfabetico)\n",
    "            prob_negativo = probs[0]  # ProbabilitÃ  classe negativa\n",
    "            prob_positivo = probs[1]\n",
    "            \n",
    "            # Calcola prioritÃ : alta se negativo E alta confidenza\n",
    "            if pred == 'negativo':\n",
    "                priorita = 'ALTA' if prob_negativo > 0.8 else 'MEDIA'\n",
    "            else:\n",
    "                priorita = 'BASSA'\n",
    "            \n",
    "            risultati.append({\n",
    "                'testo': testo[:50] + '...' if len(testo) > 50 else testo,\n",
    "                'sentiment': pred,\n",
    "                'confidenza': max(prob_negativo, prob_positivo),\n",
    "                'priorita': priorita\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(risultati)\n",
    "    \n",
    "    def get_alerts(self, testi, threshold=0.7):\n",
    "        \"\"\"\n",
    "        Restituisce solo le recensioni che richiedono attenzione.\n",
    "        \n",
    "        Args:\n",
    "            testi: lista di recensioni\n",
    "            threshold: soglia minima di confidenza per alert\n",
    "        \"\"\"\n",
    "        df_analisi = self.analyze(testi)\n",
    "        \n",
    "        # Filtra: negative con alta confidenza\n",
    "        alerts = df_analisi[\n",
    "            (df_analisi['sentiment'] == 'negativo') & \n",
    "            (df_analisi['confidenza'] >= threshold)\n",
    "        ].sort_values('confidenza', ascending=False)\n",
    "        \n",
    "        return alerts\n",
    "\n",
    "# Addestramento sistema\n",
    "alert_system = SentimentAlertSystem()\n",
    "alert_system.train(df_ext['testo_clean'].values, df_ext['sentiment'].values)\n",
    "\n",
    "# Simula arrivo nuove recensioni\n",
    "nuove_recensioni = [\n",
    "    \"Prodotto arrivato rotto, assistenza inesistente, voglio rimborso!\",\n",
    "    \"Tutto ok, niente di speciale\",\n",
    "    \"Fantastico acquisto, super contento\",\n",
    "    \"Delusione totale, peggio di cosÃ¬ non poteva andare\",\n",
    "    \"Discreto, poteva essere migliore\",\n",
    "    \"Servizio pessimo, non risponde nessuno, vergogna!\",\n",
    "    \"Ottima qualitÃ , lo consiglio\",\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 3: SISTEMA ALERT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analisi completa\n",
    "print(\"\\nðŸ“Š ANALISI COMPLETA:\")\n",
    "df_analisi = alert_system.analyze(nuove_recensioni)\n",
    "print(df_analisi.to_string(index=False))\n",
    "\n",
    "# Solo alert\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸš¨ ALERT - Recensioni che richiedono intervento:\")\n",
    "print(\"=\"*60)\n",
    "alerts = alert_system.get_alerts(nuove_recensioni, threshold=0.7)\n",
    "if len(alerts) > 0:\n",
    "    print(alerts.to_string(index=False))\n",
    "else:\n",
    "    print(\"Nessun alert critico\")\n",
    "\n",
    "# Report statistico\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸ“ˆ REPORT STATISTICO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Totale recensioni analizzate: {len(nuove_recensioni)}\")\n",
    "print(f\"Negative: {len(df_analisi[df_analisi['sentiment'] == 'negativo'])}\")\n",
    "print(f\"Positive: {len(df_analisi[df_analisi['sentiment'] == 'positivo'])}\")\n",
    "print(f\"Alert alta prioritÃ : {len(df_analisi[df_analisi['priorita'] == 'ALTA'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e892e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Conclusione Operativa\n",
    "\n",
    "## Cosa Abbiamo Imparato\n",
    "\n",
    "| Concetto | Definizione | Applicazione |\n",
    "|----------|-------------|--------------|\n",
    "| **Sentiment Analysis** | Classificazione di testi per polaritÃ  | Recensioni, social media, survey |\n",
    "| **Lexicon-based** | Dizionari di parole con score | Prototipazione rapida, baseline |\n",
    "| **ML-based** | Classificatori addestrati su dati | Produzione, alta accuratezza |\n",
    "| **Preprocessing** | Pulizia e normalizzazione testo | Step obbligatorio pre-ML |\n",
    "| **Confusion Matrix** | Matrice di errori | Diagnostica modello |\n",
    "\n",
    "## Quando Usare Sentiment Analysis\n",
    "\n",
    "| Caso d'Uso | Approccio Consigliato | PerchÃ© |\n",
    "|------------|----------------------|--------|\n",
    "| PoC veloce | Lexicon-based | Nessun training richiesto |\n",
    "| Produzione | ML (LogReg + TF-IDF) | Bilanciato accuratezza/velocitÃ  |\n",
    "| Alta accuratezza | Ensemble o Deep Learning | Cattura pattern complessi |\n",
    "| Dominio specifico | Fine-tuning su dati dominio | Adatta lessico |\n",
    "\n",
    "## Workflow Operativo\n",
    "\n",
    "```python\n",
    "# Template produzione\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. Prepara dati\n",
    "X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# 2. Costruisci pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 3. Valida con cross-validation\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "print(f\"CV Score: {scores.mean():.2%} Â± {scores.std():.2%}\")\n",
    "\n",
    "# 4. Train finale e test\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(classification_report(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# 5. Deploy\n",
    "joblib.dump(pipeline, 'sentiment_model.pkl')\n",
    "```\n",
    "\n",
    "## Errori Comuni da Evitare\n",
    "\n",
    "1. **Data leakage**: fit vectorizer su tutto il dataset invece che solo train\n",
    "2. **Ignorare sbilanciamento**: accuracy alta ma recall bassa su classe minoritaria\n",
    "3. **No preprocessing**: rumore e inconsistenza nei dati\n",
    "4. **Overfitting**: modello troppo complesso per dati scarsi\n",
    "5. **Ignorare il dominio**: sentiment diverso in contesti diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e21d5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Bignami â€” Scheda di Riferimento Rapido\n",
    "\n",
    "## Pipeline Minima\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Costruzione\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Training\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predizione\n",
    "sentiments = pipeline.predict(new_texts)\n",
    "probabilities = pipeline.predict_proba(new_texts)\n",
    "```\n",
    "\n",
    "## Classificatori per Sentiment\n",
    "\n",
    "| Classificatore | Import | Pro | Contro |\n",
    "|----------------|--------|-----|--------|\n",
    "| Naive Bayes | `MultinomialNB()` | Veloce, baseline | Assume indipendenza |\n",
    "| Logistic Regression | `LogisticRegression()` | Interpretabile | Lineare |\n",
    "| Linear SVM | `LinearSVC()` | Alte performance | No probabilitÃ  |\n",
    "\n",
    "## Metriche Chiave\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import (accuracy_score, f1_score,\n",
    "                              classification_report, confusion_matrix)\n",
    "\n",
    "# Report completo\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Singole metriche\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, pos_label='negativo')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "```\n",
    "\n",
    "## Scelta Rapida Metriche\n",
    "\n",
    "| Scenario | Metrica | Motivazione |\n",
    "|----------|---------|-------------|\n",
    "| Classi bilanciate | Accuracy | Semplice e interpretabile |\n",
    "| Evitare falsi allarmi | Precision | Minimizza FP |\n",
    "| Non perdere critici | Recall | Minimizza FN |\n",
    "| Bilanciato | F1-Score | Media armonica |\n",
    "\n",
    "## Checklist Pre-Deploy\n",
    "\n",
    "```\n",
    "â–¡ Split stratificato\n",
    "â–¡ Vectorizer fittato solo su train\n",
    "â–¡ Cross-validation completata\n",
    "â–¡ Confusion matrix analizzata\n",
    "â–¡ Performance su classe minoritaria ok\n",
    "â–¡ Pipeline serializzata con joblib\n",
    "```\n",
    "\n",
    "---\n",
    "*Fine Lezione 32 â€” Sentiment Analysis*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
