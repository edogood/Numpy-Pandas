{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a532efb8",
   "metadata": {},
   "source": [
    "# Lezione 19 ‚Äî Introduzione all'Unsupervised Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della Lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "1. **Distinguere** chiaramente apprendimento supervisionato da non supervisionato\n",
    "2. **Comprendere** cosa significa lavorare senza un target e quali implicazioni ha\n",
    "3. **Riconoscere** la differenza fondamentale tra \"pattern nei dati\" e \"verit√†\"\n",
    "4. **Evitare** gli errori concettuali pi√π comuni che portano a conclusioni sbagliate\n",
    "5. **Orientarti** tra le diverse famiglie di metodi unsupervised\n",
    "\n",
    "---\n",
    "\n",
    "## Perch√© questa lezione √® importante\n",
    "\n",
    "Fino ad ora abbiamo sempre lavorato con una variabile target: prevedere un prezzo, classificare un cliente, stimare una probabilit√†. Questo √® il mondo **supervisionato**.\n",
    "\n",
    "Ma nella realt√† aziendale, la maggior parte dei dati **non ha etichette**:\n",
    "- I log di navigazione di un sito web\n",
    "- Le transazioni di un e-commerce\n",
    "- I dati di sensori industriali\n",
    "- I comportamenti di utilizzo di un'app\n",
    "\n",
    "L'unsupervised learning ci permette di **estrarre struttura** da questi dati anche senza sapere \"la risposta giusta\". \n",
    "\n",
    "**Attenzione critica:** questa libert√† √® anche il suo rischio principale. Senza un target che ci dica se abbiamo ragione o torto, √® facile trovare pattern che non significano nulla.\n",
    "\n",
    "---\n",
    "\n",
    "## Ruolo nel percorso\n",
    "\n",
    "| Lezioni 11-18 | Lezioni 19-28 |\n",
    "|---------------|---------------|\n",
    "| Supervised Learning | Unsupervised Learning |\n",
    "| Target noto (y) | Nessun target |\n",
    "| Valutazione oggettiva (accuracy, RMSE) | Valutazione indiretta e soggettiva |\n",
    "| Obiettivo: predire | Obiettivo: scoprire struttura |\n",
    "\n",
    "Questa lezione introduce il **framework mentale** necessario per affrontare le lezioni successive (clustering, riduzione dimensionale, anomaly detection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec1fad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 1 ‚Äî Teoria Concettuale\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 Supervised vs Unsupervised: la differenza fondamentale\n",
    "\n",
    "### Apprendimento Supervisionato (ripasso)\n",
    "\n",
    "Nel supervised learning abbiamo sempre:\n",
    "- **Input X**: le feature che descrivono ogni osservazione\n",
    "- **Output y**: la variabile target che vogliamo predire\n",
    "\n",
    "Il modello \"impara\" la relazione $f$ tale che $y \\approx f(X)$ minimizzando un errore misurabile.\n",
    "\n",
    "**Esempio:** Prevedere il prezzo di una casa ($y$) dalle sue caratteristiche ($X$: metri quadri, zona, stanze...).\n",
    "\n",
    "La presenza del target ci d√†:\n",
    "- Un **obiettivo chiaro**: minimizzare l'errore tra predizione e realt√†\n",
    "- Una **metrica oggettiva**: possiamo calcolare RMSE, accuracy, F1 e sapere se miglioriamo\n",
    "- Un **criterio di stop**: quando l'errore √® accettabile, ci fermiamo\n",
    "\n",
    "---\n",
    "\n",
    "### Apprendimento Non Supervisionato\n",
    "\n",
    "Nell'unsupervised learning abbiamo **solo X**. Non esiste $y$.\n",
    "\n",
    "$$\\text{Dati} = \\{x_1, x_2, ..., x_n\\} \\quad \\text{(nessun target)}$$\n",
    "\n",
    "L'obiettivo non √® predire qualcosa di noto, ma **scoprire struttura nascosta**:\n",
    "- Gruppi naturali (clustering)\n",
    "- Relazioni tra variabili (riduzione dimensionale)\n",
    "- Osservazioni anomale (anomaly detection)\n",
    "- Pattern di co-occorrenza (association rules)\n",
    "\n",
    "**Esempio:** Dato l'elenco delle transazioni di un e-commerce, trovare gruppi di clienti con comportamenti simili. Nessuno ci ha detto quanti gruppi esistono o quali sono.\n",
    "\n",
    "---\n",
    "\n",
    "### Tabella comparativa\n",
    "\n",
    "| Aspetto | Supervised | Unsupervised |\n",
    "|---------|------------|--------------|\n",
    "| **Dati** | X e y | Solo X |\n",
    "| **Obiettivo** | Predire y | Scoprire struttura |\n",
    "| **Valutazione** | Errore su y (oggettiva) | Metriche interne + interpretazione (soggettiva) |\n",
    "| **Domanda** | \"Quanto √® accurata la predizione?\" | \"Ha senso questa struttura?\" |\n",
    "| **Rischio principale** | Overfitting sul target | Trovare pattern senza significato |\n",
    "| **Esempi** | Regressione, Classificazione | Clustering, PCA, Anomaly Detection |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b776dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.2 L'assenza del target: cosa implica davvero\n",
    "\n",
    "Quando non abbiamo un target, perdiamo qualcosa di fondamentale: **la possibilit√† di sapere se abbiamo ragione**.\n",
    "\n",
    "### Nel supervised learning\n",
    "\n",
    "```\n",
    "Modello predice: y_pred = 150.000‚Ç¨\n",
    "Valore reale:    y_true = 145.000‚Ç¨\n",
    "Errore:          5.000‚Ç¨ ‚Üí posso migliorare\n",
    "```\n",
    "\n",
    "Posso calcolare l'errore, confrontare modelli, scegliere il migliore.\n",
    "\n",
    "### Nell'unsupervised learning\n",
    "\n",
    "```\n",
    "Algoritmo trova: 3 cluster\n",
    "Domanda:         Sono giusti? Dovevano essere 4? O 2?\n",
    "Risposta:        Non lo sappiamo. Non c'√® \"verit√†\".\n",
    "```\n",
    "\n",
    "Non esiste un $y$ con cui confrontarsi. L'algoritmo trova **una struttura possibile**, non **la struttura vera**.\n",
    "\n",
    "---\n",
    "\n",
    "### Le conseguenze pratiche\n",
    "\n",
    "1. **Non possiamo usare accuracy, RMSE, F1** ‚Äî queste metriche richiedono un target\n",
    "\n",
    "2. **Dobbiamo usare metriche \"interne\"** ‚Äî che valutano la coerenza della struttura trovata (es. Silhouette per il clustering), ma non la sua \"verit√†\"\n",
    "\n",
    "3. **Servono validazioni esterne** ‚Äî esperti di dominio, buon senso, utilit√† business\n",
    "\n",
    "4. **I risultati sono ipotesi, non fatti** ‚Äî un cluster non √® una \"classe vera\", √® un raggruppamento che l'algoritmo ha trovato conveniente\n",
    "\n",
    "---\n",
    "\n",
    "### Esempio concreto\n",
    "\n",
    "Immagina di clusterizzare i clienti di un negozio e trovare 4 gruppi:\n",
    "- Cluster 0: acquisti frequenti, scontrino basso\n",
    "- Cluster 1: acquisti rari, scontrino alto\n",
    "- Cluster 2: nuovi clienti\n",
    "- Cluster 3: clienti dormienti\n",
    "\n",
    "**Domanda:** Questi 4 gruppi \"esistono davvero\"?\n",
    "\n",
    "**Risposta onesta:** Non lo sappiamo. L'algoritmo ha trovato 4 regioni nello spazio delle feature. Se sono utili per il marketing, li usiamo. Ma non sono \"la verit√†\" ‚Äî sono un'interpretazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97e9bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.3 Pattern vs Verit√†: la distinzione critica\n",
    "\n",
    "Questo √® forse il concetto pi√π importante di tutta la lezione.\n",
    "\n",
    "### Cosa trova un algoritmo unsupervised?\n",
    "\n",
    "Un algoritmo unsupervised trova **pattern statistici** nei dati:\n",
    "- Punti vicini nello spazio delle feature ‚Üí cluster\n",
    "- Direzioni di massima varianza ‚Üí componenti principali\n",
    "- Punti isolati ‚Üí anomalie\n",
    "\n",
    "Questi pattern sono **matematicamente veri**: l'algoritmo li ha calcolati correttamente.\n",
    "\n",
    "Ma essere matematicamente vero **non significa essere significativo**.\n",
    "\n",
    "---\n",
    "\n",
    "### L'illusione del pattern\n",
    "\n",
    "Considera questo esperimento mentale:\n",
    "\n",
    "1. Genero 1000 punti **completamente casuali** in 2 dimensioni\n",
    "2. Applico K-Means con K=3\n",
    "3. L'algoritmo trova **sempre** 3 cluster\n",
    "\n",
    "Quei 3 cluster esistono? Matematicamente s√¨: l'algoritmo ha diviso lo spazio in 3 regioni.\n",
    "Hanno significato? **No**: i dati erano casuali, non c'era struttura da trovare.\n",
    "\n",
    "---\n",
    "\n",
    "### La regola d'oro\n",
    "\n",
    "> **Un pattern trovato da un algoritmo √® un'ipotesi, non una scoperta.**\n",
    "\n",
    "Prima di concludere che \"esistono 3 tipi di clienti\" o che \"questa variabile √® anomala\", devi:\n",
    "\n",
    "1. **Verificare la stabilit√†**: se cambio random seed o parametri, il pattern resta?\n",
    "2. **Verificare l'interpretabilit√†**: il pattern ha senso nel dominio?\n",
    "3. **Verificare l'utilit√†**: il pattern √® azionabile? Serve a qualcosa?\n",
    "\n",
    "Se la risposta a tutte e tre √® s√¨, il pattern √® **probabilmente** significativo.\n",
    "Se la risposta a una √® no, il pattern potrebbe essere **rumore travestito da struttura**.\n",
    "\n",
    "---\n",
    "\n",
    "### Tabella riassuntiva\n",
    "\n",
    "| Concetto | Pattern | Verit√† |\n",
    "|----------|---------|--------|\n",
    "| **Definizione** | Regolarit√† statistica nei dati | Struttura reale nel fenomeno |\n",
    "| **Chi lo trova** | L'algoritmo | Il dominio/la realt√† |\n",
    "| **Sempre presente?** | S√¨ (anche nei dati casuali) | No (solo se esiste) |\n",
    "| **Verifica** | Metriche interne | Esperti, test, business |\n",
    "| **Rischio** | Sovra-interpretazione | Nessuno (√® la realt√†) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968a829",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.4 Errori concettuali tipici\n",
    "\n",
    "Prima di passare agli algoritmi specifici, √® fondamentale conoscere gli errori che anche professionisti esperti commettono.\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 1: Trattare i cluster come classi vere\n",
    "\n",
    "**L'errore:** \"L'algoritmo ha trovato 4 cluster, quindi esistono 4 tipi di clienti\"\n",
    "\n",
    "**Il problema:** L'algoritmo divide sempre lo spazio. Se gli chiedi 4 gruppi, ne trova 4. Se gli chiedi 10, ne trova 10. Questo non prova che quei gruppi \"esistano\".\n",
    "\n",
    "**Come evitarlo:** Valida con il dominio. I cluster hanno senso? Sono stabili? Sono azionabili?\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 2: Usare metriche supervisionate\n",
    "\n",
    "**L'errore:** Calcolare accuracy o F1 su un risultato di clustering\n",
    "\n",
    "**Il problema:** Accuracy richiede etichette vere. Se le avessimo, non saremmo in unsupervised.\n",
    "\n",
    "**Come evitarlo:** Usa metriche appropriate: Silhouette, Davies-Bouldin, errore di ricostruzione.\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 3: Non scalare le feature\n",
    "\n",
    "**L'errore:** Applicare K-Means su dati con scale diverse (es. et√† 0-100, reddito 0-100.000)\n",
    "\n",
    "**Il problema:** Le distanze saranno dominate dalla variabile con scala maggiore. L'algoritmo vedr√† solo il reddito.\n",
    "\n",
    "**Come evitarlo:** StandardScaler o MinMaxScaler prima di qualsiasi algoritmo basato su distanze.\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 4: Scegliere K \"a sentimento\"\n",
    "\n",
    "**L'errore:** \"Facciamo 5 cluster perch√© mi sembra un buon numero\"\n",
    "\n",
    "**Il problema:** Nessuna base razionale. Potrebbe essere 3, potrebbe essere 8.\n",
    "\n",
    "**Come evitarlo:** Usa metodi sistematici (Elbow, Silhouette) e confronta pi√π valori.\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 5: Confondere riduzione dimensionale con selezione feature\n",
    "\n",
    "**L'errore:** \"Ho fatto PCA, quindi ho le feature pi√π importanti\"\n",
    "\n",
    "**Il problema:** PCA crea **combinazioni lineari** delle feature originali. La prima componente principale non √® \"la feature migliore\" ‚Äî √® un mix di tutte.\n",
    "\n",
    "**Come evitarlo:** Distingui: selezione = scegli feature originali, riduzione = crei nuove dimensioni.\n",
    "\n",
    "---\n",
    "\n",
    "### Errore 6: Validare con etichette nascoste\n",
    "\n",
    "**L'errore:** Avere etichette nel dataset, fingere di non vederle, clusterizzare, poi calcolare accuracy sulle etichette \"nascoste\"\n",
    "\n",
    "**Il problema:** Questo √® un benchmark controllato, non un vero problema unsupervised. Le etichette influenzano implicitamente le scelte.\n",
    "\n",
    "**Come evitarlo:** Se usi etichette per validare, dichiaralo esplicitamente come esperimento controllato.\n",
    "\n",
    "---\n",
    "\n",
    "### Tabella riassuntiva degli errori\n",
    "\n",
    "| Errore | Conseguenza | Soluzione |\n",
    "|--------|-------------|-----------|\n",
    "| Cluster = classi vere | Conclusioni infondate | Validazione dominio |\n",
    "| Metriche supervisionate | Numeri senza senso | Metriche interne |\n",
    "| No scaling | Risultati distorti | Preprocessing |\n",
    "| K a caso | Struttura arbitraria | Metodi sistematici |\n",
    "| PCA = selezione | Confusione interpretativa | Capire la differenza |\n",
    "| Etichette nascoste | Falsa sicurezza | Dichiarare il setup |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ba402",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1.5 Le famiglie di metodi unsupervised\n",
    "\n",
    "Prima di entrare nel dettaglio di ciascun algoritmo (lezioni successive), √® utile avere una mappa delle principali famiglie.\n",
    "\n",
    "---\n",
    "\n",
    "### Famiglia 1: Clustering\n",
    "\n",
    "**Obiettivo:** Raggruppare osservazioni simili tra loro.\n",
    "\n",
    "**Domanda tipica:** \"Quanti tipi di clienti ho? Come sono fatti?\"\n",
    "\n",
    "**Algoritmi principali:**\n",
    "- **K-Means**: assume cluster sferici, numero K fisso\n",
    "- **Clustering Gerarchico**: costruisce una gerarchia di gruppi (dendrogramma)\n",
    "- **DBSCAN**: trova cluster di densit√† arbitraria, identifica outlier\n",
    "\n",
    "**Metrica tipica:** Silhouette score, Davies-Bouldin index\n",
    "\n",
    "---\n",
    "\n",
    "### Famiglia 2: Riduzione Dimensionale\n",
    "\n",
    "**Obiettivo:** Comprimere i dati in meno dimensioni preservando l'informazione.\n",
    "\n",
    "**Domanda tipica:** \"Ho 100 feature, posso ridurle a 10 senza perdere troppo?\"\n",
    "\n",
    "**Algoritmi principali:**\n",
    "- **PCA (Principal Component Analysis)**: lineare, preserva varianza\n",
    "- **t-SNE, UMAP**: non lineari, ottimi per visualizzazione 2D/3D\n",
    "\n",
    "**Metrica tipica:** Varianza spiegata, errore di ricostruzione\n",
    "\n",
    "---\n",
    "\n",
    "### Famiglia 3: Anomaly Detection\n",
    "\n",
    "**Obiettivo:** Identificare osservazioni rare o anomale.\n",
    "\n",
    "**Domanda tipica:** \"Quali transazioni sono sospette? Quali sensori hanno valori strani?\"\n",
    "\n",
    "**Algoritmi principali:**\n",
    "- **Isolation Forest**: isola punti anomali con pochi split\n",
    "- **One-Class SVM**: definisce un confine attorno ai dati \"normali\"\n",
    "- **LOF (Local Outlier Factor)**: confronta densit√† locale\n",
    "\n",
    "**Metrica tipica:** Score di anomalia, percentuale di outlier\n",
    "\n",
    "---\n",
    "\n",
    "### Famiglia 4: Association Rules (cenni)\n",
    "\n",
    "**Obiettivo:** Trovare regole di co-occorrenza.\n",
    "\n",
    "**Domanda tipica:** \"Chi compra pane, compra anche latte?\"\n",
    "\n",
    "**Algoritmi principali:**\n",
    "- **Apriori, FP-Growth**\n",
    "\n",
    "**Metrica tipica:** Support, confidence, lift\n",
    "\n",
    "*Non approfondiremo questa famiglia nel corso, ma √® utile sapere che esiste.*\n",
    "\n",
    "---\n",
    "\n",
    "### Mappa visiva\n",
    "\n",
    "```\n",
    "UNSUPERVISED LEARNING\n",
    "‚îú‚îÄ‚îÄ Clustering\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ K-Means (Lezione 20)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Gerarchico (Lezione 22)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ DBSCAN (Lezione 23)\n",
    "‚îú‚îÄ‚îÄ Riduzione Dimensionale\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PCA (Lezioni 24-25)\n",
    "‚îú‚îÄ‚îÄ Anomaly Detection\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Isolation Forest (Lezione 26)\n",
    "‚îî‚îÄ‚îÄ Feature Engineering Unsupervised (Lezione 27)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bca15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 2 ‚Äî Schema Mentale e Mappa Logica\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Quando usare l'unsupervised learning\n",
    "\n",
    "### Situazioni in cui l'unsupervised √® appropriato\n",
    "\n",
    "| Situazione | Esempio | Metodo suggerito |\n",
    "|------------|---------|------------------|\n",
    "| **Nessun target disponibile** | Log di navigazione senza conversioni etichettate | Clustering, Anomaly Detection |\n",
    "| **Esplorare dati nuovi** | Dataset appena acquisito, nessuna ipotesi | Clustering + PCA per visualizzare |\n",
    "| **Segmentare senza bias** | Dividere clienti senza categorie predefinite | Clustering |\n",
    "| **Ridurre complessit√†** | 500 feature ‚Üí 50 componenti | PCA |\n",
    "| **Trovare anomalie** | Frodi, guasti, errori di sistema | Isolation Forest |\n",
    "| **Preprocessing per supervised** | Creare feature clustering prima di classificare | Clustering come feature engineering |\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Quando NON usare l'unsupervised learning\n",
    "\n",
    "### Situazioni in cui l'unsupervised √® sbagliato\n",
    "\n",
    "| Situazione | Perch√© √® sbagliato | Cosa fare invece |\n",
    "|------------|-------------------|------------------|\n",
    "| **Hai un target chiaro** | Spreca informazione, risultati peggiori | Usa supervised |\n",
    "| **Devi fare predizioni precise** | Unsupervised non predice | Usa regressione/classificazione |\n",
    "| **Servono metriche oggettive** | Unsupervised ha solo metriche interne | Definisci un target o proxy |\n",
    "| **I cluster devono essere \"giusti\"** | Non esiste \"giusto\" senza etichette | Definisci criteri business |\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 Segnali pratici nei dati\n",
    "\n",
    "Come capire se i dati si prestano a un'analisi unsupervised?\n",
    "\n",
    "### Segnali positivi\n",
    "\n",
    "- **Alta dimensionalit√†**: molte feature ‚Üí PCA pu√≤ aiutare\n",
    "- **Nessuna variabile target naturale**: non c'√® una \"risposta\" da predire\n",
    "- **Obiettivo esplorativo**: vuoi capire, non predire\n",
    "- **Dati eterogenei**: mix di comportamenti diversi ‚Üí clustering\n",
    "- **Punti isolati visibili**: scatter plot mostra separazione ‚Üí clustering possibile\n",
    "\n",
    "### Segnali negativi\n",
    "\n",
    "- **Dati uniformi**: tutto simile, nessun gruppo naturale\n",
    "- **Forte rumore**: struttura nascosta dal rumore\n",
    "- **Poche osservazioni**: clustering instabile con pochi dati\n",
    "- **Feature irrilevanti dominanti**: clustering guidato da rumore\n",
    "\n",
    "---\n",
    "\n",
    "## 2.4 Flowchart decisionale\n",
    "\n",
    "```\n",
    "Ho un target y?\n",
    "‚îú‚îÄ‚îÄ S√å ‚Üí Supervised Learning (Regressione/Classificazione)\n",
    "‚îî‚îÄ‚îÄ NO ‚Üí Qual √® l'obiettivo?\n",
    "    ‚îú‚îÄ‚îÄ Raggruppare ‚Üí Clustering\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ Cluster sferici, K noto ‚Üí K-Means\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ Forma arbitraria, outlier ‚Üí DBSCAN\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ Gerarchia di gruppi ‚Üí Hierarchical\n",
    "    ‚îú‚îÄ‚îÄ Ridurre dimensioni ‚Üí PCA / UMAP\n",
    "    ‚îú‚îÄ‚îÄ Trovare anomalie ‚Üí Isolation Forest\n",
    "    ‚îî‚îÄ‚îÄ Pattern di co-occorrenza ‚Üí Association Rules\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8456c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 3 ‚Äî Notebook Dimostrativo\n",
    "\n",
    "In questa sezione mostriamo i concetti chiave con codice semplice e commentato.\n",
    "\n",
    "---\n",
    "\n",
    "## Demo 1: Supervised vs Unsupervised ‚Äî la stessa analisi, due mondi diversi\n",
    "\n",
    "Generiamo dati sintetici e mostriamo la differenza fondamentale tra i due approcci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53602336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 1: Supervised vs Unsupervised\n",
    "# ============================================\n",
    "# Obiettivo: mostrare la differenza fondamentale tra i due paradigmi\n",
    "# Useremo lo stesso dataset, ma con approcci diversi\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fissiamo il seed per riproducibilit√†\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generiamo dati con 3 gruppi naturali\n",
    "# In questo caso CONOSCIAMO le etichette (per scopi didattici)\n",
    "X, y_true = make_blobs(\n",
    "    n_samples=300,      # 300 osservazioni\n",
    "    centers=3,          # 3 centri (gruppi)\n",
    "    cluster_std=0.8,    # deviazione standard di ogni gruppo\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCENARIO: Stesso dataset, due approcci diversi\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDimensioni X: {X.shape}\")\n",
    "print(f\"Classi vere (y_true): {np.unique(y_true)}\")\n",
    "\n",
    "# Visualizziamo i dati con le etichette vere\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Dati con etichette vere (se le avessimo)\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', s=50, alpha=0.7)\n",
    "axes[0].set_title('Dati CON etichette (supervised)')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "\n",
    "# Plot 2: Dati senza etichette (come li vede l'unsupervised)\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c='gray', s=50, alpha=0.7)\n",
    "axes[1].set_title('Dati SENZA etichette (unsupervised)')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "\n",
    "# Plot 3: Clustering K-Means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "axes[2].scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis', s=50, alpha=0.7)\n",
    "axes[2].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
    "                c='red', marker='X', s=200, edgecolors='black', linewidth=2, label='Centroidi')\n",
    "axes[2].set_title('Clustering K-Means (senza usare y)')\n",
    "axes[2].set_xlabel('Feature 1')\n",
    "axes[2].set_ylabel('Feature 2')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# CONFRONTO METRICHE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFRONTO METRICHE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Supervised: possiamo calcolare accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.3, random_state=42)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n[SUPERVISED] Accuracy sul test set: {acc:.3f}\")\n",
    "print(\"   ‚Üí Possiamo dire SE il modello √® buono (confronto con y vero)\")\n",
    "\n",
    "# Unsupervised: NON possiamo calcolare accuracy, usiamo Silhouette\n",
    "sil = silhouette_score(X, y_kmeans)\n",
    "print(f\"\\n[UNSUPERVISED] Silhouette score: {sil:.3f}\")\n",
    "print(\"   ‚Üí Indica coesione interna, ma NON se i cluster sono 'giusti'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEZIONE CHIAVE:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Nel supervised abbiamo un 'giudice' (y) che dice se abbiamo ragione.\")\n",
    "print(\"Nell'unsupervised non c'√® giudice: troviamo struttura, non verit√†.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef972ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 2: L'illusione del pattern ‚Äî clustering su dati casuali\n",
    "\n",
    "Questa demo mostra il pericolo principale dell'unsupervised: trovare \"struttura\" dove non esiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 2: L'illusione del pattern\n",
    "# ============================================\n",
    "# Obiettivo: mostrare che K-Means trova SEMPRE cluster,\n",
    "# anche quando i dati sono completamente casuali\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generiamo dati COMPLETAMENTE CASUALI (nessuna struttura)\n",
    "X_random = np.random.randn(300, 2)  # 300 punti, distribuzione normale standard\n",
    "\n",
    "# Applichiamo K-Means con K=3\n",
    "kmeans_random = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_random = kmeans_random.fit_predict(X_random)\n",
    "\n",
    "# Calcoliamo il Silhouette (anche se non c'√® struttura vera)\n",
    "sil_random = silhouette_score(X_random, labels_random)\n",
    "\n",
    "# Visualizziamo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Dati originali (nessun colore = nessun gruppo)\n",
    "axes[0].scatter(X_random[:, 0], X_random[:, 1], c='gray', s=50, alpha=0.6)\n",
    "axes[0].set_title('Dati CASUALI (nessuna struttura reale)')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Clustering K-Means (trova comunque 3 gruppi!)\n",
    "scatter = axes[1].scatter(X_random[:, 0], X_random[:, 1], c=labels_random, \n",
    "                           cmap='viridis', s=50, alpha=0.6)\n",
    "axes[1].scatter(kmeans_random.cluster_centers_[:, 0], kmeans_random.cluster_centers_[:, 1], \n",
    "                c='red', marker='X', s=200, edgecolors='black', linewidth=2)\n",
    "axes[1].set_title(f'K-Means trova 3 cluster! (Silhouette={sil_random:.3f})')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Riflessione critica\n",
    "print(\"=\"*60)\n",
    "print(\"ATTENZIONE CRITICA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nI dati erano COMPLETAMENTE CASUALI.\")\n",
    "print(f\"Eppure K-Means ha trovato 3 cluster con Silhouette = {sil_random:.3f}\")\n",
    "print(f\"\\nQuesto dimostra che:\")\n",
    "print(\"1. L'algoritmo trova SEMPRE cluster (√® il suo lavoro)\")\n",
    "print(\"2. Il Silhouette score esiste anche per dati senza struttura\")\n",
    "print(\"3. Un pattern trovato NON significa un pattern VERO\")\n",
    "print(\"\\n‚Üí MAI fidarsi ciecamente di un risultato unsupervised!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62947f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 3: L'importanza dello scaling\n",
    "\n",
    "Mostriamo come la mancanza di preprocessing pu√≤ distorcere completamente il risultato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47763dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 3: L'importanza dello scaling\n",
    "# ============================================\n",
    "# Obiettivo: mostrare come scale diverse distorcono il clustering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Creiamo dati con 2 gruppi CHIARI ma scale MOLTO diverse\n",
    "# Feature 1: et√† (range 20-60)\n",
    "# Feature 2: reddito annuo (range 20000-80000)\n",
    "\n",
    "n_per_group = 100\n",
    "\n",
    "# Gruppo 1: giovani con reddito basso\n",
    "gruppo1_eta = np.random.normal(28, 3, n_per_group)\n",
    "gruppo1_reddito = np.random.normal(30000, 5000, n_per_group)\n",
    "\n",
    "# Gruppo 2: senior con reddito alto\n",
    "gruppo2_eta = np.random.normal(50, 5, n_per_group)\n",
    "gruppo2_reddito = np.random.normal(65000, 8000, n_per_group)\n",
    "\n",
    "# Combiniamo\n",
    "X_unscaled = np.vstack([\n",
    "    np.column_stack([gruppo1_eta, gruppo1_reddito]),\n",
    "    np.column_stack([gruppo2_eta, gruppo2_reddito])\n",
    "])\n",
    "\n",
    "# Le etichette vere (per confronto visivo)\n",
    "y_vero = np.array([0]*n_per_group + [1]*n_per_group)\n",
    "\n",
    "# Clustering SENZA scaling\n",
    "kmeans_unscaled = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_unscaled = kmeans_unscaled.fit_predict(X_unscaled)\n",
    "\n",
    "# Clustering CON scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_unscaled)\n",
    "kmeans_scaled = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
    "\n",
    "# Confronto errori\n",
    "errori_unscaled = (labels_unscaled != y_vero).sum()\n",
    "errori_scaled = (labels_scaled != y_vero).sum()\n",
    "# Nota: i label potrebbero essere invertiti, consideriamo entrambi i casi\n",
    "errori_unscaled = min(errori_unscaled, 200 - errori_unscaled)\n",
    "errori_scaled = min(errori_scaled, 200 - errori_scaled)\n",
    "\n",
    "# Visualizzazione\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Dati originali con etichette vere\n",
    "axes[0].scatter(X_unscaled[:, 0], X_unscaled[:, 1], c=y_vero, cmap='coolwarm', s=50, alpha=0.7)\n",
    "axes[0].set_title('Gruppi VERI')\n",
    "axes[0].set_xlabel('Et√†')\n",
    "axes[0].set_ylabel('Reddito (‚Ç¨)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Clustering senza scaling\n",
    "axes[1].scatter(X_unscaled[:, 0], X_unscaled[:, 1], c=labels_unscaled, cmap='coolwarm', s=50, alpha=0.7)\n",
    "axes[1].set_title(f'K-Means SENZA scaling\\n(errori: {errori_unscaled})')\n",
    "axes[1].set_xlabel('Et√†')\n",
    "axes[1].set_ylabel('Reddito (‚Ç¨)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Clustering con scaling (visualizziamo nello spazio originale)\n",
    "axes[2].scatter(X_unscaled[:, 0], X_unscaled[:, 1], c=labels_scaled, cmap='coolwarm', s=50, alpha=0.7)\n",
    "axes[2].set_title(f'K-Means CON scaling\\n(errori: {errori_scaled})')\n",
    "axes[2].set_xlabel('Et√†')\n",
    "axes[2].set_ylabel('Reddito (‚Ç¨)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Spiegazione\n",
    "print(\"=\"*60)\n",
    "print(\"COSA √à SUCCESSO?\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nRange et√†: {X_unscaled[:, 0].min():.0f} - {X_unscaled[:, 0].max():.0f}\")\n",
    "print(f\"Range reddito: {X_unscaled[:, 1].min():.0f} - {X_unscaled[:, 1].max():.0f}\")\n",
    "print(f\"\\nIl reddito ha un range ~1000 volte maggiore dell'et√†.\")\n",
    "print(\"Senza scaling, K-Means 'vede' solo il reddito.\")\n",
    "print(\"Con scaling, entrambe le feature hanno lo stesso peso.\")\n",
    "print(f\"\\n‚Üí Errori senza scaling: {errori_unscaled}\")\n",
    "print(f\"‚Üí Errori con scaling: {errori_scaled}\")\n",
    "print(\"\\nLEZIONE: Scala SEMPRE prima di usare algoritmi basati su distanza!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8e996",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 4 ‚Äî Esercizi Svolti\n",
    "\n",
    "Ogni esercizio √® risolto passo per passo con spiegazioni dettagliate.\n",
    "\n",
    "---\n",
    "\n",
    "## Esercizio 19.1 ‚Äî Classificare scenari: Supervised o Unsupervised?\n",
    "\n",
    "**Consegna:** Per ciascuno dei seguenti scenari, stabilisci se richiede un approccio supervised o unsupervised. Giustifica la risposta.\n",
    "\n",
    "### Scenario A\n",
    "> Un'azienda di telecomunicazioni vuole prevedere quali clienti abbandoneranno il servizio nei prossimi 3 mesi. Ha dati storici con l'indicazione di chi ha effettivamente abbandonato.\n",
    "\n",
    "### Scenario B\n",
    "> Un e-commerce vuole segmentare la propria base clienti per personalizzare le campagne marketing. Non ha categorie predefinite.\n",
    "\n",
    "### Scenario C\n",
    "> Una banca vuole identificare transazioni fraudolente. Ha pochissimi esempi di frodi confermate (< 0.1% dei dati).\n",
    "\n",
    "### Scenario D\n",
    "> Un'azienda vuole ridurre il numero di feature in un dataset con 500 variabili prima di applicare un modello predittivo.\n",
    "\n",
    "### Scenario E\n",
    "> Un ospedale vuole prevedere la durata della degenza di un paziente basandosi su dati clinici. Ha dati storici completi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 19.1 ‚Äî SOLUZIONE\n",
    "# ============================================\n",
    "# Non serve codice: l'esercizio √® di ragionamento concettuale.\n",
    "# Scriviamo la soluzione come output strutturato.\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 19.1 ‚Äî SOLUZIONE RAGIONATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "soluzioni = {\n",
    "    \"A\": {\n",
    "        \"scenario\": \"Prevedere churn con dati storici etichettati\",\n",
    "        \"risposta\": \"SUPERVISED\",\n",
    "        \"giustificazione\": \"\"\"\n",
    "        Abbiamo un target chiaro: cliente ha abbandonato s√¨/no (variabile binaria).\n",
    "        I dati storici contengono l'etichetta per ogni cliente.\n",
    "        Si tratta di un problema di CLASSIFICAZIONE binaria.\n",
    "        Algoritmi appropriati: Logistic Regression, Random Forest, XGBoost.\"\"\"\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"scenario\": \"Segmentare clienti senza categorie predefinite\",\n",
    "        \"risposta\": \"UNSUPERVISED\",\n",
    "        \"giustificazione\": \"\"\"\n",
    "        Non esiste un target: non sappiamo quanti segmenti esistono n√© quali sono.\n",
    "        L'obiettivo √® SCOPRIRE gruppi naturali nei dati.\n",
    "        Si tratta di un problema di CLUSTERING.\n",
    "        Algoritmi appropriati: K-Means, DBSCAN, Clustering Gerarchico.\"\"\"\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"scenario\": \"Identificare frodi con pochissimi esempi etichettati\",\n",
    "        \"risposta\": \"IBRIDO (ma principalmente UNSUPERVISED)\",\n",
    "        \"giustificazione\": \"\"\"\n",
    "        Tecnicamente esistono etichette, ma sono troppo poche e sbilanciate.\n",
    "        Supervised classico funzionerebbe male (classe rara = 0.1%).\n",
    "        Approccio consigliato: ANOMALY DETECTION (unsupervised).\n",
    "        L'idea: le frodi sono 'anomalie' rispetto al comportamento normale.\n",
    "        Algoritmi: Isolation Forest, One-Class SVM, Autoencoder.\"\"\"\n",
    "    },\n",
    "    \"D\": {\n",
    "        \"scenario\": \"Ridurre 500 feature a meno variabili\",\n",
    "        \"risposta\": \"UNSUPERVISED\",\n",
    "        \"giustificazione\": \"\"\"\n",
    "        L'obiettivo non √® predire qualcosa, ma COMPRIMERE i dati.\n",
    "        Si tratta di RIDUZIONE DIMENSIONALE.\n",
    "        Algoritmo principale: PCA (Principal Component Analysis).\n",
    "        Nota: questo √® un preprocessing, il modello finale sar√† supervised.\"\"\"\n",
    "    },\n",
    "    \"E\": {\n",
    "        \"scenario\": \"Prevedere durata degenza con dati storici\",\n",
    "        \"risposta\": \"SUPERVISED\",\n",
    "        \"giustificazione\": \"\"\"\n",
    "        Abbiamo un target chiaro: durata in giorni (variabile continua).\n",
    "        I dati storici contengono la durata effettiva per ogni paziente.\n",
    "        Si tratta di un problema di REGRESSIONE.\n",
    "        Algoritmi appropriati: Linear Regression, Random Forest Regressor.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for lettera, info in soluzioni.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SCENARIO {lettera}: {info['scenario']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n‚úÖ RISPOSTA: {info['risposta']}\")\n",
    "    print(f\"\\nüìù GIUSTIFICAZIONE:{info['giustificazione']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RIEPILOGO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n| Scenario | Approccio | Tipo problema |\")\n",
    "print(\"|----------|-----------|---------------|\")\n",
    "print(\"| A        | Supervised | Classificazione |\")\n",
    "print(\"| B        | Unsupervised | Clustering |\")\n",
    "print(\"| C        | Unsupervised | Anomaly Detection |\")\n",
    "print(\"| D        | Unsupervised | Riduzione dimensionale |\")\n",
    "print(\"| E        | Supervised | Regressione |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30315c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 19.2 ‚Äî Identificare errori concettuali\n",
    "\n",
    "**Consegna:** Leggi il seguente resoconto di un'analisi e identifica TUTTI gli errori concettuali. Spiega perch√© sono errori e come correggerli.\n",
    "\n",
    "### Resoconto dell'analista\n",
    "\n",
    "> \"Ho preso i dati dei clienti con 15 feature e ho applicato K-Means con K=5 perch√© mi sembrava un numero ragionevole. L'algoritmo ha trovato 5 cluster perfetti. \n",
    ">\n",
    "> Ho calcolato l'accuracy del clustering confrontando con le categorie marketing storiche e ho ottenuto 72%. \n",
    ">\n",
    "> Non ho fatto scaling perch√© le feature erano gi√† tutte in euro. \n",
    ">\n",
    "> Ho concluso che esistono 5 tipi di clienti e ho presentato i risultati al management come verit√† definitiva.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54117123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 19.2 ‚Äî SOLUZIONE\n",
    "# ============================================\n",
    "# Analizziamo il resoconto e identifichiamo gli errori\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 19.2 ‚Äî ANALISI DEGLI ERRORI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "errori = [\n",
    "    {\n",
    "        \"numero\": 1,\n",
    "        \"citazione\": \"K=5 perch√© mi sembrava un numero ragionevole\",\n",
    "        \"errore\": \"Scelta di K arbitraria\",\n",
    "        \"perche\": \"\"\"\n",
    "        Non c'√® base razionale per K=5. Potevano essere 3, 7, o 12.\n",
    "        L'analista ha scelto 'a sentimento', non con criteri oggettivi.\"\"\",\n",
    "        \"correzione\": \"\"\"\n",
    "        Usare metodi sistematici: Elbow method, Silhouette score.\n",
    "        Provare pi√π valori di K e confrontare le metriche.\n",
    "        Vedremo questi metodi nella Lezione 21.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"numero\": 2,\n",
    "        \"citazione\": \"Ho calcolato l'accuracy del clustering\",\n",
    "        \"errore\": \"Uso di metrica supervisionata su problema unsupervised\",\n",
    "        \"perche\": \"\"\"\n",
    "        Accuracy richiede etichette 'vere'. Nel clustering non esistono.\n",
    "        Le 'categorie marketing storiche' non sono la verit√†, sono un'altra segmentazione.\"\"\",\n",
    "        \"correzione\": \"\"\"\n",
    "        Usare metriche interne: Silhouette, Davies-Bouldin.\n",
    "        Se si confronta con etichette esistenti, dichiararlo come esperimento\n",
    "        controllato, non come 'accuracy vera'.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"numero\": 3,\n",
    "        \"citazione\": \"Non ho fatto scaling perch√© le feature erano gi√† tutte in euro\",\n",
    "        \"errore\": \"Confusione su quando serve lo scaling\",\n",
    "        \"perche\": \"\"\"\n",
    "        Anche se tutte in euro, i RANGE possono essere diversi:\n",
    "        - Scontrino medio: 10-500‚Ç¨\n",
    "        - Spesa annua: 100-50.000‚Ç¨\n",
    "        Il secondo dominerebbe le distanze.\"\"\",\n",
    "        \"correzione\": \"\"\"\n",
    "        Verificare sempre i range. Se diversi, scalare.\n",
    "        StandardScaler o MinMaxScaler prima di K-Means.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"numero\": 4,\n",
    "        \"citazione\": \"L'algoritmo ha trovato 5 cluster perfetti\",\n",
    "        \"errore\": \"Fraintendimento del funzionamento dell'algoritmo\",\n",
    "        \"perche\": \"\"\"\n",
    "        K-Means trova SEMPRE K cluster, per costruzione.\n",
    "        Non esistono 'cluster perfetti' ‚Äî l'algoritmo divide lo spazio comunque.\n",
    "        Anche dati casuali producono cluster.\"\"\",\n",
    "        \"correzione\": \"\"\"\n",
    "        Non interpretare il risultato come 'perfetto'.\n",
    "        Valutare la qualit√† con metriche e interpretazione dominio.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"numero\": 5,\n",
    "        \"citazione\": \"Esistono 5 tipi di clienti [...] verit√† definitiva\",\n",
    "        \"errore\": \"Presentare ipotesi come verit√†\",\n",
    "        \"perche\": \"\"\"\n",
    "        I cluster sono IPOTESI, non SCOPERTE.\n",
    "        Non sappiamo se quei 5 gruppi 'esistono davvero'.\n",
    "        √à una struttura che l'algoritmo ha trovato conveniente.\"\"\",\n",
    "        \"correzione\": \"\"\"\n",
    "        Presentare come: 'Abbiamo identificato una possibile segmentazione...'\n",
    "        Validare con esperti di dominio.\n",
    "        Testare stabilit√† (cambiando seed, parametri).\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for err in errori:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ERRORE #{err['numero']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nüìú CITAZIONE: \\\"{err['citazione']}\\\"\")\n",
    "    print(f\"\\n‚ùå ERRORE: {err['errore']}\")\n",
    "    print(f\"\\n‚ö†Ô∏è  PERCH√â √à UN PROBLEMA:{err['perche']}\")\n",
    "    print(f\"\\n‚úÖ CORREZIONE:{err['correzione']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RIEPILOGO: 5 ERRORI IDENTIFICATI\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. K scelto arbitrariamente ‚Üí Usare Elbow/Silhouette\n",
    "2. Accuracy su clustering ‚Üí Usare metriche interne\n",
    "3. No scaling con range diversi ‚Üí Sempre verificare e scalare\n",
    "4. 'Cluster perfetti' ‚Üí K-Means trova sempre K gruppi\n",
    "5. Ipotesi = Verit√† ‚Üí Presentare come interpretazione, non fatto\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af7b28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Esercizio 19.3 ‚Äî Confrontare clustering con e senza scaling\n",
    "\n",
    "**Consegna:** \n",
    "1. Genera un dataset sintetico con 2 gruppi di clienti caratterizzati da:\n",
    "   - Et√† (range ~20-60 anni)\n",
    "   - Numero di acquisti annui (range ~5-50)\n",
    "   - Spesa totale annua (range ~500-50.000‚Ç¨)\n",
    "2. Applica K-Means con K=2 **senza** scaling\n",
    "3. Applica K-Means con K=2 **con** scaling\n",
    "4. Confronta i risultati e spiega le differenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 19.3 ‚Äî SOLUZIONE COMPLETA\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 19.3 ‚Äî CONFRONTO SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 1: Generazione del dataset sintetico\n",
    "# ============================================\n",
    "print(\"\\nüìä PASSO 1: Generazione dataset\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_clienti = 150  # 150 clienti per gruppo\n",
    "\n",
    "# Gruppo 1: Clienti \"young & frequent\"\n",
    "# - Giovani (25-35 anni)\n",
    "# - Molti acquisti (30-45/anno)\n",
    "# - Spesa media (5000-15000‚Ç¨/anno)\n",
    "gruppo1_eta = np.random.normal(30, 3, n_clienti)\n",
    "gruppo1_acquisti = np.random.normal(38, 5, n_clienti)\n",
    "gruppo1_spesa = np.random.normal(10000, 3000, n_clienti)\n",
    "\n",
    "# Gruppo 2: Clienti \"mature & premium\"\n",
    "# - Pi√π anziani (45-55 anni)\n",
    "# - Meno acquisti (10-20/anno)\n",
    "# - Alta spesa (30000-45000‚Ç¨/anno)\n",
    "gruppo2_eta = np.random.normal(50, 4, n_clienti)\n",
    "gruppo2_acquisti = np.random.normal(15, 4, n_clienti)\n",
    "gruppo2_spesa = np.random.normal(38000, 6000, n_clienti)\n",
    "\n",
    "# Combiniamo i dati\n",
    "X_clienti = np.vstack([\n",
    "    np.column_stack([gruppo1_eta, gruppo1_acquisti, gruppo1_spesa]),\n",
    "    np.column_stack([gruppo2_eta, gruppo2_acquisti, gruppo2_spesa])\n",
    "])\n",
    "\n",
    "# Etichette vere (per valutazione)\n",
    "y_vero = np.array([0]*n_clienti + [1]*n_clienti)\n",
    "\n",
    "print(f\"Clienti totali: {X_clienti.shape[0]}\")\n",
    "print(f\"Feature: Et√†, Acquisti/anno, Spesa/anno\")\n",
    "print(f\"\\nRange per feature:\")\n",
    "print(f\"  Et√†:      {X_clienti[:, 0].min():.1f} - {X_clienti[:, 0].max():.1f} anni\")\n",
    "print(f\"  Acquisti: {X_clienti[:, 1].min():.1f} - {X_clienti[:, 1].max():.1f} /anno\")\n",
    "print(f\"  Spesa:    {X_clienti[:, 2].min():.0f} - {X_clienti[:, 2].max():.0f} ‚Ç¨/anno\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 2: K-Means SENZA scaling\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PASSO 2: K-Means SENZA scaling\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "kmeans_noscale = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_noscale = kmeans_noscale.fit_predict(X_clienti)\n",
    "\n",
    "# Calcolo errori (considerando possibile inversione etichette)\n",
    "errori_noscale = min(\n",
    "    (labels_noscale != y_vero).sum(),\n",
    "    (labels_noscale != (1 - y_vero)).sum()\n",
    ")\n",
    "\n",
    "print(f\"Cluster assegnati: {np.bincount(labels_noscale)}\")\n",
    "print(f\"Errori di assegnazione: {errori_noscale}/{len(y_vero)} ({100*errori_noscale/len(y_vero):.1f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: K-Means CON scaling\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PASSO 3: K-Means CON scaling\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_clienti)\n",
    "\n",
    "print(\"Dopo scaling, tutte le feature hanno media‚âà0 e std‚âà1:\")\n",
    "print(f\"  Et√† scalata:      media={X_scaled[:, 0].mean():.3f}, std={X_scaled[:, 0].std():.3f}\")\n",
    "print(f\"  Acquisti scalati: media={X_scaled[:, 1].mean():.3f}, std={X_scaled[:, 1].std():.3f}\")\n",
    "print(f\"  Spesa scalata:    media={X_scaled[:, 2].mean():.3f}, std={X_scaled[:, 2].std():.3f}\")\n",
    "\n",
    "kmeans_scaled = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
    "\n",
    "errori_scaled = min(\n",
    "    (labels_scaled != y_vero).sum(),\n",
    "    (labels_scaled != (1 - y_vero)).sum()\n",
    ")\n",
    "\n",
    "print(f\"\\nCluster assegnati: {np.bincount(labels_scaled)}\")\n",
    "print(f\"Errori di assegnazione: {errori_scaled}/{len(y_vero)} ({100*errori_scaled/len(y_vero):.1f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 4: Visualizzazione e confronto\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä PASSO 4: Visualizzazione\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Gruppi veri (Et√† vs Spesa per chiarezza)\n",
    "axes[0].scatter(X_clienti[y_vero==0, 0], X_clienti[y_vero==0, 2]/1000, \n",
    "                c='blue', s=50, alpha=0.6, label='Gruppo 1 (young)')\n",
    "axes[0].scatter(X_clienti[y_vero==1, 0], X_clienti[y_vero==1, 2]/1000, \n",
    "                c='red', s=50, alpha=0.6, label='Gruppo 2 (mature)')\n",
    "axes[0].set_title('Gruppi VERI')\n",
    "axes[0].set_xlabel('Et√†')\n",
    "axes[0].set_ylabel('Spesa annua (k‚Ç¨)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Clustering senza scaling\n",
    "colors_noscale = ['blue' if l==0 else 'red' for l in labels_noscale]\n",
    "axes[1].scatter(X_clienti[:, 0], X_clienti[:, 2]/1000, \n",
    "                c=colors_noscale, s=50, alpha=0.6)\n",
    "axes[1].set_title(f'K-Means SENZA scaling\\nErrori: {errori_noscale} ({100*errori_noscale/len(y_vero):.0f}%)')\n",
    "axes[1].set_xlabel('Et√†')\n",
    "axes[1].set_ylabel('Spesa annua (k‚Ç¨)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Clustering con scaling\n",
    "colors_scaled = ['blue' if l==0 else 'red' for l in labels_scaled]\n",
    "axes[2].scatter(X_clienti[:, 0], X_clienti[:, 2]/1000, \n",
    "                c=colors_scaled, s=50, alpha=0.6)\n",
    "axes[2].set_title(f'K-Means CON scaling\\nErrori: {errori_scaled} ({100*errori_scaled/len(y_vero):.0f}%)')\n",
    "axes[2].set_xlabel('Et√†')\n",
    "axes[2].set_ylabel('Spesa annua (k‚Ç¨)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# SPIEGAZIONE FINALE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù SPIEGAZIONE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "COSA √à SUCCESSO?\n",
    "\n",
    "Range originali:\n",
    "  - Et√†:      ~40 unit√† di variazione (20-60)\n",
    "  - Acquisti: ~45 unit√† di variazione (5-50)  \n",
    "  - Spesa:    ~50.000 unit√† di variazione (500-50.000)\n",
    "\n",
    "SENZA SCALING:\n",
    "  La spesa ha un range ~1000x maggiore delle altre feature.\n",
    "  K-Means calcola distanze euclidee, quindi \"vede\" principalmente la spesa.\n",
    "  Le altre feature (et√†, acquisti) sono quasi ignorate.\n",
    "  Risultato: clustering basato quasi solo sulla spesa.\n",
    "  ‚Üí Errori: {errori_noscale} ({100*errori_noscale/len(y_vero):.0f}%)\n",
    "\n",
    "CON SCALING:\n",
    "  Tutte le feature hanno media=0 e std=1.\n",
    "  K-Means considera equamente tutte e 3 le feature.\n",
    "  Il pattern multidimensionale viene catturato correttamente.\n",
    "  ‚Üí Errori: {errori_scaled} ({100*errori_scaled/len(y_vero):.0f}%)\n",
    "\n",
    "LEZIONE:\n",
    "  Prima di qualsiasi algoritmo basato su distanza (K-Means, DBSCAN, KNN...),\n",
    "  verifica i range delle feature e applica StandardScaler o MinMaxScaler.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89d21f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 5 ‚Äî Conclusione Operativa\n",
    "\n",
    "---\n",
    "\n",
    "## Cosa portarsi a casa\n",
    "\n",
    "### I 5 punti fondamentali di questa lezione\n",
    "\n",
    "1. **Supervised ‚â† Unsupervised**\n",
    "   - Supervised: hai un target, puoi misurare l'errore oggettivamente\n",
    "   - Unsupervised: nessun target, puoi solo valutare la coerenza interna\n",
    "\n",
    "2. **Pattern ‚â† Verit√†**\n",
    "   - Un algoritmo trova sempre struttura (√® il suo lavoro)\n",
    "   - Trovare un pattern non prova che sia significativo\n",
    "   - Validare sempre con dominio, stabilit√†, utilit√†\n",
    "\n",
    "3. **Scaling √® obbligatorio**\n",
    "   - Prima di K-Means, DBSCAN, PCA: sempre StandardScaler\n",
    "   - Feature con range diversi distorcono i risultati\n",
    "\n",
    "4. **Metriche diverse per problemi diversi**\n",
    "   - Supervised: accuracy, RMSE, F1\n",
    "   - Unsupervised: Silhouette, errore di ricostruzione, interpretazione\n",
    "\n",
    "5. **I cluster sono ipotesi, non scoperte**\n",
    "   - Presentare come interpretazione, non come fatto\n",
    "   - Testare stabilit√†, consultare esperti\n",
    "\n",
    "---\n",
    "\n",
    "## Errori da evitare\n",
    "\n",
    "| Errore | Conseguenza |\n",
    "|--------|-------------|\n",
    "| Scegliere K \"a sentimento\" | Struttura arbitraria |\n",
    "| Usare accuracy su clustering | Numero senza significato |\n",
    "| Non scalare le feature | Risultati distorti |\n",
    "| Interpretare cluster come verit√† | Conclusioni infondate |\n",
    "| Saltare la validazione dominio | Pattern spur√Æ accettati |\n",
    "\n",
    "---\n",
    "\n",
    "## Ponte verso la prossima lezione\n",
    "\n",
    "In questa lezione abbiamo costruito il **framework mentale** per l'unsupervised learning:\n",
    "- Quando usarlo e quando no\n",
    "- Come ragionare senza un target\n",
    "- Quali errori evitare\n",
    "\n",
    "Nella **Lezione 20** entreremo nel dettaglio del primo algoritmo di clustering: **K-Means**.\n",
    "\n",
    "Vedremo:\n",
    "- Come funziona geometricamente\n",
    "- Il ruolo dei centroidi\n",
    "- Le assunzioni forti del modello\n",
    "- Quando funziona bene e quando fallisce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6bea6e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìå Bignami ‚Äî Lezione 19\n",
    "\n",
    "## Definizioni chiave\n",
    "\n",
    "| Termine | Definizione |\n",
    "|---------|-------------|\n",
    "| **Supervised Learning** | Apprendimento con target noto (y). Obiettivo: predire. |\n",
    "| **Unsupervised Learning** | Apprendimento senza target. Obiettivo: scoprire struttura. |\n",
    "| **Clustering** | Raggruppare osservazioni simili tra loro. |\n",
    "| **Riduzione dimensionale** | Comprimere i dati in meno variabili preservando informazione. |\n",
    "| **Anomaly Detection** | Identificare osservazioni rare o anomale. |\n",
    "| **Silhouette score** | Metrica interna per valutare la qualit√† del clustering (-1 a +1). |\n",
    "\n",
    "---\n",
    "\n",
    "## Formule da ricordare\n",
    "\n",
    "**Silhouette per un punto:**\n",
    "$$s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}$$\n",
    "\n",
    "Dove:\n",
    "- $a(i)$ = distanza media dai punti dello stesso cluster\n",
    "- $b(i)$ = distanza media dai punti del cluster pi√π vicino\n",
    "\n",
    "**Interpretazione:**\n",
    "- $s \\approx +1$: punto ben assegnato\n",
    "- $s \\approx 0$: punto al confine\n",
    "- $s \\approx -1$: punto assegnato al cluster sbagliato\n",
    "\n",
    "---\n",
    "\n",
    "## Checklist operativa\n",
    "\n",
    "Prima di qualsiasi analisi unsupervised:\n",
    "\n",
    "- [ ] Verifica che NON esista un target utilizzabile\n",
    "- [ ] Definisci l'obiettivo: clustering? riduzione? anomalie?\n",
    "- [ ] Controlla i range delle feature\n",
    "- [ ] Applica StandardScaler se usi algoritmi basati su distanza\n",
    "- [ ] Scegli l'algoritmo coerente con l'obiettivo\n",
    "- [ ] Valuta con metriche interne + interpretazione dominio\n",
    "- [ ] Testa la stabilit√† (cambia seed, parametri)\n",
    "- [ ] Presenta i risultati come ipotesi, non come verit√†\n",
    "\n",
    "---\n",
    "\n",
    "## Codice template\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 1. Scaling (SEMPRE prima di clustering)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. Clustering\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 3. Valutazione interna\n",
    "sil = silhouette_score(X_scaled, labels)\n",
    "print(f\"Silhouette: {sil:.3f}\")\n",
    "\n",
    "# 4. Interpretazione (da fare manualmente!)\n",
    "# ‚Üí I cluster hanno senso nel dominio?\n",
    "# ‚Üí Sono stabili cambiando seed?\n",
    "# ‚Üí Sono azionabili?\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Prossima lezione:** K-Means Clustering ‚Äî geometria, centroidi, assunzioni del modello."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
