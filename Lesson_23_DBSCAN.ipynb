{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0353990d",
   "metadata": {},
   "source": [
    "# üéØ Lezione 23 ‚Äî DBSCAN: Clustering Basato su Densit√†\n",
    "\n",
    "## Obiettivi di Apprendimento\n",
    "\n",
    "| # | Obiettivo | Livello |\n",
    "|---|-----------|---------|\n",
    "| 1 | Capire la differenza tra clustering basato su densit√† e distanza | üü¢ Base |\n",
    "| 2 | Comprendere i parametri `eps` e `min_samples` | üü¢ Base |\n",
    "| 3 | Identificare core points, border points e noise | üü° Intermedio |\n",
    "| 4 | Usare il k-distance graph per scegliere eps | üü° Intermedio |\n",
    "| 5 | Applicare DBSCAN a dati con forme complesse | üü° Intermedio |\n",
    "| 6 | Confrontare DBSCAN con K-Means e Gerarchico | üî¥ Avanzato |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Indice\n",
    "\n",
    "1. **Teoria** ‚Äî Densit√†, parametri, tipi di punti\n",
    "2. **Schema Mentale** ‚Äî Workflow DBSCAN\n",
    "3. **Demo Pratiche** ‚Äî 5 demo progressive\n",
    "4. **Esercizi** ‚Äî 3 esercizi con soluzioni\n",
    "5. **Conclusione** ‚Äî Cosa portarsi a casa\n",
    "6. **Bignami** ‚Äî Reference card\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Setup\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f836ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ 1. Teoria\n",
    "\n",
    "### 1.1 Perch√© DBSCAN?\n",
    "\n",
    "**Limiti di K-Means e Gerarchico:**\n",
    "- Richiedono K a priori (o comunque una decisione)\n",
    "- Assumono cluster **sferici/convessi**\n",
    "- Ogni punto DEVE appartenere a un cluster\n",
    "\n",
    "**DBSCAN risolve tutto questo:**\n",
    "- **Non richiede K** ‚Äî trova automaticamente il numero di cluster\n",
    "- **Forme arbitrarie** ‚Äî pu√≤ trovare cluster di qualsiasi forma\n",
    "- **Identifica outliers** ‚Äî i punti \"rumore\" sono etichettati come -1\n",
    "\n",
    "```\n",
    "DBSCAN = Density-Based Spatial Clustering of Applications with Noise\n",
    "```\n",
    "\n",
    "### üìä Confronto Visivo\n",
    "\n",
    "```\n",
    "K-Means:                    DBSCAN:\n",
    "    ‚óè‚óè‚óè     ‚óã‚óã‚óã                ‚óè‚óè‚óè‚óè‚óè‚óè\n",
    "   ‚óè‚óè‚óè‚óè‚óè   ‚óã‚óã‚óã‚óã‚óã              ‚óè‚óè    ‚óè‚óè\n",
    "    ‚óè‚óè‚óè     ‚óã‚óã‚óã              ‚óè‚óè      ‚óè‚óè\n",
    "                              ‚óè‚óè‚óè‚óè‚óè‚óè‚óè\n",
    "  (cluster sferici)         (cluster a forma di banana)\n",
    "                              \n",
    "                              ‚úó ‚Üê outlier (noise=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a5088",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 I Due Parametri Fondamentali\n",
    "\n",
    "DBSCAN ha solo **2 parametri** (invece di K):\n",
    "\n",
    "| Parametro | Nome | Significato |\n",
    "|-----------|------|-------------|\n",
    "| **eps** (Œµ) | Epsilon | Raggio del vicinato di un punto |\n",
    "| **min_samples** | Minimo campioni | Numero minimo di punti nel vicinato per essere \"denso\" |\n",
    "\n",
    "```\n",
    "                    eps = raggio\n",
    "                         ‚Üì\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ    ‚óè    ‚îÇ  Se ci sono ‚â• min_samples punti\n",
    "                    ‚îÇ  ‚óè ‚óâ ‚óè  ‚îÇ  in questo cerchio, ‚óâ √® un CORE POINT\n",
    "                    ‚îÇ    ‚óè    ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üìê Intuizione\n",
    "\n",
    "- **eps piccolo** ‚Üí molti cluster piccoli + molto noise\n",
    "- **eps grande** ‚Üí pochi cluster grandi, rischio di unire tutto\n",
    "- **min_samples basso (es. 2)** ‚Üí sensibile al rumore\n",
    "- **min_samples alto (es. 10)** ‚Üí solo zone molto dense sono cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb7cc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.3 I Tre Tipi di Punti\n",
    "\n",
    "DBSCAN classifica ogni punto in una di tre categorie:\n",
    "\n",
    "| Tipo | Definizione | Simbolo |\n",
    "|------|-------------|---------|\n",
    "| **Core Point** | Ha ‚â• min_samples punti nel suo vicinato (raggio eps) | ‚óâ |\n",
    "| **Border Point** | Non √® core, ma √® nel vicinato di un core point | ‚óè |\n",
    "| **Noise Point** | Non √® core, non √® nel vicinato di nessun core | ‚úó |\n",
    "\n",
    "```\n",
    "Esempio con eps=1, min_samples=3:\n",
    "\n",
    "     ‚úó ‚Üê noise (isolato)\n",
    "    \n",
    "   ‚óè     ‚Üê border (vicino a core ma < 3 vicini)\n",
    "   ‚óâ‚óè‚óè   ‚Üê core (ha 3+ vicini)\n",
    "   ‚óè‚óâ‚óè‚óè  ‚Üê core (ha 4+ vicini)\n",
    "    ‚óè‚óè\n",
    "    \n",
    "   ‚úó ‚Üê noise\n",
    "```\n",
    "\n",
    "### üîë Regola Chiave\n",
    "\n",
    "> **Un cluster √® formato da tutti i core points connessi tra loro \n",
    "> (entro distanza eps) + i loro border points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc2263",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.4 L'Algoritmo Passo-Passo\n",
    "\n",
    "```\n",
    "ALGORITMO DBSCAN:\n",
    "\n",
    "1. Per ogni punto p non ancora visitato:\n",
    "   a. Marca p come visitato\n",
    "   b. Trova tutti i punti nel vicinato di p (distanza ‚â§ eps)\n",
    "   c. Se |vicinato| < min_samples ‚Üí marca p come NOISE (temporaneamente)\n",
    "   d. Altrimenti:\n",
    "      - Crea nuovo cluster C\n",
    "      - Aggiungi p a C (√® un core point)\n",
    "      - Per ogni punto q nel vicinato di p:\n",
    "        * Se q non visitato ‚Üí visita q e aggiungi i suoi vicini\n",
    "        * Se q non appartiene a nessun cluster ‚Üí aggiungi q a C\n",
    "\n",
    "2. I punti noise rimasti alla fine sono gli outliers (label = -1)\n",
    "```\n",
    "\n",
    "### ‚è±Ô∏è Complessit√†\n",
    "\n",
    "| Caso | Complessit√† |\n",
    "|------|-------------|\n",
    "| **Con indicizzazione** (KD-tree, Ball-tree) | O(n log n) |\n",
    "| **Senza indicizzazione** | O(n¬≤) |\n",
    "\n",
    "> **Nota:** sklearn usa automaticamente indicizzazione efficiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440ad96",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.5 Come Scegliere eps: Il k-Distance Graph\n",
    "\n",
    "Il trucco per scegliere **eps** √® usare il **k-distance graph**:\n",
    "\n",
    "1. Per ogni punto, calcola la distanza al k-esimo vicino pi√π vicino (k = min_samples)\n",
    "2. Ordina queste distanze in ordine crescente\n",
    "3. Plotta: il \"gomito\" indica un buon valore di eps\n",
    "\n",
    "```\n",
    "Distanza                    \n",
    "    |                    ‚óè\n",
    "    |                  ‚óè\n",
    "    |               ‚óè‚óè\n",
    "    |           ‚óè‚óè‚óè   ‚Üê gomito (knee)\n",
    "    |      ‚óè‚óè‚óè‚óè       \n",
    "    |  ‚óè‚óè‚óè‚óè\n",
    "    |‚óè‚óè‚óè\n",
    "    +------------------------‚Üí Punti (ordinati)\n",
    "    \n",
    "    Il valore di eps al gomito √® una buona scelta!\n",
    "```\n",
    "\n",
    "### üìê Formula per min_samples\n",
    "\n",
    "Una regola empirica comune:\n",
    "$$min\\_samples \\geq D + 1$$\n",
    "\n",
    "dove D √® la dimensionalit√† dei dati. Per 2D: min_samples ‚â• 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656a681",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.6 DBSCAN vs K-Means vs Gerarchico\n",
    "\n",
    "| Caratteristica | K-Means | Gerarchico | DBSCAN |\n",
    "|----------------|---------|------------|--------|\n",
    "| **Richiede K** | ‚úÖ S√¨ | ‚úÖ S√¨ (taglio) | ‚ùå No |\n",
    "| **Forma cluster** | Sferica | Dipende da linkage | Qualsiasi |\n",
    "| **Gestisce outliers** | ‚ùå No | ‚ùå No | ‚úÖ S√¨ (label=-1) |\n",
    "| **Scalabilit√†** | ‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê |\n",
    "| **Cluster di densit√† variabile** | ‚ùå | ‚ùå | ‚ö†Ô∏è Parziale |\n",
    "| **Riproducibilit√†** | ‚ö†Ô∏è (init random) | ‚úÖ | ‚úÖ |\n",
    "\n",
    "### üéØ Quando Usare DBSCAN\n",
    "\n",
    "‚úÖ **Usa DBSCAN quando:**\n",
    "- Non sai quanti cluster ci sono\n",
    "- I cluster hanno forme non sferiche\n",
    "- Ci sono outliers nei dati\n",
    "- I cluster hanno densit√† simile\n",
    "\n",
    "‚ùå **Evita DBSCAN quando:**\n",
    "- I cluster hanno densit√† molto diverse\n",
    "- I dati sono ad alta dimensionalit√† (curse of dimensionality)\n",
    "- Hai bisogno di assegnare TUTTI i punti a un cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5402ef3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß† 2. Schema Mentale\n",
    "\n",
    "### Workflow DBSCAN\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        DBSCAN WORKFLOW                              ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  1. PREPARAZIONE                                                    ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ StandardScaler (FONDAMENTALE per distanze!)                 ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  2. STIMA min_samples                                               ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Regola: min_samples ‚â• dimensioni + 1                        ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Per 2D: min_samples = 4 o 5 √® un buon default               ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  3. STIMA eps (k-distance graph)                                    ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ NearestNeighbors(n_neighbors=min_samples)                   ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Calcola distanze al k-esimo vicino                          ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Ordina e plotta ‚Üí trova il GOMITO                           ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  4. FIT DBSCAN                                                      ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ DBSCAN(eps=..., min_samples=...)                            ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ labels_ contiene: 0, 1, 2... e -1 per noise                 ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  5. VALUTAZIONE                                                     ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Numero cluster trovati: len(set(labels)) - (1 if -1 in      ‚îÇ\n",
    "‚îÇ         labels else 0)                                              ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Percentuale noise: (labels == -1).sum() / len(labels)       ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Silhouette (escludi noise!): silhouette_score(X[mask],      ‚îÇ\n",
    "‚îÇ         labels[mask])                                               ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îÇ  6. TUNING (se necessario)                                          ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Troppi cluster? ‚Üí aumenta eps                               ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Troppo noise? ‚Üí aumenta eps o diminuisci min_samples        ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ Cluster uniti? ‚Üí diminuisci eps                             ‚îÇ\n",
    "‚îÇ                                                                     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### ‚úÖ Checklist Pre-DBSCAN\n",
    "\n",
    "```\n",
    "‚ñ° Dati scalati con StandardScaler?\n",
    "‚ñ° min_samples ‚â• dimensioni + 1?\n",
    "‚ñ° Generato k-distance graph per stimare eps?\n",
    "‚ñ° Pronti a gestire label -1 (noise)?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781566d0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ 3. Demo Pratiche\n",
    "\n",
    "### Demo 1 ‚Äî Primo DBSCAN: Moon Dataset\n",
    "\n",
    "Usiamo il classico dataset \"moons\" dove K-Means fallisce miseramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 1 ‚Äî Primo DBSCAN: Moon Dataset\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 1 ‚Äî DBSCAN vs K-Means su Moons Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Genera dataset \"moons\" (due mezzelune intrecciate)\n",
    "np.random.seed(42)\n",
    "X_moons, y_true = make_moons(n_samples=300, noise=0.05)\n",
    "\n",
    "# Scaling (importante!)\n",
    "scaler = StandardScaler()\n",
    "X_moons_scaled = scaler.fit_transform(X_moons)\n",
    "\n",
    "print(f\"üìä Dataset: {len(X_moons)} punti, 2 cluster a forma di mezzaluna\")\n",
    "\n",
    "# Confronto: K-Means vs DBSCAN\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Dati originali\n",
    "axes[0].scatter(X_moons[:, 0], X_moons[:, 1], c=y_true, cmap='viridis', s=30, alpha=0.7)\n",
    "axes[0].set_title('Ground Truth', fontsize=12)\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "\n",
    "# 2. K-Means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_kmeans = kmeans.fit_predict(X_moons_scaled)\n",
    "ari_kmeans = adjusted_rand_score(y_true, labels_kmeans)\n",
    "\n",
    "axes[1].scatter(X_moons[:, 0], X_moons[:, 1], c=labels_kmeans, cmap='viridis', s=30, alpha=0.7)\n",
    "axes[1].scatter(kmeans.cluster_centers_[:, 0] * scaler.scale_[0] + scaler.mean_[0],\n",
    "                kmeans.cluster_centers_[:, 1] * scaler.scale_[1] + scaler.mean_[1],\n",
    "                c='red', marker='X', s=200, edgecolors='black')\n",
    "axes[1].set_title(f'K-Means (K=2)\\nARI={ari_kmeans:.3f} ‚ùå', fontsize=12)\n",
    "axes[1].set_xlabel('x')\n",
    "\n",
    "# 3. DBSCAN\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "labels_dbscan = dbscan.fit_predict(X_moons_scaled)\n",
    "ari_dbscan = adjusted_rand_score(y_true, labels_dbscan)\n",
    "\n",
    "# Colori: noise in grigio\n",
    "colors = labels_dbscan.copy().astype(float)\n",
    "colors[labels_dbscan == -1] = -0.5  # Noise in grigio\n",
    "\n",
    "scatter = axes[2].scatter(X_moons[:, 0], X_moons[:, 1], c=colors, cmap='viridis', s=30, alpha=0.7)\n",
    "# Evidenzia noise\n",
    "noise_mask = labels_dbscan == -1\n",
    "if noise_mask.sum() > 0:\n",
    "    axes[2].scatter(X_moons[noise_mask, 0], X_moons[noise_mask, 1], \n",
    "                    c='red', marker='x', s=50, label=f'Noise ({noise_mask.sum()})')\n",
    "    axes[2].legend()\n",
    "axes[2].set_title(f'DBSCAN (eps=0.3, min_samples=5)\\nARI={ari_dbscan:.3f} ‚úÖ', fontsize=12)\n",
    "axes[2].set_xlabel('x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche DBSCAN\n",
    "n_clusters = len(set(labels_dbscan)) - (1 if -1 in labels_dbscan else 0)\n",
    "n_noise = (labels_dbscan == -1).sum()\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä RISULTATI:\n",
    "\n",
    "K-Means:\n",
    "   - ARI: {ari_kmeans:.3f} (basso = clustering sbagliato!)\n",
    "   - Problema: assume cluster sferici\n",
    "\n",
    "DBSCAN:\n",
    "   - Cluster trovati: {n_clusters}\n",
    "   - Punti noise: {n_noise} ({100*n_noise/len(X_moons):.1f}%)\n",
    "   - ARI: {ari_dbscan:.3f} (alto = clustering corretto!)\n",
    "\n",
    "üéØ DBSCAN trova le forme complesse dove K-Means fallisce!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208276d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Demo 2 ‚Äî Il k-Distance Graph per Scegliere eps\n",
    "\n",
    "Come trovare il valore ottimale di eps? Usiamo il metodo del \"gomito\" sul k-distance graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 2 ‚Äî k-Distance Graph per Scegliere eps\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 2 ‚Äî k-Distance Graph per Scegliere eps\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Genera un dataset con outliers\n",
    "np.random.seed(42)\n",
    "X_blobs, y_blobs = make_blobs(n_samples=250, centers=3, cluster_std=0.8, random_state=42)\n",
    "# Aggiungi outliers\n",
    "outliers = np.random.uniform(low=-10, high=10, size=(15, 2))\n",
    "X_with_outliers = np.vstack([X_blobs, outliers])\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_with_outliers)\n",
    "\n",
    "print(f\"üìä Dataset: {len(X_blobs)} punti + {len(outliers)} outliers\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 1: Calcola k-distanze\n",
    "# ============================================\n",
    "min_samples = 5  # Regola: D + 1 = 2 + 1 = 3, usiamo 5 per robustezza\n",
    "\n",
    "# Trova il k-esimo vicino pi√π vicino per ogni punto\n",
    "nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "nn.fit(X_scaled)\n",
    "distances, indices = nn.kneighbors(X_scaled)\n",
    "\n",
    "# Prendi la distanza al k-esimo vicino (ultima colonna)\n",
    "k_distances = distances[:, -1]\n",
    "\n",
    "# Ordina in ordine crescente\n",
    "k_distances_sorted = np.sort(k_distances)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 2: Plot k-distance graph\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# k-distance graph\n",
    "axes[0].plot(range(len(k_distances_sorted)), k_distances_sorted, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Punti (ordinati per k-distanza)', fontsize=11)\n",
    "axes[0].set_ylabel(f'Distanza al {min_samples}¬∞ vicino', fontsize=11)\n",
    "axes[0].set_title('k-Distance Graph\\n(Cerca il GOMITO)', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trova il \"gomito\" (approssimazione: derivata seconda massima)\n",
    "# Metodo semplice: cerca dove la pendenza cambia di pi√π\n",
    "second_derivative = np.diff(np.diff(k_distances_sorted))\n",
    "knee_idx = np.argmax(second_derivative) + 2  # +2 per offset\n",
    "eps_optimal = k_distances_sorted[knee_idx]\n",
    "\n",
    "axes[0].axhline(y=eps_optimal, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'eps ottimale ‚âà {eps_optimal:.2f}')\n",
    "axes[0].scatter([knee_idx], [eps_optimal], color='red', s=100, zorder=5, marker='o')\n",
    "axes[0].legend()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: Applica DBSCAN con eps stimato\n",
    "# ============================================\n",
    "dbscan = DBSCAN(eps=eps_optimal, min_samples=min_samples)\n",
    "labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = (labels == -1).sum()\n",
    "\n",
    "# Plot clustering\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_clusters + 1))\n",
    "for i in range(n_clusters):\n",
    "    mask = labels == i\n",
    "    axes[1].scatter(X_with_outliers[mask, 0], X_with_outliers[mask, 1], \n",
    "                    c=[colors[i]], s=50, alpha=0.7, label=f'Cluster {i}')\n",
    "\n",
    "# Noise in rosso\n",
    "noise_mask = labels == -1\n",
    "axes[1].scatter(X_with_outliers[noise_mask, 0], X_with_outliers[noise_mask, 1],\n",
    "                c='red', marker='x', s=80, label=f'Noise ({n_noise})')\n",
    "\n",
    "axes[1].set_xlabel('x', fontsize=11)\n",
    "axes[1].set_ylabel('y', fontsize=11)\n",
    "axes[1].set_title(f'DBSCAN (eps={eps_optimal:.2f}, min_samples={min_samples})\\n'\n",
    "                  f'{n_clusters} cluster, {n_noise} noise points', fontsize=12)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä RISULTATI:\n",
    "\n",
    "1. k-Distance Graph:\n",
    "   - min_samples = {min_samples}\n",
    "   - eps ottimale (dal gomito) ‚âà {eps_optimal:.2f}\n",
    "\n",
    "2. DBSCAN:\n",
    "   - Cluster trovati: {n_clusters}\n",
    "   - Punti noise: {n_noise} ({100*n_noise/len(X_with_outliers):.1f}%)\n",
    "   \n",
    "üéØ Gli outliers aggiunti sono stati identificati come NOISE!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102abd5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Demo 3 ‚Äî Core Points, Border Points, Noise\n",
    "\n",
    "Visualizziamo i tre tipi di punti che DBSCAN identifica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 3 ‚Äî Core Points, Border Points, Noise\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 3 ‚Äî Core Points, Border Points, Noise\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset semplice per visualizzazione chiara\n",
    "np.random.seed(123)\n",
    "X_small = np.array([\n",
    "    # Cluster 1 (denso)\n",
    "    [1, 1], [1.2, 0.8], [0.8, 1.2], [1.1, 1.1], [0.9, 0.9],\n",
    "    [1.3, 1.0], [1.0, 1.3],\n",
    "    # Cluster 2 (denso)\n",
    "    [4, 4], [4.2, 3.8], [3.8, 4.2], [4.1, 4.1], [3.9, 3.9],\n",
    "    [4.3, 4.0], [4.0, 4.3],\n",
    "    # Border points (al limite)\n",
    "    [2.0, 2.0],  # Border tra i cluster\n",
    "    [0.3, 0.3],  # Border di cluster 1\n",
    "    # Noise (isolati)\n",
    "    [6, 1],\n",
    "    [0, 5],\n",
    "    [7, 7]\n",
    "])\n",
    "\n",
    "eps = 0.8\n",
    "min_samples = 3\n",
    "\n",
    "print(f\"üìä Dataset: {len(X_small)} punti\")\n",
    "print(f\"   Parametri: eps={eps}, min_samples={min_samples}\")\n",
    "\n",
    "# Fit DBSCAN\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "labels = dbscan.fit_predict(X_small)\n",
    "\n",
    "# Identifica core samples (sklearn li salva in core_sample_indices_)\n",
    "core_mask = np.zeros(len(X_small), dtype=bool)\n",
    "core_mask[dbscan.core_sample_indices_] = True\n",
    "\n",
    "# Border = non-core ma con label != -1\n",
    "border_mask = ~core_mask & (labels != -1)\n",
    "\n",
    "# Noise = label == -1\n",
    "noise_mask = labels == -1\n",
    "\n",
    "print(f\"\\nüìå Classificazione punti:\")\n",
    "print(f\"   Core points: {core_mask.sum()}\")\n",
    "print(f\"   Border points: {border_mask.sum()}\")\n",
    "print(f\"   Noise points: {noise_mask.sum()}\")\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Core points (grandi e pieni)\n",
    "ax.scatter(X_small[core_mask, 0], X_small[core_mask, 1], \n",
    "           c='blue', s=200, marker='o', edgecolors='black', linewidths=2,\n",
    "           label=f'Core Points ({core_mask.sum()})', alpha=0.8)\n",
    "\n",
    "# Border points (medi)\n",
    "ax.scatter(X_small[border_mask, 0], X_small[border_mask, 1],\n",
    "           c='green', s=150, marker='s', edgecolors='black', linewidths=2,\n",
    "           label=f'Border Points ({border_mask.sum()})', alpha=0.8)\n",
    "\n",
    "# Noise points (X rosse)\n",
    "ax.scatter(X_small[noise_mask, 0], X_small[noise_mask, 1],\n",
    "           c='red', s=150, marker='X', edgecolors='black', linewidths=2,\n",
    "           label=f'Noise Points ({noise_mask.sum()})', alpha=0.8)\n",
    "\n",
    "# Disegna cerchi eps intorno ai core points\n",
    "for i, (x, y) in enumerate(X_small[core_mask]):\n",
    "    circle = plt.Circle((x, y), eps, fill=False, color='blue', \n",
    "                         linestyle='--', alpha=0.3)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "# Etichette punti\n",
    "for i, (x, y) in enumerate(X_small):\n",
    "    tipo = \"C\" if core_mask[i] else (\"B\" if border_mask[i] else \"N\")\n",
    "    ax.annotate(f'{i}({tipo})', (x + 0.1, y + 0.1), fontsize=8)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=11)\n",
    "ax.set_ylabel('y', fontsize=11)\n",
    "ax.set_title(f'DBSCAN: Core, Border, Noise\\n(eps={eps}, min_samples={min_samples})', fontsize=13)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-1, 9)\n",
    "ax.set_ylim(-1, 9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"\n",
    "üìñ LEGENDA:\n",
    "   C = Core Point (‚â• {min_samples} vicini entro eps={eps})\n",
    "   B = Border Point (nel vicinato di un core, ma < {min_samples} vicini)\n",
    "   N = Noise Point (isolato)\n",
    "   \n",
    "   I cerchi tratteggiati mostrano il raggio eps intorno ai core points.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20479cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Demo 4 ‚Äî Effetto dei Parametri eps e min_samples\n",
    "\n",
    "Esploriamo come cambiano i risultati variando i due parametri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba79e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 4 ‚Äî Effetto dei Parametri eps e min_samples\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 4 ‚Äî Effetto dei Parametri eps e min_samples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset: cerchi concentrici (sfida per K-Means!)\n",
    "np.random.seed(42)\n",
    "X_circles, y_circles = make_circles(n_samples=300, noise=0.05, factor=0.5)\n",
    "scaler = StandardScaler()\n",
    "X_circles_scaled = scaler.fit_transform(X_circles)\n",
    "\n",
    "# Griglia di parametri\n",
    "eps_values = [0.1, 0.3, 0.5]\n",
    "min_samples_values = [3, 5, 10]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for i, eps in enumerate(eps_values):\n",
    "    for j, min_s in enumerate(min_samples_values):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_s)\n",
    "        labels = dbscan.fit_predict(X_circles_scaled)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = (labels == -1).sum()\n",
    "        pct_noise = 100 * n_noise / len(X_circles)\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        # Colori per cluster\n",
    "        unique_labels = set(labels)\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for k, col in zip(unique_labels, colors):\n",
    "            if k == -1:\n",
    "                # Noise\n",
    "                col = 'red'\n",
    "                marker = 'x'\n",
    "                size = 30\n",
    "            else:\n",
    "                marker = 'o'\n",
    "                size = 20\n",
    "            \n",
    "            mask = labels == k\n",
    "            ax.scatter(X_circles[mask, 0], X_circles[mask, 1], \n",
    "                      c=[col], marker=marker, s=size, alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f'eps={eps}, min_s={min_s}\\n{n_clusters} cluster, {pct_noise:.0f}% noise',\n",
    "                     fontsize=10)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # Evidenzia casi interessanti\n",
    "        if n_clusters == 2 and pct_noise < 5:\n",
    "            ax.patch.set_edgecolor('green')\n",
    "            ax.patch.set_linewidth(4)\n",
    "\n",
    "# Etichette assi\n",
    "for i, eps in enumerate(eps_values):\n",
    "    axes[i, 0].set_ylabel(f'eps={eps}', fontsize=12, fontweight='bold')\n",
    "for j, min_s in enumerate(min_samples_values):\n",
    "    axes[0, j].set_title(f'min_samples={min_s}\\n' + axes[0, j].get_title(), fontsize=10)\n",
    "\n",
    "plt.suptitle('Effetto di eps e min_samples su Cerchi Concentrici\\n(bordo verde = configurazione ottimale)',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "üìä OSSERVAZIONI:\n",
    "\n",
    "eps PICCOLO (0.1):\n",
    "   ‚Üí Molti cluster piccoli o tutto noise\n",
    "   ‚Üí Troppo restrittivo\n",
    "\n",
    "eps MEDIO (0.3):\n",
    "   ‚Üí Trova i 2 cerchi correttamente ‚úÖ\n",
    "   ‚Üí Poco noise\n",
    "\n",
    "eps GRANDE (0.5):\n",
    "   ‚Üí Rischia di unire i cerchi\n",
    "   ‚Üí Meno noise ma clustering sbagliato\n",
    "\n",
    "min_samples BASSO (3):\n",
    "   ‚Üí Sensibile al rumore\n",
    "   ‚Üí Pi√π punti considerati \"densi\"\n",
    "\n",
    "min_samples ALTO (10):\n",
    "   ‚Üí Solo zone molto dense sono cluster\n",
    "   ‚Üí Pi√π punti diventano noise\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673e205",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Demo 5 ‚Äî DBSCAN vs K-Means vs Gerarchico: Confronto Finale\n",
    "\n",
    "Confrontiamo i tre metodi di clustering su un dataset con forme complesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073645fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO 5 ‚Äî DBSCAN vs K-Means vs Gerarchico\n",
    "# ============================================\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 5 ‚Äî Confronto Finale: DBSCAN vs K-Means vs Gerarchico\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset combinato: moons + blob + outliers\n",
    "np.random.seed(42)\n",
    "\n",
    "# Due mezzelune\n",
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.05)\n",
    "X_moons[:, 0] += 3  # Sposta a destra\n",
    "\n",
    "# Un blob\n",
    "X_blob = np.random.normal(loc=[-2, 0], scale=0.5, size=(100, 2))\n",
    "\n",
    "# Outliers\n",
    "outliers = np.array([[-4, 3], [6, 3], [2, -2], [-3, -2], [5, -1]])\n",
    "\n",
    "# Combina\n",
    "X_complex = np.vstack([X_moons, X_blob, outliers])\n",
    "y_true = np.concatenate([y_moons, np.full(100, 2), np.full(5, -1)])\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_complex_scaled = scaler.fit_transform(X_complex)\n",
    "\n",
    "print(f\"üìä Dataset complesso:\")\n",
    "print(f\"   - 2 mezzelune (200 punti)\")\n",
    "print(f\"   - 1 blob (100 punti)\")\n",
    "print(f\"   - 5 outliers\")\n",
    "print(f\"   - Totale: {len(X_complex)} punti\")\n",
    "\n",
    "# ============================================\n",
    "# Confronto metodi\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Ground Truth\n",
    "ax = axes[0, 0]\n",
    "colors_true = y_true.copy().astype(float)\n",
    "colors_true[y_true == -1] = 3  # outliers\n",
    "scatter = ax.scatter(X_complex[:, 0], X_complex[:, 1], c=colors_true, \n",
    "                      cmap='viridis', s=30, alpha=0.7)\n",
    "ax.scatter(outliers[:, 0], outliers[:, 1], c='red', marker='X', s=100, \n",
    "           edgecolors='black', label='Outliers')\n",
    "ax.set_title('Ground Truth\\n(3 cluster + 5 outliers)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. K-Means\n",
    "ax = axes[0, 1]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_km = kmeans.fit_predict(X_complex_scaled)\n",
    "ari_km = adjusted_rand_score(y_true[y_true != -1], labels_km[y_true != -1])\n",
    "ax.scatter(X_complex[:, 0], X_complex[:, 1], c=labels_km, cmap='viridis', s=30, alpha=0.7)\n",
    "ax.set_title(f'K-Means (K=3)\\nARI={ari_km:.3f}', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Gerarchico\n",
    "ax = axes[1, 0]\n",
    "agg = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "labels_agg = agg.fit_predict(X_complex_scaled)\n",
    "ari_agg = adjusted_rand_score(y_true[y_true != -1], labels_agg[y_true != -1])\n",
    "ax.scatter(X_complex[:, 0], X_complex[:, 1], c=labels_agg, cmap='viridis', s=30, alpha=0.7)\n",
    "ax.set_title(f'Gerarchico (Ward, K=3)\\nARI={ari_agg:.3f}', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. DBSCAN\n",
    "ax = axes[1, 1]\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "labels_db = dbscan.fit_predict(X_complex_scaled)\n",
    "n_clusters_db = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "n_noise_db = (labels_db == -1).sum()\n",
    "\n",
    "# Calcola ARI escludendo noise\n",
    "mask_valid = (y_true != -1) & (labels_db != -1)\n",
    "if mask_valid.sum() > 0:\n",
    "    ari_db = adjusted_rand_score(y_true[mask_valid], labels_db[mask_valid])\n",
    "else:\n",
    "    ari_db = 0\n",
    "\n",
    "# Colori\n",
    "colors_db = labels_db.astype(float)\n",
    "colors_db[labels_db == -1] = -1\n",
    "\n",
    "scatter = ax.scatter(X_complex[labels_db != -1, 0], X_complex[labels_db != -1, 1], \n",
    "                      c=labels_db[labels_db != -1], cmap='viridis', s=30, alpha=0.7)\n",
    "ax.scatter(X_complex[labels_db == -1, 0], X_complex[labels_db == -1, 1],\n",
    "           c='red', marker='x', s=50, label=f'Noise ({n_noise_db})')\n",
    "ax.set_title(f'DBSCAN (eps=0.3, min_samples=5)\\n{n_clusters_db} cluster, ARI={ari_db:.3f}', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "plt.suptitle('Confronto Metodi di Clustering su Dataset Complesso', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabella riassuntiva\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABELLA RIASSUNTIVA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metodo':<20} {'ARI':>10} {'Gestisce Outliers':>20}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'K-Means':<20} {ari_km:>10.3f} {'‚ùå No':>20}\")\n",
    "print(f\"{'Gerarchico':<20} {ari_agg:>10.3f} {'‚ùå No':>20}\")\n",
    "print(f\"{'DBSCAN':<20} {ari_db:>10.3f} {'‚úÖ S√¨ ('+str(n_noise_db)+' trovati)':>20}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üéØ CONCLUSIONE:\n",
    "\n",
    "DBSCAN √® l'unico che:\n",
    "   1. Trova cluster di forme non sferiche (le mezzelune)\n",
    "   2. Identifica gli outliers automaticamente\n",
    "   3. Non richiede K a priori\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407de1e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù 4. Esercizi\n",
    "\n",
    "### üìù Esercizio 23.1 ‚Äî Anomaly Detection con DBSCAN\n",
    "\n",
    "**Consegna:** Usa DBSCAN per identificare transazioni anomale in un dataset di e-commerce.\n",
    "\n",
    "**Dataset:**\n",
    "```python\n",
    "importo = [25, 30, 28, 35, 500, 22, 27, 1000, 33, 29, 31, 26, 750, 28, 24]\n",
    "durata_sessione = [5, 6, 4, 7, 2, 5, 6, 1, 8, 5, 6, 4, 3, 5, 6]  # minuti\n",
    "```\n",
    "\n",
    "**Richieste:**\n",
    "1. Scala i dati con StandardScaler\n",
    "2. Usa il k-distance graph per scegliere eps (min_samples=3)\n",
    "3. Applica DBSCAN e identifica le transazioni anomale (noise)\n",
    "4. Interpreta: perch√© queste transazioni sono considerate anomale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 23.1 ‚Äî SOLUZIONE\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 23.1 ‚Äî Anomaly Detection con DBSCAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 1: Preparazione dati\n",
    "# ============================================\n",
    "importo = [25, 30, 28, 35, 500, 22, 27, 1000, 33, 29, 31, 26, 750, 28, 24]\n",
    "durata_sessione = [5, 6, 4, 7, 2, 5, 6, 1, 8, 5, 6, 4, 3, 5, 6]\n",
    "\n",
    "df_trans = pd.DataFrame({\n",
    "    'transazione': [f'T{i}' for i in range(1, 16)],\n",
    "    'importo': importo,\n",
    "    'durata_min': durata_sessione\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Dataset Transazioni:\")\n",
    "print(df_trans)\n",
    "\n",
    "X_trans = df_trans[['importo', 'durata_min']].values\n",
    "scaler = StandardScaler()\n",
    "X_trans_scaled = scaler.fit_transform(X_trans)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 2: k-distance graph\n",
    "# ============================================\n",
    "min_samples = 3\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "nn.fit(X_trans_scaled)\n",
    "distances, _ = nn.kneighbors(X_trans_scaled)\n",
    "k_distances = np.sort(distances[:, -1])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# k-distance graph\n",
    "axes[0].plot(range(len(k_distances)), k_distances, 'b-o', linewidth=2, markersize=6)\n",
    "axes[0].set_xlabel('Punti (ordinati)', fontsize=11)\n",
    "axes[0].set_ylabel(f'Distanza al {min_samples}¬∞ vicino', fontsize=11)\n",
    "axes[0].set_title('k-Distance Graph', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trova gomito (approssimazione)\n",
    "second_deriv = np.diff(np.diff(k_distances))\n",
    "knee_idx = np.argmax(second_deriv) + 2\n",
    "eps_optimal = k_distances[knee_idx]\n",
    "\n",
    "axes[0].axhline(y=eps_optimal, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'eps ‚âà {eps_optimal:.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: Applica DBSCAN\n",
    "# ============================================\n",
    "# Uso un eps leggermente pi√π conservativo per catturare anomalie\n",
    "eps_used = 0.8  # Dopo analisi del graph\n",
    "\n",
    "dbscan = DBSCAN(eps=eps_used, min_samples=min_samples)\n",
    "labels = dbscan.fit_predict(X_trans_scaled)\n",
    "\n",
    "df_trans['cluster'] = labels\n",
    "df_trans['anomalia'] = labels == -1\n",
    "\n",
    "# Plot\n",
    "colors = ['green' if l != -1 else 'red' for l in labels]\n",
    "axes[1].scatter(df_trans['importo'], df_trans['durata_min'], \n",
    "                c=colors, s=150, edgecolors='black', alpha=0.8)\n",
    "\n",
    "for i, row in df_trans.iterrows():\n",
    "    marker = '‚ö†Ô∏è' if row['anomalia'] else ''\n",
    "    axes[1].annotate(f\"{row['transazione']}{marker}\", \n",
    "                     (row['importo']+20, row['durata_min']+0.1), fontsize=9)\n",
    "\n",
    "axes[1].set_xlabel('Importo (‚Ç¨)', fontsize=11)\n",
    "axes[1].set_ylabel('Durata Sessione (min)', fontsize=11)\n",
    "axes[1].set_title(f'DBSCAN (eps={eps_used}, min_samples={min_samples})\\n'\n",
    "                  f'Rosso = Anomalie', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 4: Interpretazione\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PASSO 4: Interpretazione Anomalie\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "anomalie = df_trans[df_trans['anomalia']]\n",
    "normali = df_trans[~df_trans['anomalia']]\n",
    "\n",
    "print(f\"\\nüìä STATISTICHE:\")\n",
    "print(f\"\\n   Transazioni normali ({len(normali)}):\")\n",
    "print(f\"   - Importo medio: ‚Ç¨{normali['importo'].mean():.0f}\")\n",
    "print(f\"   - Durata media: {normali['durata_min'].mean():.1f} min\")\n",
    "\n",
    "print(f\"\\n   üö® ANOMALIE RILEVATE ({len(anomalie)}):\")\n",
    "for _, row in anomalie.iterrows():\n",
    "    print(f\"\\n   {row['transazione']}:\")\n",
    "    print(f\"   - Importo: ‚Ç¨{row['importo']} (vs media ‚Ç¨{normali['importo'].mean():.0f})\")\n",
    "    print(f\"   - Durata: {row['durata_min']} min (vs media {normali['durata_min'].mean():.1f} min)\")\n",
    "    \n",
    "    # Interpretazione\n",
    "    if row['importo'] > 400:\n",
    "        print(\"   ‚Üí SOSPETTO: Importo anomalmente alto + sessione breve\")\n",
    "        print(\"   ‚Üí Possibile frode o errore di sistema\")\n",
    "\n",
    "print(\"\\n‚úÖ DBSCAN ha identificato automaticamente le transazioni sospette!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd7b52f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù Esercizio 23.2 ‚Äî Clustering Geografico\n",
    "\n",
    "**Consegna:** Usa DBSCAN per raggruppare punti di interesse in una citt√†.\n",
    "\n",
    "**Dataset:**\n",
    "```python\n",
    "lat = [45.46, 45.47, 45.46, 45.48, 45.70, 45.71, 45.69, 45.20, 45.46, 45.47]\n",
    "lon = [9.18, 9.19, 9.17, 9.18, 9.30, 9.31, 9.29, 9.50, 9.20, 9.18]\n",
    "nomi = ['Duomo', 'Scala', 'Castello', 'Brera', 'Monza1', 'Monza2', 'Monza3', \n",
    "        'Pavia', 'Navigli', 'Porta Romana']\n",
    "```\n",
    "\n",
    "**Richieste:**\n",
    "1. Identifica le zone di interesse (cluster di POI vicini)\n",
    "2. Trova eventuali POI isolati\n",
    "3. Assegna nomi descrittivi alle zone trovate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 23.2 ‚Äî SOLUZIONE\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 23.2 ‚Äî Clustering Geografico POI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 1: Preparazione dati\n",
    "# ============================================\n",
    "lat = [45.46, 45.47, 45.46, 45.48, 45.70, 45.71, 45.69, 45.20, 45.46, 45.47]\n",
    "lon = [9.18, 9.19, 9.17, 9.18, 9.30, 9.31, 9.29, 9.50, 9.20, 9.18]\n",
    "nomi = ['Duomo', 'Scala', 'Castello', 'Brera', 'Monza1', 'Monza2', 'Monza3', \n",
    "        'Pavia', 'Navigli', 'Porta Romana']\n",
    "\n",
    "df_poi = pd.DataFrame({\n",
    "    'nome': nomi,\n",
    "    'lat': lat,\n",
    "    'lon': lon\n",
    "})\n",
    "\n",
    "print(\"\\nüìç Dataset POI:\")\n",
    "print(df_poi)\n",
    "\n",
    "X_geo = df_poi[['lat', 'lon']].values\n",
    "\n",
    "# Per dati geografici, scaling pu√≤ alterare le proporzioni\n",
    "# Usiamo i dati raw ma con eps appropriato\n",
    "# 0.05 gradi ‚âà 5km\n",
    "\n",
    "# ============================================\n",
    "# PASSO 2: k-distance graph\n",
    "# ============================================\n",
    "min_samples = 2  # Piccolo dataset\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "nn.fit(X_geo)\n",
    "distances, _ = nn.kneighbors(X_geo)\n",
    "k_distances = np.sort(distances[:, -1])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(len(k_distances)), k_distances, 'b-o', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Punti (ordinati)', fontsize=11)\n",
    "axes[0].set_ylabel('Distanza al vicino', fontsize=11)\n",
    "axes[0].set_title('k-Distance Graph (dati geografici)', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# eps = circa 0.05 (distanza tra POI nella stessa zona)\n",
    "eps_geo = 0.05\n",
    "axes[0].axhline(y=eps_geo, color='red', linestyle='--', label=f'eps={eps_geo}')\n",
    "axes[0].legend()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: Applica DBSCAN\n",
    "# ============================================\n",
    "dbscan = DBSCAN(eps=eps_geo, min_samples=min_samples)\n",
    "labels = dbscan.fit_predict(X_geo)\n",
    "\n",
    "df_poi['cluster'] = labels\n",
    "\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = (labels == -1).sum()\n",
    "\n",
    "print(f\"\\nüìä DBSCAN: {n_clusters} zone trovate, {n_noise} POI isolati\")\n",
    "\n",
    "# Plot mappa\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, n_clusters + 1))\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    mask = labels == i\n",
    "    axes[1].scatter(df_poi.loc[mask, 'lon'], df_poi.loc[mask, 'lat'],\n",
    "                    c=[colors[i]], s=200, edgecolors='black', \n",
    "                    label=f'Zona {i}', alpha=0.8)\n",
    "\n",
    "# POI isolati\n",
    "noise_mask = labels == -1\n",
    "if noise_mask.sum() > 0:\n",
    "    axes[1].scatter(df_poi.loc[noise_mask, 'lon'], df_poi.loc[noise_mask, 'lat'],\n",
    "                    c='gray', s=200, marker='X', edgecolors='black',\n",
    "                    label='Isolati', alpha=0.8)\n",
    "\n",
    "# Etichette\n",
    "for i, row in df_poi.iterrows():\n",
    "    axes[1].annotate(row['nome'], (row['lon']+0.01, row['lat']+0.01), fontsize=9)\n",
    "\n",
    "axes[1].set_xlabel('Longitudine', fontsize=11)\n",
    "axes[1].set_ylabel('Latitudine', fontsize=11)\n",
    "axes[1].set_title('Mappa POI con Clustering DBSCAN', fontsize=12)\n",
    "axes[1].legend(loc='upper left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 4: Nomi descrittivi\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PASSO 4: Zone Identificate\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "zone_nomi = {}\n",
    "for cluster_id in sorted(df_poi['cluster'].unique()):\n",
    "    if cluster_id == -1:\n",
    "        continue\n",
    "    \n",
    "    cluster_data = df_poi[df_poi['cluster'] == cluster_id]\n",
    "    poi_list = cluster_data['nome'].tolist()\n",
    "    \n",
    "    # Logica naming basata sui POI\n",
    "    if 'Duomo' in poi_list or 'Scala' in poi_list:\n",
    "        zona_nome = \"üèõÔ∏è Centro Storico Milano\"\n",
    "    elif 'Monza' in poi_list[0]:\n",
    "        zona_nome = \"üèéÔ∏è Zona Monza\"\n",
    "    else:\n",
    "        zona_nome = f\"üìç Zona {cluster_id}\"\n",
    "    \n",
    "    zone_nomi[cluster_id] = zona_nome\n",
    "    print(f\"\\n   {zona_nome}:\")\n",
    "    print(f\"   POI: {', '.join(poi_list)}\")\n",
    "\n",
    "# POI isolati\n",
    "isolati = df_poi[df_poi['cluster'] == -1]\n",
    "if len(isolati) > 0:\n",
    "    print(f\"\\n   üö´ POI ISOLATI (non raggruppabili):\")\n",
    "    for _, row in isolati.iterrows():\n",
    "        print(f\"   - {row['nome']} ({row['lat']:.2f}, {row['lon']:.2f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Clustering geografico completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950de6cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üìù Esercizio 23.3 ‚Äî Tuning Automatico di eps\n",
    "\n",
    "**Consegna:** Implementa una funzione che trova automaticamente il miglior eps per DBSCAN.\n",
    "\n",
    "**Richieste:**\n",
    "1. Crea una funzione `trova_eps_ottimale(X, min_samples)` che usa il k-distance graph\n",
    "2. Testa la funzione sul dataset make_moons con noise\n",
    "3. Confronta il risultato con eps scelti manualmente (0.1, 0.3, 0.5)\n",
    "4. Valuta con Silhouette Score (escludi noise!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5860072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ESERCIZIO 23.3 ‚Äî SOLUZIONE\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ESERCIZIO 23.3 ‚Äî Tuning Automatico di eps\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================\n",
    "# PASSO 1: Funzione trova_eps_ottimale\n",
    "# ============================================\n",
    "\n",
    "def trova_eps_ottimale(X, min_samples, plot=False):\n",
    "    \"\"\"\n",
    "    Trova il valore ottimale di eps usando il metodo del gomito\n",
    "    sul k-distance graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Dati (gi√† scalati!)\n",
    "    min_samples : int\n",
    "        Parametro min_samples per DBSCAN\n",
    "    plot : bool\n",
    "        Se True, mostra il k-distance graph\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    eps_ottimale : float\n",
    "        Valore di eps al gomito\n",
    "    \"\"\"\n",
    "    # Calcola k-distanze\n",
    "    nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "    nn.fit(X)\n",
    "    distances, _ = nn.kneighbors(X)\n",
    "    k_distances = np.sort(distances[:, -1])\n",
    "    \n",
    "    # Trova il gomito (massima curvatura)\n",
    "    # Metodo: trova dove la derivata seconda √® massima\n",
    "    if len(k_distances) > 3:\n",
    "        second_deriv = np.diff(np.diff(k_distances))\n",
    "        knee_idx = np.argmax(second_deriv) + 2\n",
    "    else:\n",
    "        knee_idx = len(k_distances) // 2\n",
    "    \n",
    "    eps_ottimale = k_distances[knee_idx]\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(range(len(k_distances)), k_distances, 'b-', linewidth=2)\n",
    "        plt.axhline(y=eps_ottimale, color='red', linestyle='--', \n",
    "                    label=f'eps ottimale = {eps_ottimale:.3f}')\n",
    "        plt.scatter([knee_idx], [eps_ottimale], color='red', s=100, zorder=5)\n",
    "        plt.xlabel('Punti (ordinati)')\n",
    "        plt.ylabel(f'Distanza al {min_samples}¬∞ vicino')\n",
    "        plt.title('k-Distance Graph con Gomito Automatico')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    \n",
    "    return eps_ottimale\n",
    "\n",
    "print(\"‚úÖ Funzione trova_eps_ottimale() definita!\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 2: Test su make_moons\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PASSO 2: Test su make_moons\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "np.random.seed(42)\n",
    "X_test, y_test = make_moons(n_samples=300, noise=0.08)\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "min_samples = 5\n",
    "eps_auto = trova_eps_ottimale(X_test_scaled, min_samples, plot=True)\n",
    "print(f\"\\nüéØ eps ottimale trovato automaticamente: {eps_auto:.3f}\")\n",
    "\n",
    "# ============================================\n",
    "# PASSO 3: Confronto con eps manuali\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PASSO 3: Confronto eps manuali vs automatico\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "eps_values = [0.1, 0.3, 0.5, eps_auto]\n",
    "eps_labels = ['0.1 (piccolo)', '0.3 (medio)', '0.5 (grande)', f'{eps_auto:.3f} (auto)']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "risultati = {}\n",
    "\n",
    "for idx, (eps, label) in enumerate(zip(eps_values, eps_labels)):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_test_scaled)\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = (labels == -1).sum()\n",
    "    \n",
    "    # Silhouette (escludi noise!)\n",
    "    mask = labels != -1\n",
    "    if mask.sum() > 1 and len(set(labels[mask])) > 1:\n",
    "        sil = silhouette_score(X_test_scaled[mask], labels[mask])\n",
    "    else:\n",
    "        sil = -1\n",
    "    \n",
    "    # ARI\n",
    "    ari = adjusted_rand_score(y_test, labels)\n",
    "    \n",
    "    risultati[label] = {\n",
    "        'eps': eps,\n",
    "        'n_clusters': n_clusters,\n",
    "        'n_noise': n_noise,\n",
    "        'silhouette': sil,\n",
    "        'ari': ari\n",
    "    }\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    colors = labels.astype(float)\n",
    "    colors[labels == -1] = -0.5\n",
    "    \n",
    "    ax.scatter(X_test[labels != -1, 0], X_test[labels != -1, 1],\n",
    "               c=labels[labels != -1], cmap='viridis', s=30, alpha=0.7)\n",
    "    if n_noise > 0:\n",
    "        ax.scatter(X_test[labels == -1, 0], X_test[labels == -1, 1],\n",
    "                   c='red', marker='x', s=30, label=f'Noise ({n_noise})')\n",
    "        ax.legend()\n",
    "    \n",
    "    ax.set_title(f'eps={label}\\n{n_clusters} cluster, Sil={sil:.3f}, ARI={ari:.3f}',\n",
    "                 fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Evidenzia il migliore\n",
    "    if eps == eps_auto:\n",
    "        ax.patch.set_edgecolor('green')\n",
    "        ax.patch.set_linewidth(4)\n",
    "\n",
    "plt.suptitle('Confronto eps: Manuale vs Automatico\\n(bordo verde = automatico)', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PASSO 4: Tabella riassuntiva\n",
    "# ============================================\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(f\"{'eps':<20} {'Cluster':>10} {'Noise':>10} {'Silhouette':>12} {'ARI':>10}\")\n",
    "print(\"-\"*70)\n",
    "for label, res in risultati.items():\n",
    "    marker = \"‚≠ê\" if 'auto' in label else \"  \"\n",
    "    print(f\"{marker}{label:<18} {res['n_clusters']:>10} {res['n_noise']:>10} \"\n",
    "          f\"{res['silhouette']:>12.3f} {res['ari']:>10.3f}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ CONCLUSIONE:\n",
    "   Il metodo automatico del gomito trova un eps ragionevole,\n",
    "   ma potrebbe necessitare di fine-tuning manuale per casi specifici.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d39baf0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ 5. Conclusione\n",
    "\n",
    "### ‚úÖ Cosa Portarsi a Casa\n",
    "\n",
    "| Concetto | Cosa Ricordare |\n",
    "|----------|----------------|\n",
    "| **DBSCAN** | Clustering basato su densit√†, non richiede K |\n",
    "| **eps** | Raggio del vicinato ‚Äî usa k-distance graph per sceglierlo |\n",
    "| **min_samples** | Minimo punti per essere \"denso\" ‚Äî regola: ‚â• D+1 |\n",
    "| **Noise (label=-1)** | DBSCAN identifica automaticamente gli outliers |\n",
    "| **Core/Border/Noise** | I tre tipi di punti che DBSCAN classifica |\n",
    "| **Forme arbitrarie** | DBSCAN trova cluster di qualsiasi forma |\n",
    "\n",
    "### ‚ö†Ô∏è Errori Comuni\n",
    "\n",
    "| Errore | Perch√© √® Sbagliato | Correzione |\n",
    "|--------|-------------------|------------|\n",
    "| Non scalare i dati | eps dipende dalla scala | Sempre StandardScaler |\n",
    "| Ignorare il noise | Pu√≤ contenere informazioni utili | Analizza i punti noise |\n",
    "| eps troppo grande | Unisce cluster distinti | Usa k-distance graph |\n",
    "| eps troppo piccolo | Tutto diventa noise | Aumenta gradualmente |\n",
    "| Silhouette con noise | Risultato falsato | `silhouette_score(X[mask], labels[mask])` |\n",
    "\n",
    "### üîó Ponte verso la Lezione 24\n",
    "\n",
    "Nella prossima lezione esploreremo **PCA** (Principal Component Analysis):\n",
    "- **Riduzione dimensionalit√†** ‚Äî da N feature a K componenti\n",
    "- **Varianza spiegata** ‚Äî quanto informazione conserviamo\n",
    "- **Visualizzazione** ‚Äî proiettare dati in 2D/3D\n",
    "- Combineremo PCA + Clustering nella Lezione 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ebc6ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö 6. Bignami ‚Äî DBSCAN\n",
    "\n",
    "### üìñ Definizioni Chiave\n",
    "\n",
    "| Termine | Definizione |\n",
    "|---------|-------------|\n",
    "| **DBSCAN** | Density-Based Spatial Clustering of Applications with Noise |\n",
    "| **eps (Œµ)** | Raggio del vicinato di un punto |\n",
    "| **min_samples** | Numero minimo di punti nel vicinato per essere \"denso\" |\n",
    "| **Core Point** | Punto con ‚â• min_samples vicini entro eps |\n",
    "| **Border Point** | Nel vicinato di un core point ma non √® core |\n",
    "| **Noise Point** | Non √® core e non √® nel vicinato di nessun core (label = -1) |\n",
    "| **k-distance graph** | Grafico per scegliere eps (cercare il gomito) |\n",
    "\n",
    "### üìê Formule\n",
    "\n",
    "| Concetto | Formula |\n",
    "|----------|---------|\n",
    "| Vicinato | $N_{eps}(p) = \\{q \\in D \\mid dist(p, q) \\leq eps\\}$ |\n",
    "| Core Point | $\\|N_{eps}(p)\\| \\geq min\\_samples$ |\n",
    "| min_samples consigliato | $min\\_samples \\geq D + 1$ (D = dimensionalit√†) |\n",
    "\n",
    "### ‚úÖ Checklist Pre-DBSCAN\n",
    "\n",
    "```\n",
    "‚ñ° Dati scalati con StandardScaler?\n",
    "‚ñ° min_samples ‚â• dimensioni + 1?\n",
    "‚ñ° Generato k-distance graph?\n",
    "‚ñ° Trovato il gomito per eps?\n",
    "‚ñ° Pronti a gestire label -1 (noise)?\n",
    "‚ñ° Silhouette calcolato SENZA noise?\n",
    "```\n",
    "\n",
    "### üíª Template di Codice\n",
    "\n",
    "```python\n",
    "# === DBSCAN COMPLETO ===\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. Stima eps con k-distance graph\n",
    "min_samples = 5  # ‚â• D + 1\n",
    "nn = NearestNeighbors(n_neighbors=min_samples)\n",
    "nn.fit(X_scaled)\n",
    "distances, _ = nn.kneighbors(X_scaled)\n",
    "k_distances = np.sort(distances[:, -1])\n",
    "\n",
    "# Plot per trovare il gomito\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_distances)\n",
    "plt.xlabel('Punti')\n",
    "plt.ylabel(f'Distanza al {min_samples}¬∞ vicino')\n",
    "plt.show()\n",
    "\n",
    "# 3. DBSCAN\n",
    "eps = 0.5  # Dal gomito\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# 4. Statistiche\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = (labels == -1).sum()\n",
    "print(f\"Cluster: {n_clusters}, Noise: {n_noise}\")\n",
    "\n",
    "# 5. Silhouette (ESCLUDI NOISE!)\n",
    "mask = labels != -1\n",
    "if mask.sum() > 1:\n",
    "    sil = silhouette_score(X_scaled[mask], labels[mask])\n",
    "    print(f\"Silhouette: {sil:.3f}\")\n",
    "\n",
    "# 6. Core samples\n",
    "core_mask = np.zeros(len(X), dtype=bool)\n",
    "core_mask[dbscan.core_sample_indices_] = True\n",
    "```\n",
    "\n",
    "### üéØ Quando Usare\n",
    "\n",
    "| Usa DBSCAN quando... | Evita DBSCAN quando... |\n",
    "|----------------------|------------------------|\n",
    "| Non conosci K | I cluster hanno densit√† diverse |\n",
    "| Ci sono outliers | Dati ad alta dimensionalit√† |\n",
    "| Cluster non sferici | Tutti i punti DEVONO essere in un cluster |\n",
    "| Vuoi anomaly detection | Hai bisogno di un modello predittivo |\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Lezione 23 Completata!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
