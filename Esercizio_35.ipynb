{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0293e4e6",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Teoria: Information Retrieval\n",
    "\n",
    "## 1.1 Definizione e Problema\n",
    "\n",
    "**Information Retrieval (IR)** Ã¨ la disciplina che si occupa di trovare materiale (solitamente documenti) di natura non strutturata (solitamente testo) che soddisfa un bisogno informativo, all'interno di grandi collezioni.\n",
    "\n",
    "### Il Problema Fondamentale\n",
    "\n",
    "```\n",
    "QUERY UTENTE  â†’  SISTEMA IR  â†’  DOCUMENTI RILEVANTI (ranked)\n",
    "   \"AI for healthcare\"     ?       [doc1, doc5, doc12, ...]\n",
    "```\n",
    "\n",
    "**Sfide principali:**\n",
    "\n",
    "1. **Vocabulary mismatch**: utente usa \"car\", documento contiene \"automobile\"\n",
    "2. **AmbiguitÃ **: \"bank\" = banca finanziaria o riva del fiume?\n",
    "3. **Rilevanza soggettiva**: ciÃ² che Ã¨ rilevante dipende dal contesto\n",
    "4. **ScalabilitÃ **: milioni/miliardi di documenti\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 Modelli di Information Retrieval\n",
    "\n",
    "### Modello Booleano\n",
    "\n",
    "Il piÃ¹ semplice: documenti sono insiemi di termini, query sono espressioni booleane.\n",
    "\n",
    "```\n",
    "Query: \"python AND machine learning AND NOT java\"\n",
    "```\n",
    "\n",
    "**Vantaggi:** Preciso, deterministico  \n",
    "**Svantaggi:** Nessun ranking, troppo rigido, difficile per utenti\n",
    "\n",
    "### Modello Vettoriale (Vector Space Model)\n",
    "\n",
    "Documenti e query sono rappresentati come **vettori** in uno spazio n-dimensionale, dove n = numero di termini nel vocabolario.\n",
    "\n",
    "```\n",
    "Vocabolario: [python, data, machine, learning, sql]\n",
    "\n",
    "Doc1: \"python data analysis\"   â†’ [1, 1, 0, 0, 0]  (o con TF-IDF)\n",
    "Doc2: \"machine learning python\" â†’ [1, 0, 1, 1, 0]\n",
    "Query: \"python machine learning\" â†’ [1, 0, 1, 1, 0]\n",
    "```\n",
    "\n",
    "**SimilaritÃ ** tra query e documento = similaritÃ  tra vettori.\n",
    "\n",
    "### SimilaritÃ  Coseno\n",
    "\n",
    "La misura piÃ¹ usata per confrontare vettori in IR:\n",
    "\n",
    "$$\\text{cosine}(\\vec{q}, \\vec{d}) = \\frac{\\vec{q} \\cdot \\vec{d}}{||\\vec{q}|| \\times ||\\vec{d}||}$$\n",
    "\n",
    "- Range: [0, 1] per vettori non-negativi (TF-IDF)\n",
    "- 1 = identici, 0 = ortogonali (nulla in comune)\n",
    "- Invariante rispetto alla lunghezza del documento\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Indice Invertito\n",
    "\n",
    "Struttura dati fondamentale per IR efficiente.\n",
    "\n",
    "**Forward Index** (inefficiente per ricerca):\n",
    "```\n",
    "Doc1 â†’ [python, data, analysis]\n",
    "Doc2 â†’ [machine, learning, python]\n",
    "Doc3 â†’ [sql, database, python]\n",
    "```\n",
    "\n",
    "**Inverted Index** (efficiente):\n",
    "```\n",
    "python    â†’ [Doc1, Doc2, Doc3]\n",
    "data      â†’ [Doc1]\n",
    "machine   â†’ [Doc2]\n",
    "learning  â†’ [Doc2]\n",
    "sql       â†’ [Doc3]\n",
    "database  â†’ [Doc3]\n",
    "analysis  â†’ [Doc1]\n",
    "```\n",
    "\n",
    "**Con posizioni** (per phrase queries):\n",
    "```\n",
    "python â†’ [Doc1:pos1, Doc2:pos3, Doc3:pos3]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Valutazione dei Sistemi IR\n",
    "\n",
    "### Precision e Recall\n",
    "\n",
    "Per una query, dato un insieme di documenti **rilevanti** (ground truth):\n",
    "\n",
    "$$\\text{Precision} = \\frac{|\\text{Retrieved} \\cap \\text{Relevant}|}{|\\text{Retrieved}|}$$\n",
    "\n",
    "$$\\text{Recall} = \\frac{|\\text{Retrieved} \\cap \\text{Relevant}|}{|\\text{Relevant}|}$$\n",
    "\n",
    "**Esempio:**\n",
    "- Documenti totali: 100\n",
    "- Documenti rilevanti: 10\n",
    "- Documenti restituiti dal sistema: 8\n",
    "- Di questi, 5 sono effettivamente rilevanti\n",
    "\n",
    "```\n",
    "Precision = 5/8 = 62.5%  (\"quanto Ã¨ pulito il risultato\")\n",
    "Recall    = 5/10 = 50%   (\"quanto ho trovato del totale\")\n",
    "```\n",
    "\n",
    "### F1-Score\n",
    "\n",
    "Media armonica di precision e recall:\n",
    "\n",
    "$$F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "### Precision@K e Recall@K\n",
    "\n",
    "Valuta solo i primi K risultati:\n",
    "\n",
    "```\n",
    "Precision@5 = rilevanti nei primi 5 / 5\n",
    "Precision@10 = rilevanti nei primi 10 / 10\n",
    "```\n",
    "\n",
    "### Mean Average Precision (MAP)\n",
    "\n",
    "Media delle Average Precision su piÃ¹ query:\n",
    "\n",
    "$$AP(q) = \\frac{1}{|R_q|} \\sum_{k=1}^{n} P(k) \\cdot rel(k)$$\n",
    "\n",
    "Dove:\n",
    "- $P(k)$ = precision at rank k\n",
    "- $rel(k)$ = 1 se doc a rank k Ã¨ rilevante, 0 altrimenti\n",
    "\n",
    "---\n",
    "\n",
    "## 1.5 Tecniche Avanzate\n",
    "\n",
    "### Query Expansion\n",
    "\n",
    "Aggiunge termini alla query per migliorare recall:\n",
    "\n",
    "```\n",
    "Query originale: \"automobile\"\n",
    "Query espansa:   \"automobile car vehicle auto\"\n",
    "```\n",
    "\n",
    "**Tecniche:**\n",
    "- Sinonimi da thesaurus\n",
    "- Termini da documenti rilevanti (relevance feedback)\n",
    "- Word embeddings (termini simili nello spazio vettoriale)\n",
    "\n",
    "### Relevance Feedback\n",
    "\n",
    "L'utente indica quali risultati sono rilevanti, il sistema riformula la query.\n",
    "\n",
    "**Rocchio Algorithm:**\n",
    "\n",
    "$$\\vec{q}_{new} = \\alpha \\vec{q}_{old} + \\beta \\frac{1}{|D_r|} \\sum_{d \\in D_r} \\vec{d} - \\gamma \\frac{1}{|D_{nr}|} \\sum_{d \\in D_{nr}} \\vec{d}$$\n",
    "\n",
    "Dove:\n",
    "- $D_r$ = documenti rilevanti\n",
    "- $D_{nr}$ = documenti non rilevanti\n",
    "- $\\alpha, \\beta, \\gamma$ = pesi (tipicamente 1, 0.75, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd90aa",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Schema Mentale\n",
    "\n",
    "## Architettura Sistema IR\n",
    "\n",
    "```\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚         SISTEMA IR                   â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                    â”‚\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚                         â”‚                         â”‚\n",
    "          â–¼                         â–¼                         â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚   INDEXING    â”‚        â”‚   RETRIEVAL   â”‚        â”‚  EVALUATION   â”‚\n",
    "  â”‚               â”‚        â”‚               â”‚        â”‚               â”‚\n",
    "  â”‚ â€¢ Tokenize    â”‚        â”‚ â€¢ Parse query â”‚        â”‚ â€¢ Precision   â”‚\n",
    "  â”‚ â€¢ Normalize   â”‚        â”‚ â€¢ Vectorize   â”‚        â”‚ â€¢ Recall      â”‚\n",
    "  â”‚ â€¢ Inverted Idxâ”‚        â”‚ â€¢ Similarity  â”‚        â”‚ â€¢ F1          â”‚\n",
    "  â”‚ â€¢ TF-IDF      â”‚        â”‚ â€¢ Rank        â”‚        â”‚ â€¢ MAP         â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "          â”‚                         â”‚                         â”‚\n",
    "          â–¼                         â–¼                         â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚   INDEX    â”‚           â”‚  RANKED    â”‚           â”‚  METRICS   â”‚\n",
    "   â”‚  (stored)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  RESULTS   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  REPORT    â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Decision Tree: Quale Approccio?\n",
    "\n",
    "```\n",
    "                    Tipo di Ricerca?\n",
    "                          â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚                 â”‚                 â”‚\n",
    "        â–¼                 â–¼                 â–¼\n",
    "     Esatta          Semantica         Ibrida\n",
    "        â”‚                 â”‚                 â”‚\n",
    "        â–¼                 â–¼                 â–¼\n",
    "   Inverted Index    Embeddings      BM25 + Dense\n",
    "   + BM25/TF-IDF     + ANN Search    Retrieval\n",
    "```\n",
    "\n",
    "## Pipeline Implementativa\n",
    "\n",
    "```\n",
    "DOCUMENTI â”€â”€â–¶ Preprocessing â”€â”€â–¶ Vectorization â”€â”€â–¶ INDEX\n",
    "                   â”‚                  â”‚              â”‚\n",
    "                   â”‚                  â”‚              â”‚\n",
    "              Lowercase          TF-IDF           Store\n",
    "              Tokenize           Matrice          (pickle/\n",
    "              Stopwords          Sparsa            disk)\n",
    "              Stemming\n",
    "\n",
    "\n",
    "QUERY â”€â”€â–¶ Same Preprocessing â”€â”€â–¶ Vectorization â”€â”€â–¶ SIMILARITY â”€â”€â–¶ RANKED DOCS\n",
    "                                                        â”‚\n",
    "                                                        â–¼\n",
    "                                                  Cosine(q, d)\n",
    "                                                  for each d\n",
    "```\n",
    "\n",
    "## Metriche: Quando Usare Cosa\n",
    "\n",
    "| Metrica | Usa Quando | Interpretazione |\n",
    "|---------|------------|------------------|\n",
    "| Precision@K | Utente guarda pochi risultati | QualitÃ  top results |\n",
    "| Recall | Trovare tutto Ã¨ importante | Copertura |\n",
    "| F1 | Bilanciare P e R | Score unico |\n",
    "| MAP | Confrontare sistemi | Performance media |\n",
    "| MRR | Un solo doc rilevante | Rank del primo hit |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e26acc",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Notebook Dimostrativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef907c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP E IMPORT\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Import completati.\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 1: INDICE INVERTITO\n",
    "# ============================================================\n",
    "\n",
    "class InvertedIndex:\n",
    "    \"\"\"\n",
    "    Implementazione base di un indice invertito.\n",
    "    \n",
    "    L'indice mappa ogni termine ai documenti che lo contengono,\n",
    "    con le posizioni di occorrenza.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Struttura: {termine: {doc_id: [posizioni]}}\n",
    "        self.index = defaultdict(lambda: defaultdict(list))\n",
    "        # Documenti originali\n",
    "        self.documents = {}\n",
    "        # Statistiche\n",
    "        self.doc_count = 0\n",
    "        self.term_count = 0\n",
    "    \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenizzazione semplice: lowercase + split su non-alfanumerici.\"\"\"\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(r'\\b[a-z]+\\b', text)  # Solo parole alfabetiche\n",
    "        return tokens\n",
    "    \n",
    "    def add_document(self, doc_id: str, text: str):\n",
    "        \"\"\"Aggiunge un documento all'indice.\"\"\"\n",
    "        # Salva documento originale\n",
    "        self.documents[doc_id] = text\n",
    "        self.doc_count += 1\n",
    "        \n",
    "        # Tokenizza e indicizza\n",
    "        tokens = self.tokenize(text)\n",
    "        for position, token in enumerate(tokens):\n",
    "            self.index[token][doc_id].append(position)\n",
    "        \n",
    "        # Aggiorna conteggio termini unici\n",
    "        self.term_count = len(self.index)\n",
    "    \n",
    "    def search(self, query: str) -> Dict[str, List[int]]:\n",
    "        \"\"\"Cerca documenti che contengono il termine.\"\"\"\n",
    "        query_term = query.lower().strip()\n",
    "        if query_term in self.index:\n",
    "            return dict(self.index[query_term])\n",
    "        return {}\n",
    "    \n",
    "    def boolean_search(self, terms: List[str], operator: str = 'AND') -> List[str]:\n",
    "        \"\"\"Ricerca booleana: AND o OR tra termini.\"\"\"\n",
    "        if not terms:\n",
    "            return []\n",
    "        \n",
    "        # Trova documenti per ogni termine\n",
    "        doc_sets = []\n",
    "        for term in terms:\n",
    "            term_lower = term.lower().strip()\n",
    "            if term_lower in self.index:\n",
    "                doc_sets.append(set(self.index[term_lower].keys()))\n",
    "            else:\n",
    "                doc_sets.append(set())\n",
    "        \n",
    "        # Applica operatore\n",
    "        if operator.upper() == 'AND':\n",
    "            result = doc_sets[0]\n",
    "            for s in doc_sets[1:]:\n",
    "                result = result.intersection(s)\n",
    "        else:  # OR\n",
    "            result = set()\n",
    "            for s in doc_sets:\n",
    "                result = result.union(s)\n",
    "        \n",
    "        return list(result)\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Statistiche sull'indice.\"\"\"\n",
    "        return {\n",
    "            'num_documents': self.doc_count,\n",
    "            'vocabulary_size': self.term_count,\n",
    "            'avg_terms_per_doc': sum(len(self.tokenize(d)) \n",
    "                                     for d in self.documents.values()) / max(self.doc_count, 1)\n",
    "        }\n",
    "\n",
    "# Test dell'indice invertito\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 1: INDICE INVERTITO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crea indice\n",
    "idx = InvertedIndex()\n",
    "\n",
    "# Aggiungi documenti\n",
    "docs = {\n",
    "    'doc1': 'Python is great for data science and machine learning',\n",
    "    'doc2': 'Machine learning with Python and TensorFlow',\n",
    "    'doc3': 'Data analysis using SQL and Python',\n",
    "    'doc4': 'JavaScript for web development',\n",
    "    'doc5': 'Deep learning and neural networks with Python'\n",
    "}\n",
    "\n",
    "for doc_id, text in docs.items():\n",
    "    idx.add_document(doc_id, text)\n",
    "\n",
    "print(\"\\nðŸ“Š Statistiche indice:\")\n",
    "stats = idx.get_stats()\n",
    "for k, v in stats.items():\n",
    "    print(f\"   {k}: {v:.2f}\" if isinstance(v, float) else f\"   {k}: {v}\")\n",
    "\n",
    "# Ricerca singolo termine\n",
    "print(\"\\nðŸ” Ricerca 'python':\")\n",
    "result = idx.search('python')\n",
    "for doc_id, positions in result.items():\n",
    "    print(f\"   {doc_id}: posizioni {positions}\")\n",
    "\n",
    "# Ricerca booleana AND\n",
    "print(\"\\nðŸ” Ricerca booleana 'python AND learning':\")\n",
    "result_and = idx.boolean_search(['python', 'learning'], 'AND')\n",
    "print(f\"   Documenti: {result_and}\")\n",
    "\n",
    "# Ricerca booleana OR\n",
    "print(\"\\nðŸ” Ricerca booleana 'sql OR javascript':\")\n",
    "result_or = idx.boolean_search(['sql', 'javascript'], 'OR')\n",
    "print(f\"   Documenti: {result_or}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86efd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 2: SISTEMA IR CON TF-IDF E COSINE SIMILARITY\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Risultato di una ricerca.\"\"\"\n",
    "    doc_id: str\n",
    "    score: float\n",
    "    snippet: str\n",
    "\n",
    "class TFIDFSearchEngine:\n",
    "    \"\"\"\n",
    "    Motore di ricerca basato su TF-IDF e similaritÃ  coseno.\n",
    "    \n",
    "    Workflow:\n",
    "    1. Indicizza documenti con TF-IDF\n",
    "    2. Trasforma query nello stesso spazio\n",
    "    3. Calcola similaritÃ  coseno\n",
    "    4. Restituisce documenti ranked\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_features: int = 5000):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,  # Limita vocabolario\n",
    "            stop_words='english',       # Rimuovi stopwords\n",
    "            ngram_range=(1, 2),         # Unigrammi e bigrammi\n",
    "            lowercase=True\n",
    "        )\n",
    "        self.doc_vectors = None    # Matrice TF-IDF documenti\n",
    "        self.documents = {}         # doc_id -> testo\n",
    "        self.doc_ids = []           # Lista ordinata doc_id\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def index(self, documents: Dict[str, str]):\n",
    "        \"\"\"\n",
    "        Indicizza una collezione di documenti.\n",
    "        \n",
    "        Args:\n",
    "            documents: {doc_id: testo}\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.doc_ids = list(documents.keys())\n",
    "        \n",
    "        # Crea matrice TF-IDF\n",
    "        texts = [documents[doc_id] for doc_id in self.doc_ids]\n",
    "        self.doc_vectors = self.vectorizer.fit_transform(texts)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        print(f\"Indicizzati {len(documents)} documenti\")\n",
    "        print(f\"Vocabolario: {len(self.vectorizer.vocabulary_)} termini\")\n",
    "        print(f\"Matrice: {self.doc_vectors.shape}\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:\n",
    "        \"\"\"\n",
    "        Cerca documenti rilevanti per la query.\n",
    "        \n",
    "        Args:\n",
    "            query: testo della query\n",
    "            top_k: numero massimo di risultati\n",
    "            \n",
    "        Returns:\n",
    "            Lista di SearchResult ordinati per score decrescente\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Indice non inizializzato. Chiamare index() prima.\")\n",
    "        \n",
    "        # Trasforma query nello stesso spazio TF-IDF\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        \n",
    "        # Calcola similaritÃ  coseno con tutti i documenti\n",
    "        similarities = cosine_similarity(query_vector, self.doc_vectors)[0]\n",
    "        \n",
    "        # Ordina per similaritÃ  decrescente\n",
    "        ranked_indices = similarities.argsort()[::-1][:top_k]\n",
    "        \n",
    "        # Costruisci risultati\n",
    "        results = []\n",
    "        for idx in ranked_indices:\n",
    "            if similarities[idx] > 0:  # Solo risultati con match\n",
    "                doc_id = self.doc_ids[idx]\n",
    "                results.append(SearchResult(\n",
    "                    doc_id=doc_id,\n",
    "                    score=similarities[idx],\n",
    "                    snippet=self.documents[doc_id][:100] + '...'\n",
    "                ))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_similar_docs(self, doc_id: str, top_k: int = 3) -> List[SearchResult]:\n",
    "        \"\"\"Trova documenti simili a un documento dato.\"\"\"\n",
    "        if doc_id not in self.documents:\n",
    "            raise ValueError(f\"Documento {doc_id} non trovato\")\n",
    "        \n",
    "        # Usa il documento come query\n",
    "        return self.search(self.documents[doc_id], top_k + 1)[1:]  # Escludi se stesso\n",
    "\n",
    "# Test\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 2: SEARCH ENGINE TF-IDF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset di documenti (articoli fittizi)\n",
    "articles = {\n",
    "    'art1': 'Python programming language is widely used in data science. Python offers many libraries for machine learning and data analysis.',\n",
    "    'art2': 'Machine learning algorithms can predict outcomes based on data. Deep learning is a subset of machine learning using neural networks.',\n",
    "    'art3': 'SQL databases store structured data efficiently. Query optimization is important for database performance.',\n",
    "    'art4': 'Web development with JavaScript and React creates interactive user interfaces. Frontend frameworks improve developer productivity.',\n",
    "    'art5': 'Data visualization helps communicate insights. Charts and graphs make data more understandable for stakeholders.',\n",
    "    'art6': 'Natural language processing enables computers to understand human language. Text classification and sentiment analysis are NLP applications.',\n",
    "    'art7': 'Cloud computing provides scalable infrastructure. AWS and Azure offer machine learning services in the cloud.',\n",
    "    'art8': 'Statistical analysis reveals patterns in data. Hypothesis testing and regression are fundamental statistical methods.'\n",
    "}\n",
    "\n",
    "# Crea e popola search engine\n",
    "engine = TFIDFSearchEngine()\n",
    "engine.index(articles)\n",
    "\n",
    "# Test ricerche\n",
    "queries = [\n",
    "    'machine learning python',\n",
    "    'database SQL query',\n",
    "    'data visualization charts'\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nðŸ” Query: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    results = engine.search(query, top_k=3)\n",
    "    for i, res in enumerate(results, 1):\n",
    "        print(f\"   {i}. [{res.doc_id}] Score: {res.score:.4f}\")\n",
    "        print(f\"      {res.snippet}\")\n",
    "\n",
    "# Documenti simili\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DOCUMENTI SIMILI\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nðŸ“„ Documenti simili a 'art1' (Python programming):\")\n",
    "similar = engine.get_similar_docs('art1', top_k=2)\n",
    "for res in similar:\n",
    "    print(f\"   - [{res.doc_id}] Score: {res.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 3: VALUTAZIONE IR - PRECISION, RECALL, F1\n",
    "# ============================================================\n",
    "\n",
    "class IRMetrics:\n",
    "    \"\"\"\n",
    "    Calcola metriche di valutazione per sistemi IR.\n",
    "    \n",
    "    Richiede:\n",
    "    - Documenti restituiti dal sistema (retrieved)\n",
    "    - Documenti rilevanti secondo ground truth (relevant)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision(retrieved: List[str], relevant: set) -> float:\n",
    "        \"\"\"Precision = |retrieved âˆ© relevant| / |retrieved|\"\"\"\n",
    "        if not retrieved:\n",
    "            return 0.0\n",
    "        retrieved_set = set(retrieved)\n",
    "        return len(retrieved_set & relevant) / len(retrieved_set)\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall(retrieved: List[str], relevant: set) -> float:\n",
    "        \"\"\"Recall = |retrieved âˆ© relevant| / |relevant|\"\"\"\n",
    "        if not relevant:\n",
    "            return 0.0\n",
    "        retrieved_set = set(retrieved)\n",
    "        return len(retrieved_set & relevant) / len(relevant)\n",
    "    \n",
    "    @staticmethod\n",
    "    def f1_score(precision: float, recall: float) -> float:\n",
    "        \"\"\"F1 = 2 * (precision * recall) / (precision + recall)\"\"\"\n",
    "        if precision + recall == 0:\n",
    "            return 0.0\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_at_k(retrieved: List[str], relevant: set, k: int) -> float:\n",
    "        \"\"\"Precision considerando solo i primi k risultati.\"\"\"\n",
    "        return IRMetrics.precision(retrieved[:k], relevant)\n",
    "    \n",
    "    @staticmethod\n",
    "    def average_precision(retrieved: List[str], relevant: set) -> float:\n",
    "        \"\"\"\n",
    "        Average Precision: media delle precision a ogni rank dove\n",
    "        compare un documento rilevante.\n",
    "        \"\"\"\n",
    "        if not relevant:\n",
    "            return 0.0\n",
    "        \n",
    "        precisions = []\n",
    "        relevant_found = 0\n",
    "        \n",
    "        for i, doc in enumerate(retrieved):\n",
    "            if doc in relevant:\n",
    "                relevant_found += 1\n",
    "                p_at_i = relevant_found / (i + 1)\n",
    "                precisions.append(p_at_i)\n",
    "        \n",
    "        if not precisions:\n",
    "            return 0.0\n",
    "        \n",
    "        return sum(precisions) / len(relevant)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean_average_precision(queries_results: List[Tuple[List[str], set]]) -> float:\n",
    "        \"\"\"\n",
    "        MAP: media delle Average Precision su multiple query.\n",
    "        \n",
    "        Args:\n",
    "            queries_results: [(retrieved_list, relevant_set), ...]\n",
    "        \"\"\"\n",
    "        if not queries_results:\n",
    "            return 0.0\n",
    "        \n",
    "        aps = [IRMetrics.average_precision(r, rel) for r, rel in queries_results]\n",
    "        return sum(aps) / len(aps)\n",
    "\n",
    "# Test metriche\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 3: METRICHE IR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Scenario: ricerca \"machine learning\"\n",
    "# Ground truth: documenti effettivamente rilevanti\n",
    "relevant_docs = {'art1', 'art2', 'art6', 'art7'}  # 4 documenti rilevanti\n",
    "\n",
    "# Sistema restituisce (in ordine di ranking)\n",
    "retrieved_docs = ['art2', 'art1', 'art5', 'art6', 'art3']  # 5 risultati\n",
    "\n",
    "print(\"\\nðŸ“Š Scenario di valutazione\")\n",
    "print(f\"   Documenti rilevanti (ground truth): {relevant_docs}\")\n",
    "print(f\"   Documenti restituiti (ranked): {retrieved_docs}\")\n",
    "\n",
    "# Calcola metriche\n",
    "metrics = IRMetrics()\n",
    "\n",
    "p = metrics.precision(retrieved_docs, relevant_docs)\n",
    "r = metrics.recall(retrieved_docs, relevant_docs)\n",
    "f1 = metrics.f1_score(p, r)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Metriche Base:\")\n",
    "print(f\"   Precision: {p:.2%} ({len(set(retrieved_docs) & relevant_docs)}/{len(retrieved_docs)})\")\n",
    "print(f\"   Recall:    {r:.2%} ({len(set(retrieved_docs) & relevant_docs)}/{len(relevant_docs)})\")\n",
    "print(f\"   F1-Score:  {f1:.2%}\")\n",
    "\n",
    "# Precision@K\n",
    "print(f\"\\nðŸ“ˆ Precision@K:\")\n",
    "for k in [1, 3, 5]:\n",
    "    p_at_k = metrics.precision_at_k(retrieved_docs, relevant_docs, k)\n",
    "    print(f\"   P@{k}: {p_at_k:.2%}\")\n",
    "\n",
    "# Average Precision\n",
    "ap = metrics.average_precision(retrieved_docs, relevant_docs)\n",
    "print(f\"\\nðŸ“ˆ Average Precision: {ap:.4f}\")\n",
    "\n",
    "# Spiegazione dettagliata AP\n",
    "print(\"\\n   Calcolo AP step by step:\")\n",
    "rel_count = 0\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    is_rel = \"âœ“\" if doc in relevant_docs else \"âœ—\"\n",
    "    if doc in relevant_docs:\n",
    "        rel_count += 1\n",
    "        p_at_i = rel_count / (i + 1)\n",
    "        print(f\"   Rank {i+1}: {doc} {is_rel} â†’ P@{i+1}={p_at_i:.3f} (contribuisce ad AP)\")\n",
    "    else:\n",
    "        print(f\"   Rank {i+1}: {doc} {is_rel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 4: QUERY EXPANSION\n",
    "# ============================================================\n",
    "\n",
    "class QueryExpander:\n",
    "    \"\"\"\n",
    "    Espande query con sinonimi e termini correlati.\n",
    "    \n",
    "    Tecniche:\n",
    "    1. Thesaurus-based: sinonimi da dizionario\n",
    "    2. Corpus-based: termini co-occorrenti\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Thesaurus semplificato\n",
    "        self.synonyms = {\n",
    "            'car': ['automobile', 'vehicle', 'auto'],\n",
    "            'big': ['large', 'huge', 'enormous'],\n",
    "            'fast': ['quick', 'rapid', 'speedy'],\n",
    "            'machine learning': ['ml', 'artificial intelligence', 'ai'],\n",
    "            'database': ['db', 'data store', 'databank'],\n",
    "            'error': ['bug', 'fault', 'defect', 'issue'],\n",
    "            'analyze': ['examine', 'investigate', 'study'],\n",
    "            'python': ['py'],\n",
    "            'javascript': ['js'],\n",
    "        }\n",
    "        \n",
    "        # Reverse mapping\n",
    "        self.reverse_synonyms = {}\n",
    "        for term, syns in self.synonyms.items():\n",
    "            for syn in syns:\n",
    "                if syn not in self.reverse_synonyms:\n",
    "                    self.reverse_synonyms[syn] = []\n",
    "                self.reverse_synonyms[syn].append(term)\n",
    "    \n",
    "    def expand_thesaurus(self, query: str, max_expansions: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Espande query usando il thesaurus.\n",
    "        \n",
    "        Args:\n",
    "            query: query originale\n",
    "            max_expansions: max sinonimi per termine\n",
    "            \n",
    "        Returns:\n",
    "            Query espansa\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        expanded_terms = [query_lower]  # Include originale\n",
    "        \n",
    "        # Cerca match nel thesaurus (prima frasi, poi singole parole)\n",
    "        for term, syns in self.synonyms.items():\n",
    "            if term in query_lower:\n",
    "                expanded_terms.extend(syns[:max_expansions])\n",
    "        \n",
    "        # Cerca anche in reverse\n",
    "        for term, originals in self.reverse_synonyms.items():\n",
    "            if term in query_lower:\n",
    "                expanded_terms.extend(originals[:max_expansions])\n",
    "        \n",
    "        # Rimuovi duplicati mantenendo ordine\n",
    "        seen = set()\n",
    "        unique = []\n",
    "        for t in expanded_terms:\n",
    "            if t not in seen:\n",
    "                seen.add(t)\n",
    "                unique.append(t)\n",
    "        \n",
    "        return ' '.join(unique)\n",
    "    \n",
    "    def expand_with_corpus(self, query: str, corpus_vectorizer: TfidfVectorizer,\n",
    "                           corpus_matrix, n_terms: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        Espande query con termini correlati dal corpus.\n",
    "        \n",
    "        Trova termini che co-occorrono frequentemente con\n",
    "        i termini della query nel corpus.\n",
    "        \"\"\"\n",
    "        # Trasforma query\n",
    "        query_vec = corpus_vectorizer.transform([query])\n",
    "        \n",
    "        # Trova documenti piÃ¹ simili\n",
    "        similarities = cosine_similarity(query_vec, corpus_matrix)[0]\n",
    "        top_doc_idx = similarities.argsort()[-3:][::-1]  # Top 3 docs\n",
    "        \n",
    "        # Estrai termini importanti da quei documenti\n",
    "        feature_names = corpus_vectorizer.get_feature_names_out()\n",
    "        expansion_terms = set()\n",
    "        \n",
    "        for idx in top_doc_idx:\n",
    "            doc_vec = corpus_matrix[idx].toarray()[0]\n",
    "            top_term_indices = doc_vec.argsort()[-n_terms:][::-1]\n",
    "            for term_idx in top_term_indices:\n",
    "                if doc_vec[term_idx] > 0:\n",
    "                    expansion_terms.add(feature_names[term_idx])\n",
    "        \n",
    "        # Combina con query originale\n",
    "        expanded = query + ' ' + ' '.join(expansion_terms)\n",
    "        return expanded\n",
    "\n",
    "# Test\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 4: QUERY EXPANSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "expander = QueryExpander()\n",
    "\n",
    "test_queries = [\n",
    "    'machine learning python',\n",
    "    'fix database error',\n",
    "    'analyze big data fast'\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“ Espansione con Thesaurus:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    expanded = expander.expand_thesaurus(query)\n",
    "    print(f\"\\nOriginale: '{query}'\")\n",
    "    print(f\"Espansa:   '{expanded}'\")\n",
    "\n",
    "# Test corpus-based expansion\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸ“ Espansione basata su Corpus:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Usa l'engine creato prima\n",
    "expanded_corpus = expander.expand_with_corpus(\n",
    "    'machine learning', \n",
    "    engine.vectorizer, \n",
    "    engine.doc_vectors,\n",
    "    n_terms=5\n",
    ")\n",
    "print(f\"\\nOriginale: 'machine learning'\")\n",
    "print(f\"Espansa:   '{expanded_corpus}'\")\n",
    "\n",
    "# Confronto risultati\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ðŸ“Š Confronto Ricerca Originale vs Espansa\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "query_orig = 'machine learning'\n",
    "query_exp = expander.expand_thesaurus(query_orig)\n",
    "\n",
    "results_orig = engine.search(query_orig, top_k=3)\n",
    "results_exp = engine.search(query_exp, top_k=3)\n",
    "\n",
    "print(f\"\\nQuery originale: '{query_orig}'\")\n",
    "for r in results_orig:\n",
    "    print(f\"   {r.doc_id}: {r.score:.4f}\")\n",
    "\n",
    "print(f\"\\nQuery espansa: '{query_exp}'\")\n",
    "for r in results_exp:\n",
    "    print(f\"   {r.doc_id}: {r.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMO 5: SEARCH ENGINE COMPLETO\n",
    "# ============================================================\n",
    "\n",
    "class AdvancedSearchEngine:\n",
    "    \"\"\"\n",
    "    Search engine completo con:\n",
    "    - Indicizzazione TF-IDF\n",
    "    - Query expansion\n",
    "    - Ranking\n",
    "    - Metriche di valutazione\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.engine = TFIDFSearchEngine(max_features=3000)\n",
    "        self.expander = QueryExpander()\n",
    "        self.metrics = IRMetrics()\n",
    "        self.search_history = []  # Log ricerche\n",
    "    \n",
    "    def index(self, documents: Dict[str, str]):\n",
    "        \"\"\"Indicizza documenti.\"\"\"\n",
    "        self.engine.index(documents)\n",
    "    \n",
    "    def search(self, query: str, expand: bool = False, top_k: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Esegue ricerca con opzioni avanzate.\n",
    "        \n",
    "        Args:\n",
    "            query: testo query\n",
    "            expand: se True, espande la query\n",
    "            top_k: numero risultati\n",
    "            \n",
    "        Returns:\n",
    "            Dict con risultati e metadati\n",
    "        \"\"\"\n",
    "        # Espansione opzionale\n",
    "        processed_query = query\n",
    "        if expand:\n",
    "            processed_query = self.expander.expand_thesaurus(query)\n",
    "        \n",
    "        # Ricerca\n",
    "        results = self.engine.search(processed_query, top_k)\n",
    "        \n",
    "        # Log\n",
    "        search_log = {\n",
    "            'original_query': query,\n",
    "            'processed_query': processed_query,\n",
    "            'expansion_used': expand,\n",
    "            'num_results': len(results),\n",
    "            'results': [{'doc_id': r.doc_id, 'score': r.score} for r in results]\n",
    "        }\n",
    "        self.search_history.append(search_log)\n",
    "        \n",
    "        return {\n",
    "            'query': processed_query,\n",
    "            'results': results,\n",
    "            'expanded': expand\n",
    "        }\n",
    "    \n",
    "    def evaluate(self, test_queries: Dict[str, set], expand: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Valuta performance su un set di query con ground truth.\n",
    "        \n",
    "        Args:\n",
    "            test_queries: {query: set di doc_id rilevanti}\n",
    "            expand: se usare query expansion\n",
    "            \n",
    "        Returns:\n",
    "            Dict con metriche aggregate\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        query_metrics = []\n",
    "        \n",
    "        for query, relevant in test_queries.items():\n",
    "            # Esegui ricerca\n",
    "            search_result = self.search(query, expand=expand, top_k=10)\n",
    "            retrieved = [r.doc_id for r in search_result['results']]\n",
    "            \n",
    "            # Calcola metriche per questa query\n",
    "            p = self.metrics.precision(retrieved, relevant)\n",
    "            r = self.metrics.recall(retrieved, relevant)\n",
    "            f1 = self.metrics.f1_score(p, r)\n",
    "            ap = self.metrics.average_precision(retrieved, relevant)\n",
    "            \n",
    "            query_metrics.append({\n",
    "                'query': query,\n",
    "                'precision': p,\n",
    "                'recall': r,\n",
    "                'f1': f1,\n",
    "                'ap': ap\n",
    "            })\n",
    "            \n",
    "            all_results.append((retrieved, relevant))\n",
    "        \n",
    "        # Metriche aggregate\n",
    "        map_score = self.metrics.mean_average_precision(all_results)\n",
    "        avg_p = np.mean([m['precision'] for m in query_metrics])\n",
    "        avg_r = np.mean([m['recall'] for m in query_metrics])\n",
    "        avg_f1 = np.mean([m['f1'] for m in query_metrics])\n",
    "        \n",
    "        return {\n",
    "            'per_query': query_metrics,\n",
    "            'aggregate': {\n",
    "                'MAP': map_score,\n",
    "                'avg_precision': avg_p,\n",
    "                'avg_recall': avg_r,\n",
    "                'avg_f1': avg_f1\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Test completo\n",
    "print(\"=\"*60)\n",
    "print(\"DEMO 5: SEARCH ENGINE COMPLETO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crea engine\n",
    "adv_engine = AdvancedSearchEngine()\n",
    "adv_engine.index(articles)  # Usa articles definito prima\n",
    "\n",
    "# Test ricerca\n",
    "print(\"\\nðŸ” Ricerca normale:\")\n",
    "result = adv_engine.search('machine learning', expand=False, top_k=3)\n",
    "for r in result['results']:\n",
    "    print(f\"   {r.doc_id}: {r.score:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ” Ricerca con expansion:\")\n",
    "result_exp = adv_engine.search('machine learning', expand=True, top_k=3)\n",
    "print(f\"   Query espansa: {result_exp['query']}\")\n",
    "for r in result_exp['results']:\n",
    "    print(f\"   {r.doc_id}: {r.score:.4f}\")\n",
    "\n",
    "# Valutazione\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VALUTAZIONE SISTEMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ground truth per test\n",
    "test_queries = {\n",
    "    'python programming': {'art1'},\n",
    "    'machine learning': {'art1', 'art2', 'art7'},\n",
    "    'database query': {'art3'},\n",
    "    'data analysis visualization': {'art1', 'art5'},\n",
    "}\n",
    "\n",
    "# Valuta senza expansion\n",
    "print(\"\\nðŸ“Š Valutazione SENZA query expansion:\")\n",
    "eval_no_exp = adv_engine.evaluate(test_queries, expand=False)\n",
    "print(f\"   MAP: {eval_no_exp['aggregate']['MAP']:.4f}\")\n",
    "print(f\"   Avg Precision: {eval_no_exp['aggregate']['avg_precision']:.4f}\")\n",
    "print(f\"   Avg Recall: {eval_no_exp['aggregate']['avg_recall']:.4f}\")\n",
    "\n",
    "# Valuta con expansion\n",
    "print(\"\\nðŸ“Š Valutazione CON query expansion:\")\n",
    "eval_exp = adv_engine.evaluate(test_queries, expand=True)\n",
    "print(f\"   MAP: {eval_exp['aggregate']['MAP']:.4f}\")\n",
    "print(f\"   Avg Precision: {eval_exp['aggregate']['avg_precision']:.4f}\")\n",
    "print(f\"   Avg Recall: {eval_exp['aggregate']['avg_recall']:.4f}\")\n",
    "\n",
    "# Confronto\n",
    "print(\"\\nðŸ“ˆ Confronto:\")\n",
    "map_diff = eval_exp['aggregate']['MAP'] - eval_no_exp['aggregate']['MAP']\n",
    "print(f\"   Î” MAP con expansion: {map_diff:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d27f2b",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Esercizi Svolti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d29212",
   "metadata": {},
   "source": [
    "---\n",
    "## Esercizio 1: Motore di Ricerca per Documentazione Tecnica\n",
    "\n",
    "**Obiettivo:** Costruire un motore di ricerca per documentazione tecnica con supporto per ricerca esatta e fuzzy, snippet highlighting e metriche di valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac47469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 1 - SOLUZIONE\n",
    "# Motore di Ricerca per Documentazione Tecnica\n",
    "# ============================================================\n",
    "\n",
    "class TechDocsSearchEngine:\n",
    "    \"\"\"\n",
    "    Search engine specializzato per documentazione tecnica.\n",
    "    \n",
    "    Features:\n",
    "    - Ricerca full-text con TF-IDF\n",
    "    - Snippet extraction con highlighting\n",
    "    - Ricerca per sezione (API, Tutorial, FAQ)\n",
    "    - Metriche di performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            ngram_range=(1, 3),  # Fino a trigrammi per frasi tecniche\n",
    "            stop_words='english'\n",
    "        )\n",
    "        self.doc_matrix = None\n",
    "        self.documents = {}\n",
    "        self.doc_metadata = {}  # Metadati aggiuntivi\n",
    "        self.doc_ids = []\n",
    "    \n",
    "    def add_document(self, doc_id: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"\n",
    "        Aggiunge documento con metadati.\n",
    "        \n",
    "        Args:\n",
    "            doc_id: identificativo documento\n",
    "            content: testo del documento\n",
    "            metadata: {section, tags, author, ...}\n",
    "        \"\"\"\n",
    "        self.documents[doc_id] = content\n",
    "        self.doc_metadata[doc_id] = metadata or {}\n",
    "    \n",
    "    def build_index(self):\n",
    "        \"\"\"Costruisce l'indice TF-IDF.\"\"\"\n",
    "        self.doc_ids = list(self.documents.keys())\n",
    "        texts = [self.documents[doc_id] for doc_id in self.doc_ids]\n",
    "        self.doc_matrix = self.vectorizer.fit_transform(texts)\n",
    "        print(f\"Indice costruito: {len(self.doc_ids)} documenti, {len(self.vectorizer.vocabulary_)} termini\")\n",
    "    \n",
    "    def search(self, query: str, section: str = None, top_k: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Esegue ricerca con filtri opzionali.\n",
    "        \n",
    "        Args:\n",
    "            query: testo query\n",
    "            section: filtra per sezione (opzionale)\n",
    "            top_k: numero risultati\n",
    "        \"\"\"\n",
    "        # Trasforma query\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        \n",
    "        # Calcola similaritÃ \n",
    "        similarities = cosine_similarity(query_vec, self.doc_matrix)[0]\n",
    "        \n",
    "        # Ordina\n",
    "        ranked = [(self.doc_ids[i], similarities[i]) for i in range(len(self.doc_ids))]\n",
    "        ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Filtra per sezione se specificato\n",
    "        if section:\n",
    "            ranked = [(doc_id, score) for doc_id, score in ranked\n",
    "                      if self.doc_metadata.get(doc_id, {}).get('section') == section]\n",
    "        \n",
    "        # Costruisci risultati\n",
    "        results = []\n",
    "        for doc_id, score in ranked[:top_k]:\n",
    "            if score > 0:\n",
    "                results.append({\n",
    "                    'doc_id': doc_id,\n",
    "                    'score': score,\n",
    "                    'snippet': self._extract_snippet(doc_id, query),\n",
    "                    'metadata': self.doc_metadata.get(doc_id, {})\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _extract_snippet(self, doc_id: str, query: str, window: int = 100) -> str:\n",
    "        \"\"\"Estrae snippet con contesto attorno ai match.\"\"\"\n",
    "        text = self.documents[doc_id]\n",
    "        query_terms = query.lower().split()\n",
    "        \n",
    "        # Trova prima occorrenza di un termine query\n",
    "        text_lower = text.lower()\n",
    "        best_pos = len(text)  # Default: inizio\n",
    "        \n",
    "        for term in query_terms:\n",
    "            pos = text_lower.find(term)\n",
    "            if pos != -1 and pos < best_pos:\n",
    "                best_pos = pos\n",
    "        \n",
    "        # Estrai finestra\n",
    "        start = max(0, best_pos - window // 2)\n",
    "        end = min(len(text), best_pos + window)\n",
    "        \n",
    "        snippet = text[start:end]\n",
    "        if start > 0:\n",
    "            snippet = '...' + snippet\n",
    "        if end < len(text):\n",
    "            snippet = snippet + '...'\n",
    "        \n",
    "        # Highlight (semplice: uppercase)\n",
    "        for term in query_terms:\n",
    "            snippet = re.sub(\n",
    "                rf'\\b({term})\\b',\n",
    "                r'**\\1**',\n",
    "                snippet,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "        \n",
    "        return snippet\n",
    "\n",
    "# Dataset documentazione tecnica\n",
    "tech_docs = {\n",
    "    'api_auth': {\n",
    "        'content': \"\"\"\n",
    "        API Authentication Guide\n",
    "        \n",
    "        All API requests require authentication using an API key.\n",
    "        Include the API key in the header: Authorization: Bearer YOUR_API_KEY\n",
    "        \n",
    "        To obtain an API key, register at the developer portal.\n",
    "        Keys have rate limits of 1000 requests per hour.\n",
    "        \"\"\",\n",
    "        'metadata': {'section': 'API', 'tags': ['authentication', 'security']}\n",
    "    },\n",
    "    'api_endpoints': {\n",
    "        'content': \"\"\"\n",
    "        API Endpoints Reference\n",
    "        \n",
    "        GET /users - List all users\n",
    "        POST /users - Create new user\n",
    "        GET /users/{id} - Get user by ID\n",
    "        PUT /users/{id} - Update user\n",
    "        DELETE /users/{id} - Delete user\n",
    "        \n",
    "        All endpoints return JSON responses.\n",
    "        \"\"\",\n",
    "        'metadata': {'section': 'API', 'tags': ['endpoints', 'reference']}\n",
    "    },\n",
    "    'tutorial_quickstart': {\n",
    "        'content': \"\"\"\n",
    "        Quickstart Tutorial\n",
    "        \n",
    "        Step 1: Install the SDK using pip install our-sdk\n",
    "        Step 2: Import the library and initialize with your API key\n",
    "        Step 3: Make your first API call\n",
    "        \n",
    "        Example code:\n",
    "        from our_sdk import Client\n",
    "        client = Client(api_key='YOUR_KEY')\n",
    "        users = client.get_users()\n",
    "        \"\"\",\n",
    "        'metadata': {'section': 'Tutorial', 'tags': ['quickstart', 'beginner']}\n",
    "    },\n",
    "    'tutorial_advanced': {\n",
    "        'content': \"\"\"\n",
    "        Advanced Usage Tutorial\n",
    "        \n",
    "        Batch operations allow processing multiple items efficiently.\n",
    "        Use pagination for large result sets.\n",
    "        Implement retry logic for handling rate limits.\n",
    "        \n",
    "        Advanced error handling with custom exceptions.\n",
    "        \"\"\",\n",
    "        'metadata': {'section': 'Tutorial', 'tags': ['advanced', 'batch']}\n",
    "    },\n",
    "    'faq_errors': {\n",
    "        'content': \"\"\"\n",
    "        FAQ: Common Errors\n",
    "        \n",
    "        Q: Why do I get 401 Unauthorized?\n",
    "        A: Your API key is invalid or expired. Check the developer portal.\n",
    "        \n",
    "        Q: What does 429 Too Many Requests mean?\n",
    "        A: You exceeded the rate limit. Wait and retry.\n",
    "        \n",
    "        Q: How to fix 500 Internal Server Error?\n",
    "        A: This is a server issue. Contact support.\n",
    "        \"\"\",\n",
    "        'metadata': {'section': 'FAQ', 'tags': ['errors', 'troubleshooting']}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crea e popola engine\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 1: SEARCH ENGINE DOCUMENTAZIONE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "doc_engine = TechDocsSearchEngine()\n",
    "\n",
    "for doc_id, doc_data in tech_docs.items():\n",
    "    doc_engine.add_document(doc_id, doc_data['content'], doc_data['metadata'])\n",
    "\n",
    "doc_engine.build_index()\n",
    "\n",
    "# Test ricerche\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST RICERCHE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ricerca generale\n",
    "print(\"\\nðŸ” Query: 'api key authentication'\")\n",
    "print(\"-\" * 50)\n",
    "results = doc_engine.search('api key authentication', top_k=3)\n",
    "for r in results:\n",
    "    print(f\"\\n   [{r['doc_id']}] Score: {r['score']:.4f}\")\n",
    "    print(f\"   Section: {r['metadata'].get('section', 'N/A')}\")\n",
    "    print(f\"   Snippet: {r['snippet'][:100]}...\")\n",
    "\n",
    "# Ricerca filtrata per sezione\n",
    "print(\"\\nðŸ” Query: 'error' (solo FAQ)\")\n",
    "print(\"-\" * 50)\n",
    "results_faq = doc_engine.search('error', section='FAQ', top_k=3)\n",
    "for r in results_faq:\n",
    "    print(f\"\\n   [{r['doc_id']}] Score: {r['score']:.4f}\")\n",
    "    print(f\"   Tags: {r['metadata'].get('tags', [])}\")\n",
    "\n",
    "# Ricerca tecnica\n",
    "print(\"\\nðŸ” Query: 'rate limit requests'\")\n",
    "print(\"-\" * 50)\n",
    "results_tech = doc_engine.search('rate limit requests', top_k=2)\n",
    "for r in results_tech:\n",
    "    print(f\"\\n   [{r['doc_id']}] Score: {r['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d586ac9",
   "metadata": {},
   "source": [
    "---\n",
    "## Esercizio 2: Sistema di Raccomandazione Articoli\n",
    "\n",
    "**Obiettivo:** Creare un sistema che raccomanda articoli simili basandosi sul contenuto testuale e traccia le metriche di engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 2 - SOLUZIONE\n",
    "# Sistema di Raccomandazione Articoli Simili\n",
    "# ============================================================\n",
    "\n",
    "class ArticleRecommender:\n",
    "    \"\"\"\n",
    "    Sistema di raccomandazione content-based per articoli.\n",
    "    \n",
    "    Features:\n",
    "    - SimilaritÃ  basata su TF-IDF del contenuto\n",
    "    - Boost per categoria e autore\n",
    "    - Tracciamento click per valutazione\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=3000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        self.articles = {}\n",
    "        self.article_vectors = None\n",
    "        self.article_ids = []\n",
    "        self.click_log = []  # [(article_shown, article_clicked), ...]\n",
    "    \n",
    "    def add_articles(self, articles: Dict[str, Dict]):\n",
    "        \"\"\"\n",
    "        Aggiunge articoli al sistema.\n",
    "        \n",
    "        Args:\n",
    "            articles: {\n",
    "                'art_id': {\n",
    "                    'title': str,\n",
    "                    'content': str,\n",
    "                    'category': str,\n",
    "                    'author': str\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.articles = articles\n",
    "        self.article_ids = list(articles.keys())\n",
    "        \n",
    "        # Combina title + content per vettorizzazione\n",
    "        texts = [\n",
    "            f\"{a['title']} {a['title']} {a['content']}\"  # Title pesato 2x\n",
    "            for a in articles.values()\n",
    "        ]\n",
    "        \n",
    "        self.article_vectors = self.vectorizer.fit_transform(texts)\n",
    "        print(f\"Indicizzati {len(articles)} articoli\")\n",
    "    \n",
    "    def get_similar(self, article_id: str, top_k: int = 5,\n",
    "                    category_boost: float = 0.2,\n",
    "                    author_boost: float = 0.1) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Trova articoli simili a quello dato.\n",
    "        \n",
    "        Args:\n",
    "            article_id: ID articolo di partenza\n",
    "            top_k: numero raccomandazioni\n",
    "            category_boost: bonus per stessa categoria\n",
    "            author_boost: bonus per stesso autore\n",
    "        \"\"\"\n",
    "        if article_id not in self.articles:\n",
    "            return []\n",
    "        \n",
    "        # Ottieni indice\n",
    "        idx = self.article_ids.index(article_id)\n",
    "        source_article = self.articles[article_id]\n",
    "        \n",
    "        # Calcola similaritÃ  con tutti\n",
    "        similarities = cosine_similarity(\n",
    "            self.article_vectors[idx],\n",
    "            self.article_vectors\n",
    "        )[0]\n",
    "        \n",
    "        # Applica boost per categoria/autore\n",
    "        adjusted_scores = []\n",
    "        for i, art_id in enumerate(self.article_ids):\n",
    "            if art_id == article_id:\n",
    "                continue  # Escludi se stesso\n",
    "            \n",
    "            score = similarities[i]\n",
    "            art = self.articles[art_id]\n",
    "            \n",
    "            # Boost categoria\n",
    "            if art.get('category') == source_article.get('category'):\n",
    "                score += category_boost\n",
    "            \n",
    "            # Boost autore\n",
    "            if art.get('author') == source_article.get('author'):\n",
    "                score += author_boost\n",
    "            \n",
    "            adjusted_scores.append((art_id, score, art))\n",
    "        \n",
    "        # Ordina e prendi top_k\n",
    "        adjusted_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommendations = []\n",
    "        for art_id, score, art in adjusted_scores[:top_k]:\n",
    "            recommendations.append({\n",
    "                'article_id': art_id,\n",
    "                'title': art['title'],\n",
    "                'score': score,\n",
    "                'category': art.get('category'),\n",
    "                'reason': self._explain_recommendation(source_article, art, score)\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _explain_recommendation(self, source: Dict, target: Dict, score: float) -> str:\n",
    "        \"\"\"Genera spiegazione della raccomandazione.\"\"\"\n",
    "        reasons = []\n",
    "        \n",
    "        if source.get('category') == target.get('category'):\n",
    "            reasons.append(\"stessa categoria\")\n",
    "        if source.get('author') == target.get('author'):\n",
    "            reasons.append(\"stesso autore\")\n",
    "        \n",
    "        if reasons:\n",
    "            return f\"Contenuto simile + {', '.join(reasons)}\"\n",
    "        return \"Contenuto simile\"\n",
    "    \n",
    "    def log_click(self, shown_article: str, clicked_article: str):\n",
    "        \"\"\"Registra click su raccomandazione.\"\"\"\n",
    "        self.click_log.append((shown_article, clicked_article))\n",
    "    \n",
    "    def calculate_ctr(self, article_id: str = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Calcola Click-Through Rate.\n",
    "        \n",
    "        CTR = clicks / impressions\n",
    "        \"\"\"\n",
    "        if not self.click_log:\n",
    "            return {'ctr': 0.0, 'clicks': 0, 'impressions': 0}\n",
    "        \n",
    "        impressions = len(self.click_log)\n",
    "        clicks = len([1 for _, clicked in self.click_log if clicked])\n",
    "        \n",
    "        if article_id:\n",
    "            impressions = len([1 for shown, _ in self.click_log if shown == article_id])\n",
    "            clicks = len([1 for shown, clicked in self.click_log \n",
    "                          if shown == article_id and clicked])\n",
    "        \n",
    "        return {\n",
    "            'ctr': clicks / impressions if impressions > 0 else 0.0,\n",
    "            'clicks': clicks,\n",
    "            'impressions': impressions\n",
    "        }\n",
    "\n",
    "# Dataset articoli\n",
    "news_articles = {\n",
    "    'tech1': {\n",
    "        'title': 'Introduction to Machine Learning',\n",
    "        'content': 'Machine learning is transforming how we analyze data. Neural networks and deep learning algorithms can recognize patterns in large datasets.',\n",
    "        'category': 'Technology',\n",
    "        'author': 'John Smith'\n",
    "    },\n",
    "    'tech2': {\n",
    "        'title': 'Python for Data Science',\n",
    "        'content': 'Python has become the go-to language for data science. Libraries like pandas and scikit-learn make data analysis accessible.',\n",
    "        'category': 'Technology',\n",
    "        'author': 'Jane Doe'\n",
    "    },\n",
    "    'tech3': {\n",
    "        'title': 'Deep Learning Applications',\n",
    "        'content': 'Deep learning neural networks are used in image recognition, natural language processing, and autonomous vehicles.',\n",
    "        'category': 'Technology',\n",
    "        'author': 'John Smith'\n",
    "    },\n",
    "    'biz1': {\n",
    "        'title': 'Business Analytics Trends',\n",
    "        'content': 'Companies are investing in data analytics to drive decisions. Business intelligence tools help visualize key metrics.',\n",
    "        'category': 'Business',\n",
    "        'author': 'Jane Doe'\n",
    "    },\n",
    "    'biz2': {\n",
    "        'title': 'Digital Transformation Strategy',\n",
    "        'content': 'Digital transformation requires both technology and organizational change. Data-driven culture is essential for success.',\n",
    "        'category': 'Business',\n",
    "        'author': 'Mike Johnson'\n",
    "    },\n",
    "    'sci1': {\n",
    "        'title': 'Data in Scientific Research',\n",
    "        'content': 'Scientific research generates vast amounts of data. Machine learning helps analyze experimental results and discover patterns.',\n",
    "        'category': 'Science',\n",
    "        'author': 'John Smith'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 2: RACCOMANDAZIONE ARTICOLI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recommender = ArticleRecommender()\n",
    "recommender.add_articles(news_articles)\n",
    "\n",
    "# Test raccomandazioni\n",
    "print(\"\\nðŸ“° Articolo corrente: 'Introduction to Machine Learning' (tech1)\")\n",
    "print(\"-\" * 50)\n",
    "recs = recommender.get_similar('tech1', top_k=4)\n",
    "\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    print(f\"\\n   {i}. {rec['title']}\")\n",
    "    print(f\"      Score: {rec['score']:.4f}\")\n",
    "    print(f\"      Categoria: {rec['category']}\")\n",
    "    print(f\"      Motivo: {rec['reason']}\")\n",
    "\n",
    "# Simula click\n",
    "recommender.log_click('tech1', 'tech3')  # Click\n",
    "recommender.log_click('tech1', 'sci1')   # Click\n",
    "recommender.log_click('tech1', None)     # No click\n",
    "recommender.log_click('tech1', 'tech2')  # Click\n",
    "\n",
    "# Metriche\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"METRICHE CTR\")\n",
    "print(\"=\"*60)\n",
    "ctr = recommender.calculate_ctr()\n",
    "print(f\"\\nðŸ“Š CTR globale: {ctr['ctr']:.1%}\")\n",
    "print(f\"   Clicks: {ctr['clicks']}\")\n",
    "print(f\"   Impressions: {ctr['impressions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0580e",
   "metadata": {},
   "source": [
    "---\n",
    "## Esercizio 3: Benchmark di Sistemi IR\n",
    "\n",
    "**Obiettivo:** Creare un framework per confrontare diverse configurazioni di un sistema IR e visualizzare le metriche comparative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESERCIZIO 3 - SOLUZIONE\n",
    "# Benchmark Framework per Sistemi IR\n",
    "# ============================================================\n",
    "\n",
    "class IRBenchmark:\n",
    "    \"\"\"\n",
    "    Framework per benchmarking di configurazioni IR.\n",
    "    \n",
    "    Confronta diverse configurazioni:\n",
    "    - Con/senza stopwords\n",
    "    - Unigrammi vs bigrammi vs trigrammi\n",
    "    - Diverse strategie di weighting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, documents: Dict[str, str], \n",
    "                 test_queries: Dict[str, set]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            documents: {doc_id: text}\n",
    "            test_queries: {query: set di doc_id rilevanti}\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.test_queries = test_queries\n",
    "        self.results = {}\n",
    "    \n",
    "    def run_config(self, config_name: str, vectorizer_params: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Esegue benchmark per una configurazione.\n",
    "        \n",
    "        Args:\n",
    "            config_name: nome identificativo\n",
    "            vectorizer_params: parametri per TfidfVectorizer\n",
    "        \"\"\"\n",
    "        # Crea vectorizer con configurazione\n",
    "        vectorizer = TfidfVectorizer(**vectorizer_params)\n",
    "        \n",
    "        # Indicizza\n",
    "        doc_ids = list(self.documents.keys())\n",
    "        texts = [self.documents[doc_id] for doc_id in doc_ids]\n",
    "        doc_matrix = vectorizer.fit_transform(texts)\n",
    "        \n",
    "        # Valuta su tutte le query\n",
    "        metrics_collector = IRMetrics()\n",
    "        all_results = []\n",
    "        \n",
    "        for query, relevant in self.test_queries.items():\n",
    "            # Trasforma query\n",
    "            query_vec = vectorizer.transform([query])\n",
    "            \n",
    "            # Calcola similaritÃ \n",
    "            sims = cosine_similarity(query_vec, doc_matrix)[0]\n",
    "            \n",
    "            # Ranking\n",
    "            ranked_indices = sims.argsort()[::-1][:10]\n",
    "            retrieved = [doc_ids[i] for i in ranked_indices if sims[i] > 0]\n",
    "            \n",
    "            all_results.append((retrieved, relevant))\n",
    "        \n",
    "        # Calcola metriche aggregate\n",
    "        map_score = metrics_collector.mean_average_precision(all_results)\n",
    "        \n",
    "        avg_p = np.mean([metrics_collector.precision(r, rel) \n",
    "                         for r, rel in all_results])\n",
    "        avg_r = np.mean([metrics_collector.recall(r, rel) \n",
    "                         for r, rel in all_results])\n",
    "        \n",
    "        result = {\n",
    "            'config_name': config_name,\n",
    "            'params': vectorizer_params,\n",
    "            'vocab_size': len(vectorizer.vocabulary_),\n",
    "            'MAP': map_score,\n",
    "            'avg_precision': avg_p,\n",
    "            'avg_recall': avg_r,\n",
    "            'avg_f1': metrics_collector.f1_score(avg_p, avg_r)\n",
    "        }\n",
    "        \n",
    "        self.results[config_name] = result\n",
    "        return result\n",
    "    \n",
    "    def compare_all(self) -> None:\n",
    "        \"\"\"Visualizza confronto tra tutte le configurazioni.\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"Nessun risultato. Eseguire run_config() prima.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CONFRONTO CONFIGURAZIONI IR\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Header\n",
    "        print(f\"\\n{'Configurazione':<25} {'Vocab':>8} {'MAP':>8} {'P':>8} {'R':>8} {'F1':>8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Ordina per MAP decrescente\n",
    "        sorted_configs = sorted(self.results.values(), \n",
    "                                key=lambda x: x['MAP'], reverse=True)\n",
    "        \n",
    "        for r in sorted_configs:\n",
    "            print(f\"{r['config_name']:<25} {r['vocab_size']:>8} \"\n",
    "                  f\"{r['MAP']:>8.4f} {r['avg_precision']:>8.4f} \"\n",
    "                  f\"{r['avg_recall']:>8.4f} {r['avg_f1']:>8.4f}\")\n",
    "        \n",
    "        # Best config\n",
    "        best = sorted_configs[0]\n",
    "        print(f\"\\nðŸ† Migliore configurazione: {best['config_name']}\")\n",
    "        print(f\"   MAP = {best['MAP']:.4f}\")\n",
    "    \n",
    "    def get_winner(self) -> str:\n",
    "        \"\"\"Restituisce nome della configurazione vincente (max MAP).\"\"\"\n",
    "        if not self.results:\n",
    "            return None\n",
    "        return max(self.results.items(), key=lambda x: x[1]['MAP'])[0]\n",
    "\n",
    "# Test benchmark\n",
    "print(\"=\"*60)\n",
    "print(\"ESERCIZIO 3: BENCHMARK SISTEMI IR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ground truth per benchmark\n",
    "benchmark_queries = {\n",
    "    'python data': {'art1', 'art3'},\n",
    "    'machine learning': {'art1', 'art2', 'art7'},\n",
    "    'sql database': {'art3'},\n",
    "    'visualization charts': {'art5'},\n",
    "    'natural language text': {'art6'}\n",
    "}\n",
    "\n",
    "# Crea benchmark\n",
    "benchmark = IRBenchmark(articles, benchmark_queries)\n",
    "\n",
    "# Configurazioni da testare\n",
    "configs = [\n",
    "    ('baseline_unigram', {\n",
    "        'max_features': 1000,\n",
    "        'ngram_range': (1, 1),\n",
    "        'stop_words': None\n",
    "    }),\n",
    "    ('unigram_nostop', {\n",
    "        'max_features': 1000,\n",
    "        'ngram_range': (1, 1),\n",
    "        'stop_words': 'english'\n",
    "    }),\n",
    "    ('bigram_nostop', {\n",
    "        'max_features': 2000,\n",
    "        'ngram_range': (1, 2),\n",
    "        'stop_words': 'english'\n",
    "    }),\n",
    "    ('trigram_nostop', {\n",
    "        'max_features': 3000,\n",
    "        'ngram_range': (1, 3),\n",
    "        'stop_words': 'english'\n",
    "    }),\n",
    "    ('bigram_sublinear', {\n",
    "        'max_features': 2000,\n",
    "        'ngram_range': (1, 2),\n",
    "        'stop_words': 'english',\n",
    "        'sublinear_tf': True\n",
    "    })\n",
    "]\n",
    "\n",
    "# Esegui benchmark\n",
    "print(\"\\nðŸ“Š Esecuzione benchmark...\")\n",
    "for name, params in configs:\n",
    "    result = benchmark.run_config(name, params)\n",
    "    print(f\"   âœ“ {name}: MAP = {result['MAP']:.4f}\")\n",
    "\n",
    "# Visualizza confronto\n",
    "benchmark.compare_all()\n",
    "\n",
    "# Analisi dettagliata\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANALISI IMPATTO CONFIGURAZIONE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Confronto stopwords\n",
    "baseline = benchmark.results['baseline_unigram']['MAP']\n",
    "nostop = benchmark.results['unigram_nostop']['MAP']\n",
    "print(f\"\\nðŸ“Œ Impatto rimozione stopwords:\")\n",
    "print(f\"   Baseline: {baseline:.4f}\")\n",
    "print(f\"   No stopwords: {nostop:.4f}\")\n",
    "print(f\"   Î” MAP: {nostop - baseline:+.4f}\")\n",
    "\n",
    "# Confronto n-grams\n",
    "uni = benchmark.results['unigram_nostop']['MAP']\n",
    "bi = benchmark.results['bigram_nostop']['MAP']\n",
    "tri = benchmark.results['trigram_nostop']['MAP']\n",
    "print(f\"\\nðŸ“Œ Impatto n-grams (con stopwords rimossi):\")\n",
    "print(f\"   Unigram: {uni:.4f}\")\n",
    "print(f\"   Bigram:  {bi:.4f}\")\n",
    "print(f\"   Trigram: {tri:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42e0dc",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 5. Conclusione Operativa\n",
    "\n",
    "## Cosa abbiamo imparato\n",
    "\n",
    "**Information Retrieval** Ã¨ la disciplina fondamentale per costruire sistemi di ricerca:\n",
    "\n",
    "| Componente | Funzione | Implementazione |\n",
    "|------------|----------|-----------------|\n",
    "| Indice Invertito | Ricerca efficiente | defaultdict + posizioni |\n",
    "| TF-IDF | Rappresentazione vettoriale | TfidfVectorizer |\n",
    "| Cosine Similarity | Ranking documenti | cosine_similarity() |\n",
    "| Query Expansion | Migliorare recall | Thesaurus + corpus |\n",
    "| Metriche | Valutazione | Precision, Recall, MAP |\n",
    "\n",
    "## Pattern Architetturali\n",
    "\n",
    "1. **Indicizzazione offline** â†’ **Ricerca online**: separa i costi\n",
    "2. **Vector Space Model**: documenti e query nello stesso spazio\n",
    "3. **Ranked retrieval**: non solo match/no-match, ma score graduati\n",
    "\n",
    "## Metriche Chiave\n",
    "\n",
    "| Metrica | Formula | Uso |\n",
    "|---------|---------|-----|\n",
    "| Precision | TP / (TP + FP) | QualitÃ  risultati |\n",
    "| Recall | TP / (TP + FN) | Copertura |\n",
    "| F1 | 2PR / (P+R) | Bilanciamento |\n",
    "| Precision@K | Prec nei primi K | Top results |\n",
    "| MAP | Media delle AP | Confronto sistemi |\n",
    "\n",
    "## Quando Usare IR Classico\n",
    "\n",
    "âœ… **Ideale per:**\n",
    "- Ricerca testuale keyword-based\n",
    "- Matching esatto importante\n",
    "- InterpretabilitÃ  richiesta\n",
    "- Dataset medio-piccoli (< milioni docs)\n",
    "\n",
    "âš ï¸ **Limitazioni:**\n",
    "- Vocabulary mismatch (sinonimi non catturati)\n",
    "- Nessuna comprensione semantica\n",
    "- Per semantica: considera embeddings (Lesson 37+)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93fc6a",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“‹ BIGNAMI - Information Retrieval\n",
    "\n",
    "## Architettura Base\n",
    "\n",
    "```\n",
    "                INDEXING                          RETRIEVAL\n",
    "                   â”‚                                  â”‚\n",
    "DOCUMENTI â”€â”€â–¶ Preprocess â”€â”€â–¶ TF-IDF â”€â”€â–¶ INDEX    QUERY â”€â”€â–¶ Preprocess â”€â”€â–¶ TF-IDF\n",
    "                                          â”‚                                  â”‚\n",
    "                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                     â”‚\n",
    "                                                     â–¼\n",
    "                                               COSINE SIM â”€â”€â–¶ RANKED DOCS\n",
    "```\n",
    "\n",
    "## Template Indice Invertito\n",
    "\n",
    "```python\n",
    "from collections import defaultdict\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        self.index = defaultdict(lambda: defaultdict(list))\n",
    "        self.documents = {}\n",
    "    \n",
    "    def add_document(self, doc_id, text):\n",
    "        self.documents[doc_id] = text\n",
    "        tokens = text.lower().split()\n",
    "        for pos, token in enumerate(tokens):\n",
    "            self.index[token][doc_id].append(pos)\n",
    "    \n",
    "    def search(self, term):\n",
    "        return dict(self.index[term.lower()])\n",
    "```\n",
    "\n",
    "## Template Search Engine TF-IDF\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        self.doc_matrix = None\n",
    "        self.doc_ids = []\n",
    "    \n",
    "    def index(self, documents):\n",
    "        self.doc_ids = list(documents.keys())\n",
    "        texts = list(documents.values())\n",
    "        self.doc_matrix = self.vectorizer.fit_transform(texts)\n",
    "    \n",
    "    def search(self, query, top_k=5):\n",
    "        query_vec = self.vectorizer.transform([query])\n",
    "        sims = cosine_similarity(query_vec, self.doc_matrix)[0]\n",
    "        ranked = sims.argsort()[::-1][:top_k]\n",
    "        return [(self.doc_ids[i], sims[i]) for i in ranked if sims[i] > 0]\n",
    "```\n",
    "\n",
    "## Formule Metriche\n",
    "\n",
    "| Metrica | Formula |\n",
    "|---------|---------|\n",
    "| Precision | `len(retrieved & relevant) / len(retrieved)` |\n",
    "| Recall | `len(retrieved & relevant) / len(relevant)` |\n",
    "| F1 | `2 * P * R / (P + R)` |\n",
    "| P@K | `precision(retrieved[:k], relevant)` |\n",
    "| AP | `sum(P@k * rel(k)) / len(relevant)` |\n",
    "| MAP | `mean([AP(q) for q in queries])` |\n",
    "\n",
    "## Template Metriche\n",
    "\n",
    "```python\n",
    "def precision(retrieved, relevant):\n",
    "    if not retrieved:\n",
    "        return 0.0\n",
    "    return len(set(retrieved) & relevant) / len(retrieved)\n",
    "\n",
    "def recall(retrieved, relevant):\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len(set(retrieved) & relevant) / len(relevant)\n",
    "\n",
    "def average_precision(retrieved, relevant):\n",
    "    precisions = []\n",
    "    rel_count = 0\n",
    "    for i, doc in enumerate(retrieved):\n",
    "        if doc in relevant:\n",
    "            rel_count += 1\n",
    "            precisions.append(rel_count / (i + 1))\n",
    "    return sum(precisions) / len(relevant) if relevant else 0.0\n",
    "```\n",
    "\n",
    "## Parametri TfidfVectorizer\n",
    "\n",
    "| Parametro | Default | Uso |\n",
    "|-----------|---------|-----|\n",
    "| `max_features` | None | Limita vocabolario |\n",
    "| `stop_words` | None | 'english' rimuove stopwords |\n",
    "| `ngram_range` | (1,1) | (1,2) include bigrammi |\n",
    "| `sublinear_tf` | False | True usa 1+log(tf) |\n",
    "| `max_df` | 1.0 | Ignora termini troppo frequenti |\n",
    "| `min_df` | 1 | Ignora termini troppo rari |\n",
    "\n",
    "## Checklist Progetto IR\n",
    "\n",
    "- [ ] Definire corpus documenti\n",
    "- [ ] Preprocessing testo (lowercase, tokenize, stopwords)\n",
    "- [ ] Scegliere rappresentazione (TF-IDF, BM25)\n",
    "- [ ] Costruire indice\n",
    "- [ ] Implementare ricerca con ranking\n",
    "- [ ] Creare ground truth per valutazione\n",
    "- [ ] Calcolare metriche (P, R, MAP)\n",
    "- [ ] Ottimizzare parametri\n",
    "- [ ] (Opzionale) Query expansion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
