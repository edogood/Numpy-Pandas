{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9fe989e",
   "metadata": {},
   "source": [
    "# Lezione 36 — Knowledge Mining\n",
    "\n",
    "**Obiettivi della lezione**\n",
    "- Chiarire cosa sia una knowledge base e perché serve in analisi dati.\n",
    "- Mostrare come estrarre conoscenza da documenti non strutturati con una pipeline semplice.\n",
    "- Evidenziare limiti pratici (rumore, ambiguità, contesto) e come mitigarli.\n",
    "- Posizionare il tema nel percorso: ponte tra data analytics classico e applicazioni AI basate su testo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc6252",
   "metadata": {},
   "source": [
    "## Teoria concettuale approfondita\n",
    "\n",
    "**Concetto di knowledge base**\n",
    "- Archivio strutturato di informazioni che consente interrogazioni coerenti nel tempo (FAQ, policy, manuali, log arricchiti).\n",
    "- Differenza da un semplice repository di file: informazioni normalizzate, relazioni esplicite, versioning e controlli di qualità.\n",
    "\n",
    "**Estrazione di conoscenza (knowledge mining)**\n",
    "- Processo per trasformare dati non strutturati (testo, pdf) in rappresentazioni utilizzabili da analisti e sistemi downstream.\n",
    "- Passi tipici: raccolta → pulizia → segmentazione → indicizzazione → arricchimento (es. entità, categorie) → retrieval/analisi.\n",
    "\n",
    "**Pipeline documentale semplificata**\n",
    "1. **Ingestione**: acquisire documenti da fonti eterogenee.\n",
    "2. **Normalizzazione**: rimuovere rumore (boilerplate, stopword), gestire encoding.\n",
    "3. **Indicizzazione**: creare strutture per recupero efficiente (inverted index, TF-IDF, embeddings). Qui usiamo TF-IDF per semplicità.\n",
    "4. **Enrichment**: estrarre metadati (entità, date) o tag manuali.\n",
    "5. **Query & Ranking**: calcolare similarità tra query e documenti, ordinare per rilevanza.\n",
    "\n",
    "**Spiegazione matematica essenziale (TF-IDF)**\n",
    "- TF (term frequency): $tf_{t,d} = \\frac{\\text{conteggio}(t,d)}{\\text{numero tot. termini in }d}$.\n",
    "- IDF (inverse document frequency): $idf_t = \\log \\frac{N}{1 + n_t}$ dove $N$ è il numero di documenti e $n_t$ il numero di documenti che contengono il termine.\n",
    "- Punteggio documento-query: prodotto scalare tra vettori TF-IDF di query e documenti; più alto ⇒ maggiore rilevanza.\n",
    "\n",
    "**Assunzioni implicite**\n",
    "- Il significato di un termine è approssimato dalla frequenza (bag-of-words: perde l'ordine).\n",
    "- Documenti indipendenti; contesto sintattico e semantico ridotto.\n",
    "\n",
    "**Errori concettuali comuni**\n",
    "- Confondere estrazione di conoscenza con semplice full-text search.\n",
    "- Pensare che TF-IDF risolva ambiguità semantiche (es. \"Apple\" frutto vs azienda).\n",
    "- Trascurare la qualità dell'ingestione: garbage-in, garbage-out.\n",
    "\n",
    "**Esempi mentali**\n",
    "- Manuale interno: cercare \"procedura rimborso\" restituisce documenti con termini specifici; TF-IDF aumenta il peso di termini distintivi rispetto a parole comuni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c7f77",
   "metadata": {},
   "source": [
    "## Schema mentale / mappa logica\n",
    "\n",
    "- **Quando usare**: FAQ aziendali, assistenza clienti, audit documentale, ricerca rapida su policy interne.\n",
    "- **Quando non usare**: dataset troppo piccolo (pochi documenti), richieste che richiedono ragionamento simbolico complesso o comprensione profonda del contesto.\n",
    "- **Segnali pratici nei dati**: molto testo libero, ripetizioni, termini distintivi; presenza di rumore (footer, boilerplate) da filtrare; necessità di ranking di pertinenza.\n",
    "- **Pattern operativo**: definire fonte → normalizzare → indicizzare → testare con query reali → misurare precisione/recall qualitative → iterare pulizia/stopword/tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b726db5",
   "metadata": {},
   "source": [
    "## Notebook dimostrativo (pipeline minimale TF-IDF)\n",
    "Useremo un piccolo corpus testuale simulato per vedere una pipeline di knowledge mining semplificata: ingestione, pulizia minima, indicizzazione TF-IDF, query e osservazione dei limiti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie minime per il testo e la gestione dei dati\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d20537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un piccolo corpus simulato con documenti eterogenei\n",
    "corpus = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [\"doc1\", \"doc2\", \"doc3\", \"doc4\"],\n",
    "        \"testo\": [\n",
    "            \"Policy rimborsi viaggi: inviare ricevuta e approvazione manager.\",\n",
    "            \"Guida interna sicurezza: password lunghe, MFA obbligatorio, niente condivisione.\",\n",
    "            \"Procedura onboarding: account email, laptop configurato, formazione sicurezza.\",\n",
    "            \"FAQ clienti: tempi spedizione standard 3-5 giorni lavorativi, resi entro 30 giorni.\"\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo il vettorizzatore TF-IDF con stopword italiane per ridurre il rumore\n",
    "vectorizer = TfidfVectorizer(stop_words=\"italian\")\n",
    "\n",
    "# Addestriamo l'indice sul corpus (fit) e trasformiamo i testi in vettori sparsi\n",
    "matrix = vectorizer.fit_transform(corpus[\"testo\"])\n",
    "\n",
    "# Salviamo anche la lista dei termini per consultazione\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names[:10]  # mostriamo i primi 10 termini ordinati alfabeticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo una funzione di ricerca che:\n",
    "# 1) Trasforma la query in TF-IDF\n",
    "# 2) Calcola la similarità coseno con i documenti\n",
    "# 3) Restituisce una tabella ordinata per punteggio\n",
    "\n",
    "def cerca(query: str, top_k: int = 3):\n",
    "    query_vec = vectorizer.transform([query])  # trasformiamo la query\n",
    "    scores = cosine_similarity(query_vec, matrix).flatten()  # similarità coseno\n",
    "    risultati = pd.DataFrame({\"id\": corpus[\"id\"], \"punteggio\": scores})\n",
    "    return risultati.sort_values(by=\"punteggio\", ascending=False).head(top_k)\n",
    "\n",
    "cerca(\"procedura rimborso viaggio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostriamo due query per osservare limiti pratici\n",
    "queries = [\n",
    "    \"sicurezza password\",  # dovrebbe trovare doc2 e doc3\n",
    "    \"spedizione veloce\"    # termine \"veloce\" non presente → punteggi bassi\n",
    "]\n",
    "\n",
    "risultati_demo = {q: cerca(q, top_k=4) for q in queries}\n",
    "risultati_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8f276",
   "metadata": {},
   "source": [
    "### Osservazioni sul risultato\n",
    "- La query su \"sicurezza password\" restituisce doc2 e doc3 con punteggi più alti: i termini distintivi coincidono.\n",
    "- La query \"spedizione veloce\" produce punteggi bassi: il termine \"veloce\" non compare. Questo mostra sensibilità al vocabolario.\n",
    "- Rumore/ambiguità: se inserissimo documenti con la parola \"security\" in inglese, la query in italiano potrebbe non trovarli senza stemming/translation.\n",
    "- Mitigazioni: dizionari controllati, sinonimi, normalizzazione linguistica, tag manuali, feedback degli utenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709cff7",
   "metadata": {},
   "source": [
    "## Esercizi svolti (step-by-step)\n",
    "Gli esercizi mirano a consolidare: creazione dell'indice, valutazione qualitativa delle query, mitigazione del rumore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 1: aggiungiamo un documento sul tema rimborsi e rivalutiamo una query\n",
    "nuovo_doc = pd.DataFrame(\n",
    "    {\"id\": [\"doc5\"], \"testo\": [\"Istruzioni rimborso spese: compilare modulo, allegare fatture, inviare a finance.\"]}\n",
    ")\n",
    "corpus_esteso = pd.concat([corpus, nuovo_doc], ignore_index=True)\n",
    "\n",
    "# Ricostruiamo l'indice TF-IDF sul corpus esteso\n",
    "vectorizer_esteso = TfidfVectorizer(stop_words=\"italian\")\n",
    "matrix_estesa = vectorizer_esteso.fit_transform(corpus_esteso[\"testo\"])\n",
    "\n",
    "# Definiamo una funzione di ricerca sul corpus esteso\n",
    "\n",
    "def cerca_esteso(query: str, top_k: int = 5):\n",
    "    query_vec = vectorizer_esteso.transform([query])\n",
    "    scores = cosine_similarity(query_vec, matrix_estesa).flatten()\n",
    "    return pd.DataFrame({\"id\": corpus_esteso[\"id\"], \"punteggio\": scores}).sort_values(\n",
    "        by=\"punteggio\", ascending=False\n",
    "    ).head(top_k)\n",
    "\n",
    "cerca_esteso(\"rimborso spese viaggio\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf361474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 2: confrontiamo l'effetto di aggiungere stopword personalizzate\n",
    "stopword_extra = [\"obbligatorio\", \"standard\", \"giorni\"]  # termini poco informativi nel nostro dominio\n",
    "vectorizer_stop = TfidfVectorizer(stop_words=stopword_extra + [\"italian\"])\n",
    "matrix_stop = vectorizer_stop.fit_transform(corpus[\"testo\"])\n",
    "\n",
    "# Ricerca con stopword personalizzate\n",
    "query = \"spedizione standard resi\"\n",
    "query_vec = vectorizer_stop.transform([query])\n",
    "scores = cosine_similarity(query_vec, matrix_stop).flatten()\n",
    "risultati_stop = pd.DataFrame({\"id\": corpus[\"id\"], \"punteggio\": scores}).sort_values(\n",
    "    by=\"punteggio\", ascending=False\n",
    ")\n",
    "risultati_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 3: gestiamo una ambiguità semplice con sinonimi manuali\n",
    "# Implementiamo una funzione di espansione della query con sinonimi noti del dominio\n",
    "sinonimi = {\n",
    "    \"spedizione\": [\"consegna\", \"delivery\"],\n",
    "    \"rimborso\": [\"reso\", \"refund\"],\n",
    "}\n",
    "\n",
    "\n",
    "def espandi_query(query: str) -> str:\n",
    "    parole = query.split()\n",
    "    espansa = parole.copy()\n",
    "    for p in parole:\n",
    "        if p in sinonimi:\n",
    "            espansa.extend(sinonimi[p])\n",
    "    return \" \".join(espansa)\n",
    "\n",
    "query_base = \"spedizione veloce\"\n",
    "query_espansa = espandi_query(query_base)\n",
    "\n",
    "risultati_espansi = cerca(query_espansa, top_k=4)\n",
    "query_base, query_espansa, risultati_espansi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f51383",
   "metadata": {},
   "source": [
    "## Conclusione operativa\n",
    "- Portarsi a casa: knowledge mining richiede pipeline disciplinata; TF-IDF è un punto di partenza per ranking basico.\n",
    "- Errori da evitare: ignorare la pulizia, sovrastimare TF-IDF per concetti ambigui, non validare con query reali.\n",
    "- Ponte verso la prossima lezione: introduzione concettuale al deep learning, confrontando approcci classici (bag-of-words) con modelli neurali per il testo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
