{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb7c3c",
   "metadata": {},
   "source": [
    "# Lezione 22 - Clustering Gerarchico\n",
    "\n",
    "## Sezione 1 - Titolo e obiettivi\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa della lezione\n",
    "\n",
    "| Sezione | Contenuto | Tempo stimato |\n",
    "|---------|-----------|---------------|\n",
    "| 1 | Titolo, obiettivi, confronto con K-Means | 5 min |\n",
    "| 2 | Teoria profonda: agglomerativo, linkage, dendrogrammi | 20 min |\n",
    "| 3 | Schema mentale: workflow gerarchico | 5 min |\n",
    "| 4 | Demo: costruzione e lettura dendrogramma | 20 min |\n",
    "| 5 | Esercizi risolti + errori comuni | 20 min |\n",
    "| 6 | Conclusione operativa | 10 min |\n",
    "| 7 | Checklist di fine lezione + glossario | 5 min |\n",
    "| 8 | Changelog didattico | 2 min |\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "| # | Obiettivo | Verifica |\n",
    "|---|-----------|----------|\n",
    "| 1 | Costruire e interpretare un **dendrogramma** | Sai leggere le \"gambe lunghe\"? |\n",
    "| 2 | Differenziare i metodi di **linkage** | Sai quando Ward vs Single? |\n",
    "| 3 | **Tagliare** il dendrogramma per ottenere K cluster | Sai usare fcluster? |\n",
    "| 4 | Valutare i cluster con **silhouette** | Conosci la procedura? |\n",
    "| 5 | Confrontare gerarchico vs K-Means | Sai quando usare l'uno o l'altro? |\n",
    "\n",
    "---\n",
    "\n",
    "## Il vantaggio chiave: K non serve a priori\n",
    "\n",
    "```\n",
    "K-MEANS:                         GERARCHICO:\n",
    "   │                                │\n",
    "   ▼                                ▼\n",
    "\"Dammi K cluster\"               \"Ti mostro TUTTI i livelli\"\n",
    "   │                                │\n",
    "   ▼                                ▼\n",
    "Devi decidere K prima           Decidi K dopo, guardando il dendrogramma\n",
    "```\n",
    "\n",
    "**Quando usare gerarchico:**\n",
    "- Non sai quanti cluster ci sono\n",
    "- Vuoi vedere la struttura multi-livello\n",
    "- Dataset piccolo/medio (< 10k punti)\n",
    "- Esiste una gerarchia naturale nei dati\n",
    "\n",
    "---\n",
    "\n",
    "## I 4 metodi di linkage (sintesi visiva)\n",
    "\n",
    "```\n",
    "SINGLE (min):     COMPLETE (max):    AVERAGE:         WARD:\n",
    "   A    B            A    B          A    B           A    B\n",
    "   ●    ●            ●    ●          ●    ●           ●    ●\n",
    "   │    │            │    │          │    │         var(A∪B)\n",
    "   ●────●            ●    ●          ●────●            ↓\n",
    "   min dist          │    │          all pairs      minimize\n",
    "                     ●────●                         Δ variance\n",
    "                     max dist\n",
    "```\n",
    "\n",
    "| Linkage | Default? | Pro | Contro |\n",
    "|---------|----------|-----|--------|\n",
    "| **Ward** | ✅ Consigliato | Cluster bilanciati, simile a K-Means | Assume sfericità |\n",
    "| Complete | No | Cluster compatti | Sensibile a outlier |\n",
    "| Average | No | Compromesso | Meno intuitivo |\n",
    "| Single | ⚠️ Da evitare | Trova forme allungate | Effetto catena |\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti minimi\n",
    "\n",
    "| Concetto | Dove lo trovi | Verifica |\n",
    "|----------|---------------|----------|\n",
    "| K-Means | Lezione 20 | Conosci inertia e centroidi? |\n",
    "| Scelta K | Lezione 21 | Sai usare Elbow e Silhouette? |\n",
    "| StandardScaler | Lezione 13, 20 | Sai perché scalare? |\n",
    "\n",
    "**Micro-checkpoint prerequisiti:**\n",
    "```python\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "print(\"OK!\" if callable(linkage) else \"Installa scipy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924e58c",
   "metadata": {},
   "source": [
    "## Sezione 2 - Teoria profonda\n",
    "\n",
    "### 1.1 Clustering gerarchico: agglomerativo vs divisivo\n",
    "- Agglomerativo (bottom-up): ogni punto e un cluster, poi unisci i due cluster piu simili fino a ottenerne uno solo. E l'approccio usato da sklearn.\n",
    "- Divisivo (top-down): parti da un unico cluster con tutti i punti e lo dividi iterativamente. Meno comune, non implementato in sklearn.\n",
    "\n",
    "### 1.2 Dendrogramma: la mappa delle fusioni\n",
    "- Asse Y: distanza/dissimilarita alla quale avviene l'unione.\n",
    "- Linee orizzontali: fusioni; piu sono alte, piu i cluster erano lontani.\n",
    "- Taglio orizzontale: determina il numero di cluster. Taglio alto = pochi cluster generali; taglio basso = molti cluster specifici.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea4408",
   "metadata": {},
   "source": [
    "### 1.3 Metodi di linkage (distanza tra cluster)\n",
    "\n",
    "| Linkage | Distanza tra cluster | Pro | Contro |\n",
    "|---------|---------------------|-----|--------|\n",
    "| Single | Distanza minima tra coppie | Rileva forme allungate | Effetto catena (unisce cluster lontani tramite punti ponte) |\n",
    "| Complete | Distanza massima tra coppie | Cluster compatti | Sensibile a outlier |\n",
    "| Average | Media di tutte le coppie | Compromesso | Piu costoso da intuire |\n",
    "| Ward | Aumento di varianza totale | Cluster bilanciati, simile a K-Means | Assume forma quasi sferica |\n",
    "\n",
    "Formule sintetiche (A, B cluster):\n",
    "- Single: $d=\\min_{a\\in A, b\\in B} d(a,b)$\n",
    "- Complete: $d=\\max_{a\\in A, b\\in B} d(a,b)$\n",
    "- Average: media di tutte le distanze tra i punti dei due cluster\n",
    "- Ward: minimizza l'incremento di varianza intra-cluster ($\\propto \\|\bar a-\bar b\\|$)\n",
    "\n",
    "Regola pratica: prova prima Ward; passa a complete/average se i cluster non sono sferici; evita single se sospetti l'effetto catena.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa59dd6",
   "metadata": {},
   "source": [
    "### 1.4 Confronto gerarchico vs K-Means\n",
    "\n",
    "| Aspetto | K-Means | Gerarchico |\n",
    "|---------|---------|------------|\n",
    "| K richiesto a priori | Si | No (lo scegli a posteriori) |\n",
    "| Complessita | O(n*K*iter) | O(n^2) o O(n^3) (meno scalabile) |\n",
    "| Forma cluster | Sferica | Dipende dal linkage |\n",
    "| Determinismo | No (init random) | Si (dato il linkage) |\n",
    "| Output | Etichette e centroidi | Albero (dendrogramma) e etichette |\n",
    "\n",
    "Quando usare gerarchico: dataset piccoli/medi (<10k), vuoi piu livelli di granularita, o esiste una gerarchia naturale. Quando usare K-Means: dataset grandi, hai un K ipotizzato, vuoi velocita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4dd0a1",
   "metadata": {},
   "source": [
    "### 1.5 Come leggere e tagliare un dendrogramma\n",
    "\n",
    "1) Osserva le altezze delle fusioni: gambe lunghe suggeriscono separazioni naturali.\n",
    "2) Decidi un'altezza di taglio: tagliando la linea orizzontale conti quante fusioni attraversi = numero di cluster.\n",
    "3) Valida con silhouette score e con il contesto (cluster interpretabili?).\n",
    "\n",
    "Taglio troppo alto -> pochi cluster (potresti perdere dettaglio). Taglio troppo basso -> molti cluster (rischio over-segmentazione).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ee6aa",
   "metadata": {},
   "source": [
    "### 1.6 Gerarchia e silhouette\n",
    "\n",
    "Silhouette resta utile anche nel gerarchico:\n",
    "- Silhouette globale: qualita media della separazione tra cluster.\n",
    "- Silhouette plot per cluster: individua cluster sottili o con valori negativi.\n",
    "\n",
    "Usa silhouette per confrontare altezze di taglio (o valori di K) e scegliere il compromesso migliore tra separazione e interpretabilita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7df6f5",
   "metadata": {},
   "source": [
    "## Sezione 3 - Schema mentale e decision map\n",
    "\n",
    "Workflow sintetico dopo lo scaling:\n",
    "\n",
    "```\n",
    "DATI SCALATI\n",
    "   |\n",
    "   +-- Calcola linkage (scipy.linkage) con metodo scelto\n",
    "   +-- Visualizza dendrogramma\n",
    "   +-- Scegli altezza di taglio (gambe lunghe, salti nelle fusioni)\n",
    "   +-- Estrai cluster (fcluster) o usa AgglomerativeClustering con K\n",
    "   +-- Valuta con silhouette e con il contesto\n",
    "   +-- Interpreta i cluster\n",
    "```\n",
    "\n",
    "Checklist rapida\n",
    "- [ ] Scaling applicato (StandardScaler).\n",
    "- [ ] Metodo di linkage scelto e motivato.\n",
    "- [ ] Dendrogramma letto (gambe lunghe e salti nelle fusioni).\n",
    "- [ ] Altezza di taglio decisa e numero di cluster verificato.\n",
    "- [ ] Silhouette calcolata e controllata per cluster deboli.\n",
    "- [ ] Cluster interpretati e rinominati in modo leggibile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9c89f",
   "metadata": {},
   "source": [
    "## Sezione 4 - Notebook dimostrativo\n",
    "\n",
    "### Perche questo passo (Demo 1 - Primo dendrogramma)\n",
    "Costruiamo il primo dendrogramma per capire cosa rappresentano distanze e taglio. Ci aspettiamo 3 cluster evidenti e gambe lunghe coerenti con i cluster generati.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904008db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: Primo dendrogramma su dati sintetici (attesi 3 cluster)\n",
    "# Perche: vedere come il dendrogramma riflette le fusioni e dove tagliare.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "np.random.seed(42)\n",
    "X, y_true = make_blobs(n_samples=30, centers=3, cluster_std=0.8, random_state=42)\n",
    "assert X.ndim == 2, \"Atteso array 2D\"\n",
    "assert not np.isnan(X).any(), \"Dati con NaN\"\n",
    "\n",
    "# Scaling: rende le feature confrontabili\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "assert X_scaled.shape == X.shape, \"Shape inattesa dopo scaling\"\n",
    "\n",
    "# Calcolo linkage (Ward)\n",
    "Z = linkage(X_scaled, method='ward')\n",
    "assert Z.shape[0] == X_scaled.shape[0] - 1, \"Linkage deve avere n-1 fusioni\"\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} punti, {X.shape[1]} feature\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_true, cmap='viridis', s=80, edgecolors='black')\n",
    "axes[0].set_title('Dati scalati con cluster noti=3')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dendrogramma con linea di taglio suggerita\n",
    "line = dendrogram(Z, ax=axes[1], leaf_rotation=90, leaf_font_size=8)\n",
    "axes[1].axhline(y=5, color='red', linestyle='--', linewidth=2, label='Taglio suggerito')\n",
    "axes[1].set_xlabel('Indice punto (riordinato)')\n",
    "axes[1].set_ylabel('Distanza (Ward)')\n",
    "axes[1].set_title('Dendrogramma (Ward)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check atteso: gambe lunghe prima del taglio a 5 e circa 3 cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829ced5",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 2 - Confronto linkage)\n",
    "Confrontiamo single, complete, average, Ward sullo stesso dataset. Obiettivo: vedere differenze visive nei dendrogrammi e nei silhouette, e capire quando un metodo e preferibile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 2: Confronto dei metodi di linkage sullo stesso dataset\n",
    "# Perche: mostrare differenze visive e di silhouette tra single/complete/average/Ward.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "assert 'X_scaled' in globals(), \"Esegui prima Demo 1 per creare X_scaled\"\n",
    "\n",
    "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    Z = linkage(X_scaled, method=method)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust')\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    dendrogram(Z, ax=axes[0, idx], leaf_rotation=90, leaf_font_size=6, truncate_mode='lastp', p=12)\n",
    "    axes[0, idx].set_title(f'{method.upper()} linkage')\n",
    "    axes[0, idx].set_xlabel('Cluster')\n",
    "    axes[0, idx].set_ylabel('Distanza')\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=70, edgecolors='black', alpha=0.8)\n",
    "    axes[1, idx].set_title(f'Silhouette={sil:.3f}')\n",
    "    axes[1, idx].set_xlabel('Feature 1')\n",
    "    axes[1, idx].set_ylabel('Feature 2')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for method in linkage_methods:\n",
    "    Z = linkage(X_scaled, method=method)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust')\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    note = {\n",
    "        'single': 'Rischio catena',\n",
    "        'complete': 'Cluster compatti',\n",
    "        'average': 'Compromesso',\n",
    "        'ward': 'Simile a K-Means'\n",
    "    }[method]\n",
    "    print(f\"{method:<10} silhouette={sil:.3f} note={note}\")\n",
    "\n",
    "# Check: atteso Ward con silhouette piu alta su cluster sferici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609eab6",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 3 - Effetto catena)\n",
    "Mostriamo il limite del single linkage quando esiste un ponte di punti tra cluster. Obiettivo: riconoscere il sintomo (silhouette basso, cluster allungati) e preferire Ward/complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739baf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 3: Effetto catena del single linkage\n",
    "# Perché: mostrare come punti ponte possano far collassare due cluster separati con single linkage.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "cluster1 = np.random.randn(30, 2) + np.array([-3, 0])\n",
    "cluster2 = np.random.randn(30, 2) + np.array([3, 0])\n",
    "ponte = np.array([[-2, 0], [-1, 0], [0, 0], [1, 0], [2, 0]])\n",
    "\n",
    "X_chain = np.vstack([cluster1, cluster2, ponte])\n",
    "X_chain_scaled = StandardScaler().fit_transform(X_chain)\n",
    "\n",
    "# Sanity check\n",
    "assert not np.isnan(X_chain_scaled).any(), \"NaN nei dati\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "\n",
    "for idx, method in enumerate([\"single\", \"ward\"]):\n",
    "    Z = linkage(X_chain_scaled, method=method)\n",
    "\n",
    "    labels = fcluster(Z, t=2, criterion=\"maxclust\")\n",
    "    sil = silhouette_score(X_chain_scaled, labels)\n",
    "\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        ax=axes[0, idx],\n",
    "        truncate_mode=\"lastp\",\n",
    "        p=20,\n",
    "        leaf_rotation=90,\n",
    "        leaf_font_size=7\n",
    "    )\n",
    "    axes[0, idx].set_title(f\"Dendrogramma {method}\")\n",
    "    axes[0, idx].set_ylabel(\"Distanza\")\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1, idx].scatter(\n",
    "        X_chain_scaled[:, 0],\n",
    "        X_chain_scaled[:, 1],\n",
    "        c=labels,\n",
    "        cmap=\"viridis\",\n",
    "        s=60,\n",
    "        edgecolors=\"black\",\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "    axes[1, idx].scatter(\n",
    "        X_chain_scaled[-5:, 0],\n",
    "        X_chain_scaled[-5:, 1],\n",
    "        c=\"orange\",\n",
    "        s=140,\n",
    "        marker=\"s\",\n",
    "        edgecolors=\"black\",\n",
    "        label=\"Punti ponte\"\n",
    "    )\n",
    "\n",
    "    axes[1, idx].set_title(f\"{method.upper()} | silhouette = {sil:.3f}\")\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].legend()\n",
    "\n",
    "axes[0, 2].axis(\"off\")\n",
    "axes[1, 2].axis(\"off\")\n",
    "\n",
    "axes[1, 2].text(\n",
    "    0.5,\n",
    "    0.5,\n",
    "    (\n",
    "        \"Single linkage usa la distanza minima.\\n\\n\"\n",
    "        \"Una catena di pochi punti ponte\\n\"\n",
    "        \"può unire cluster lontani.\\n\\n\"\n",
    "        \"Ward minimizza la varianza interna,\\n\"\n",
    "        \"quindi resiste all'effetto catena.\"\n",
    "    ),\n",
    "    transform=axes[1, 2].transAxes,\n",
    "    fontsize=11,\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"lightyellow\", alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Conclusione: se esistono punti ponte, \"\n",
    "    \"il single linkage produce cluster allungati; \"\n",
    "    \"Ward (o complete) è spesso preferibile.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c8866",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 4 - Taglio del dendrogramma)\n",
    "Mostriamo strategie pratiche per scegliere l'altezza di taglio: gambe lunghe, salti nelle distanze, confronto silhouette.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3178503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 4: Taglio del dendrogramma e scelta di K\n",
    "# Perche: mostrare metodi pratici (gambe lunghe e salti) per decidere K.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "X_multi, _ = make_blobs(n_samples=100, centers=4, cluster_std=[0.8, 1.0, 0.6, 1.2], center_box=(-10, 10), random_state=42)\n",
    "X_multi_scaled = StandardScaler().fit_transform(X_multi)\n",
    "assert not np.isnan(X_multi_scaled).any()\n",
    "\n",
    "Z = linkage(X_multi_scaled, method='ward')\n",
    "\n",
    "fusion_dist = Z[:, 2]\n",
    "jumps = np.diff(fusion_dist)\n",
    "max_jump_idx = int(np.argmax(jumps))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "dendrogram(Z, ax=axes[0], truncate_mode='lastp', p=25, leaf_rotation=90, leaf_font_size=7)\n",
    "axes[0].axhline(y=5, color='red', linestyle='--', label='Taglio esempio')\n",
    "axes[0].set_title('Dendrogramma (Ward)')\n",
    "axes[0].set_xlabel('Cluster')\n",
    "axes[0].set_ylabel('Distanza')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(range(len(jumps)), jumps, color='steelblue', alpha=0.7)\n",
    "axes[1].bar(max_jump_idx, jumps[max_jump_idx], color='red', alpha=0.8, label='Salto massimo')\n",
    "axes[1].set_title('Salti tra fusioni (aiuta a scegliere K)')\n",
    "axes[1].set_xlabel('Indice fusione')\n",
    "axes[1].set_ylabel('Delta distanza')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "labels = fcluster(Z, t=4, criterion='maxclust')\n",
    "sil = silhouette_score(X_multi_scaled, labels)\n",
    "print(f\"Taglio a 4 cluster -> silhouette={sil:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdcd84",
   "metadata": {},
   "source": [
    "### Perche questo passo (Demo 5 - Caso ambiguo)\n",
    "Dataset con cluster sovrapposti: nessun metodo fornisce un K univoco. Obiettivo: usare silhouette plot e principio di parsimonia (scegliere il K piu semplice e interpretabile).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89152c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 5: Caso ambiguo con cluster sovrapposti\n",
    "# Perche: vedere cosa fare quando silhouette non mostra un picco chiaro.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "X_hard, _ = make_blobs(n_samples=300, centers=5, cluster_std=1.8, random_state=42)\n",
    "X_hard_scaled = StandardScaler().fit_transform(X_hard)\n",
    "assert not np.isnan(X_hard_scaled).any()\n",
    "\n",
    "K_range_sil = range(2, 11)\n",
    "sil_scores_hard = []\n",
    "for k in K_range_sil:\n",
    "    km = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_scores_hard.append(silhouette_score(X_hard_scaled, labels))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "axes[0, 0].plot(K_range_sil, sil_scores_hard, 'go-')\n",
    "axes[0, 0].set_title('Silhouette (caso ambiguo)')\n",
    "axes[0, 0].set_xlabel('K')\n",
    "axes[0, 0].set_ylabel('Silhouette')\n",
    "axes[0, 0].axhline(y=0.25, color='orange', linestyle=':', alpha=0.6)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "Z_hard = linkage(X_hard_scaled, method='ward')\n",
    "dendrogram(Z_hard, ax=axes[0,1], truncate_mode='lastp', p=25, leaf_rotation=90, leaf_font_size=7)\n",
    "axes[0,1].set_title('Dendrogramma (caso ambiguo)')\n",
    "axes[0,1].set_xlabel('Cluster')\n",
    "axes[0,1].set_ylabel('Distanza')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "for idx, k in enumerate([3,4,5]):\n",
    "    km = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = km.fit_predict(X_hard_scaled)\n",
    "    sil_vals = silhouette_samples(X_hard_scaled, labels)\n",
    "    y_lower = 10\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,k))\n",
    "    ax = axes[1, idx]\n",
    "    for i in range(k):\n",
    "        vals = sil_vals[labels == i]\n",
    "        vals.sort()\n",
    "        size = len(vals)\n",
    "        y_upper = y_lower + size\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, vals, facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
    "        ax.text(-0.05, y_lower + size/2, f'C{i}')\n",
    "        y_lower = y_upper + 10\n",
    "    ax.axvline(x=np.mean(sil_vals), color='red', linestyle='--')\n",
    "    ax.set_title(f'Silhouette plot K={k}')\n",
    "    ax.set_xlim([-0.1,1])\n",
    "    ax.set_xlabel('Silhouette score')\n",
    "    ax.set_ylabel('Cluster')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Se i metodi non concordano, preferisci il K piu parsimonioso e interpretabile (es. 3).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2384a",
   "metadata": {},
   "source": [
    "## Sezione 5 - Esercizi guidati (step by step)\n",
    "\n",
    "### Perche questo esercizio (22.1)\n",
    "Eseguire un'analisi completa con dendrogramma, scelta di K, silhouette e interpretazione su dati medici. Obiettivo: applicare il flusso end-to-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.1 - Analisi completa con dendrogramma\n",
    "# Obiettivo: seguire l'intero flusso (dendrogramma -> scelta K -> silhouette -> profili).\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "eta = [25, 30, 28, 65, 70, 68, 45, 48, 50, 22, 75, 42]\n",
    "pressione = [120, 125, 118, 145, 155, 150, 130, 135, 132, 115, 160, 128]\n",
    "colesterolo = [180, 190, 175, 240, 260, 250, 210, 215, 205, 170, 270, 200]\n",
    "\n",
    "df_pazienti = pd.DataFrame({\n",
    "    'paziente': [f'P{i}' for i in range(1, 13)],\n",
    "    'eta': eta,\n",
    "    'pressione': pressione,\n",
    "    'colesterolo': colesterolo\n",
    "})\n",
    "print(\"Dataset pazienti (head):\")\n",
    "print(df_pazienti.head())\n",
    "\n",
    "X_pazienti = df_pazienti[['eta', 'pressione', 'colesterolo']].values\n",
    "scaler = StandardScaler()\n",
    "X_pazienti_scaled = scaler.fit_transform(X_pazienti)\n",
    "assert X_pazienti_scaled.shape == X_pazienti.shape\n",
    "assert not np.isnan(X_pazienti_scaled).any()\n",
    "\n",
    "Z = linkage(X_pazienti_scaled, method='ward')\n",
    "\n",
    "fusion_dist = Z[:,2]\n",
    "jumps = np.diff(fusion_dist)\n",
    "max_jump_idx = int(np.argmax(jumps))\n",
    "K_suggerito = X_pazienti_scaled.shape[0] - max_jump_idx - 1\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
    "dendrogram(Z, ax=axes[0], labels=df_pazienti['paziente'].values, leaf_rotation=45)\n",
    "axes[0].axhline(y=fusion_dist[max_jump_idx], color='red', linestyle='--', label=f'K stimato ~{K_suggerito}')\n",
    "axes[0].set_title('Dendrogramma pazienti (Ward)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[1].bar(range(len(jumps)), jumps, color='steelblue')\n",
    "axes[1].bar(max_jump_idx, jumps[max_jump_idx], color='red', label='Salto massimo')\n",
    "axes[1].set_title('Salti nelle distanze')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "K_ottimale = 3\n",
    "labels = fcluster(Z, t=K_ottimale, criterion='maxclust') - 1\n",
    "sil = silhouette_score(X_pazienti_scaled, labels)\n",
    "print(f\"K scelto: {K_ottimale}, silhouette={sil:.3f}\")\n",
    "\n",
    "df_pazienti['cluster'] = labels\n",
    "print(\"Profili medi per cluster:\")\n",
    "print(df_pazienti.groupby('cluster')[['eta','pressione','colesterolo']].mean().round(1))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "scatter = ax.scatter(df_pazienti['eta'], df_pazienti['colesterolo'], c=df_pazienti['cluster'], cmap='viridis', s=100, edgecolors='black')\n",
    "for _, row in df_pazienti.iterrows():\n",
    "    ax.annotate(row['paziente'], (row['eta']+1, row['colesterolo']+3), fontsize=8)\n",
    "ax.set_xlabel('Eta')\n",
    "ax.set_ylabel('Colesterolo')\n",
    "ax.set_title(f'Clustering pazienti (K={K_ottimale}, silhouette={sil:.3f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05237c0a",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (22.2)\n",
    "Confrontare i metodi di linkage su cluster di forme diverse. Obiettivo: scegliere il metodo migliore motivando con silhouette e struttura.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.2 - Confronto metodi di linkage su forme diverse\n",
    "# Obiettivo: vedere quale linkage gestisce meglio cluster ellittici/compatti/sparsi.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "\n",
    "np.random.seed(42)\n",
    "n1, n2, n3 = 20, 20, 20\n",
    "cluster1 = np.column_stack([\n",
    "    np.random.normal(0, 0.5, n1),\n",
    "    np.random.normal(0, 2.5, n1)\n",
    "])\n",
    "cluster2 = np.random.normal(loc=[5, 0], scale=0.5, size=(n2, 2))\n",
    "cluster3 = np.random.normal(loc=[2.5, 5], scale=1.5, size=(n3, 2))\n",
    "X_forme = np.vstack([cluster1, cluster2, cluster3])\n",
    "y_true = np.array([0]*n1 + [1]*n2 + [2]*n3)\n",
    "assert X_forme.shape[0] == 60\n",
    "\n",
    "X_forme_scaled = StandardScaler().fit_transform(X_forme)\n",
    "\n",
    "metodi = ['single', 'complete', 'average', 'ward']\n",
    "fig, axes = plt.subplots(2, 4, figsize=(17, 8))\n",
    "risultati = {}\n",
    "\n",
    "for idx, metodo in enumerate(metodi):\n",
    "    Z = linkage(X_forme_scaled, method=metodo)\n",
    "    labels = fcluster(Z, t=3, criterion='maxclust') - 1\n",
    "    sil = silhouette_score(X_forme_scaled, labels)\n",
    "    ari = adjusted_rand_score(y_true, labels)\n",
    "    risultati[metodo] = {'sil': sil, 'ari': ari}\n",
    "    dendrogram(Z, ax=axes[0, idx], truncate_mode='lastp', p=10, leaf_rotation=45, no_labels=True)\n",
    "    axes[0, idx].set_title(metodo.upper())\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].scatter(X_forme[:, 0], X_forme[:, 1], c=labels, cmap='viridis', s=50, edgecolors='black', alpha=0.8)\n",
    "    axes[1, idx].set_title(f'Sil={sil:.3f}, ARI={ari:.3f}')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"{'Metodo':<10} {'Silhouette':>12} {'ARI':>10}\")\n",
    "for m in metodi:\n",
    "    mark = '*' if m == max(risultati, key=lambda x: risultati[x]['sil']) else ' '\n",
    "    print(f\"{mark}{m:<9} {risultati[m]['sil']:>12.3f} {risultati[m]['ari']:>10.3f}\")\n",
    "\n",
    "best = max(risultati, key=lambda x: risultati[x]['sil'])\n",
    "worse = min(risultati, key=lambda x: risultati[x]['sil'])\n",
    "print(f\"Metodo migliore: {best.upper()} (silhouette {risultati[best]['sil']:.3f})\")\n",
    "print(f\"Metodo peggiore: {worse.upper()} (silhouette {risultati[worse]['sil']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb4ee0",
   "metadata": {},
   "source": [
    "### Perche questo esercizio (22.3)\n",
    "Applicare AgglomerativeClustering di sklearn a clienti e-commerce testando diversi K e rinominando i cluster in modo interpretabile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f959719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 22.3 - AgglomerativeClustering su clienti e-commerce\n",
    "# Obiettivo: testare K diversi, scegliere quello con silhouette migliore e nominare i cluster.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "spesa_media = [50, 55, 48, 200, 250, 230, 120, 130, 125, 45, 280, 115]\n",
    "frequenza_acquisti = [2, 3, 2, 8, 10, 9, 5, 6, 5, 2, 12, 4]\n",
    "\n",
    "df_clienti = pd.DataFrame({\n",
    "    'cliente': [f'C{i}' for i in range(1, 13)],\n",
    "    'spesa_media': spesa_media,\n",
    "    'frequenza_acquisti': frequenza_acquisti\n",
    "})\n",
    "print(\"Dataset clienti (describe):\")\n",
    "print(df_clienti[['spesa_media','frequenza_acquisti']].describe().round(1))\n",
    "\n",
    "X_clienti = df_clienti[['spesa_media', 'frequenza_acquisti']].values\n",
    "X_clienti_scaled = StandardScaler().fit_transform(X_clienti)\n",
    "assert X_clienti_scaled.shape[0] == len(df_clienti)\n",
    "\n",
    "K_range = [2, 3, 4]\n",
    "risultati = {}\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, k in enumerate(K_range):\n",
    "    agg = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "    labels = agg.fit_predict(X_clienti_scaled)\n",
    "    sil = silhouette_score(X_clienti_scaled, labels)\n",
    "    risultati[k] = {'sil': sil, 'labels': labels}\n",
    "    axes[idx].scatter(df_clienti['spesa_media'], df_clienti['frequenza_acquisti'], c=labels, cmap='viridis', s=100, edgecolors='black', alpha=0.8)\n",
    "    for i, row in df_clienti.iterrows():\n",
    "        axes[idx].annotate(row['cliente'], (row['spesa_media']+3, row['frequenza_acquisti']+0.1), fontsize=8)\n",
    "    axes[idx].set_title(f'K={k}, silhouette={sil:.3f}')\n",
    "    axes[idx].set_xlabel('Spesa media (EUR)')\n",
    "    axes[idx].set_ylabel('Frequenza acquisti')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "K_ottimale = max(risultati, key=lambda x: risultati[x]['sil'])\n",
    "print(f\"K ottimale: {K_ottimale} (silhouette {risultati[K_ottimale]['sil']:.3f})\")\n",
    "\n",
    "df_clienti['cluster'] = risultati[K_ottimale]['labels']\n",
    "profili = df_clienti.groupby('cluster')[['spesa_media','frequenza_acquisti']].mean().round(1)\n",
    "print(\"Profili medi per cluster:\")\n",
    "print(profili)\n",
    "\n",
    "nomi_cluster = {}\n",
    "for cluster_id, row in profili.iterrows():\n",
    "    if row['spesa_media'] > 180 and row['frequenza_acquisti'] > 7:\n",
    "        nome = 'Premium alta spesa'\n",
    "    elif row['spesa_media'] > 90 and row['frequenza_acquisti'] > 4:\n",
    "        nome = 'Clienti fedeli'\n",
    "    else:\n",
    "        nome = 'Occasionali a bassa spesa'\n",
    "    nomi_cluster[cluster_id] = nome\n",
    "\n",
    "print(\"Nomi assegnati:\")\n",
    "for cid, nome in nomi_cluster.items():\n",
    "    clienti = ', '.join(df_clienti[df_clienti['cluster'] == cid]['cliente'].values)\n",
    "    print(f\"Cluster {cid}: {nome} -> {clienti}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(profili)))\n",
    "for cid in profili.index:\n",
    "    mask = df_clienti['cluster'] == cid\n",
    "    ax.scatter(df_clienti.loc[mask, 'spesa_media'], df_clienti.loc[mask, 'frequenza_acquisti'], c=[colors[cid]], s=140, edgecolors='black', alpha=0.85, label=nomi_cluster[cid])\n",
    "for i, row in df_clienti.iterrows():\n",
    "    ax.annotate(row['cliente'], (row['spesa_media']+3, row['frequenza_acquisti']+0.1), fontsize=8)\n",
    "ax.set_xlabel('Spesa media (EUR)')\n",
    "ax.set_ylabel('Frequenza acquisti')\n",
    "ax.set_title(f'AgglomerativeClustering (K={K_ottimale})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593432d",
   "metadata": {},
   "source": [
    "## Sezione 6 - Conclusione operativa\n",
    "\n",
    "---\n",
    "\n",
    "## I 5 Take-Home Messages\n",
    "\n",
    "### 1. Il dendrogramma mostra TUTTE le fusioni\n",
    "A differenza di K-Means che richiede K a priori, il gerarchico costruisce l'intero albero e ti lascia scegliere dove tagliare.\n",
    "\n",
    "```\n",
    "Distanza\n",
    "   │\n",
    "   │    ╔═══════════╗  ← Taglio alto = 2 cluster\n",
    "   │    ║           ║\n",
    "   │   ╔╝           ╚╗\n",
    "   │   ║             ║  ← Taglio medio = 3 cluster\n",
    "   │  ╔╝             ╚╗\n",
    "   │  ║               ║\n",
    "   │ ╔╝               ╚╗ ← Taglio basso = 5 cluster\n",
    "   └──────────────────────\n",
    "```\n",
    "\n",
    "### 2. Ward è il default, Single è pericoloso\n",
    "\n",
    "| Linkage | Quando usarlo |\n",
    "|---------|---------------|\n",
    "| **Ward** | Default. Cluster bilanciati, simili a K-Means |\n",
    "| Complete | Vuoi cluster compatti, senza outlier |\n",
    "| Average | Compromesso, dati rumorosi |\n",
    "| Single | MAI (effetto catena), solo per forme molto allungate |\n",
    "\n",
    "**Effetto catena:** Single collega cluster lontani attraverso punti \"ponte\", creando un unico cluster allungato.\n",
    "\n",
    "### 3. Leggi le \"gambe lunghe\" nel dendrogramma\n",
    "- **Gambe lunghe** = grande salto di distanza = separazione naturale\n",
    "- **Taglia sotto una gamba lunga** per ottenere cluster ben separati\n",
    "- Se non ci sono gambe lunghe evidenti, i dati potrebbero non avere struttura cluster\n",
    "\n",
    "### 4. Usa silhouette per validare il taglio\n",
    "```python\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Prova diversi tagli\n",
    "for n_clusters in [2, 3, 4, 5]:\n",
    "    labels = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    print(f\"K={n_clusters}: Silhouette={sil:.3f}\")\n",
    "```\n",
    "\n",
    "### 5. Gerarchico vs K-Means: tabella decisionale\n",
    "\n",
    "| Criterio | K-Means | Gerarchico |\n",
    "|----------|---------|------------|\n",
    "| Dataset size | Qualsiasi | < 10.000 punti |\n",
    "| K noto | ✅ Sì | ❌ No, lo scopri |\n",
    "| Velocità | O(n·K·iter) | O(n²) o O(n³) |\n",
    "| Determinismo | ❌ Random init | ✅ Sempre uguale |\n",
    "| Output | Solo etichette | Albero completo |\n",
    "| Forma cluster | Sferica | Dipende da linkage |\n",
    "\n",
    "---\n",
    "\n",
    "## Template completo clustering gerarchico\n",
    "\n",
    "```python\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. PREPROCESSING\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. CALCOLA LINKAGE\n",
    "Z = linkage(X_scaled, method='ward')\n",
    "\n",
    "# 3. VISUALIZZA DENDROGRAMMA\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(Z, truncate_mode='lastp', p=30)\n",
    "plt.xlabel('Campioni')\n",
    "plt.ylabel('Distanza')\n",
    "plt.title('Dendrogramma (Ward linkage)')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=f'Taglio a {threshold}')\n",
    "plt.show()\n",
    "\n",
    "# 4. ESTRAI CLUSTER\n",
    "n_clusters = 3  # scelto dal dendrogramma\n",
    "labels = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "\n",
    "# 5. VALUTA\n",
    "print(f\"Silhouette: {silhouette_score(X_scaled, labels):.3f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Flowchart decisionale\n",
    "\n",
    "```\n",
    "               DATI SCALATI\n",
    "                    │\n",
    "                    ▼\n",
    "            CALCOLA linkage(X, 'ward')\n",
    "                    │\n",
    "                    ▼\n",
    "            VISUALIZZA dendrogramma\n",
    "                    │\n",
    "        ┌───────────┴───────────┐\n",
    "        │                       │\n",
    "   Gambe lunghe?           No gambe?\n",
    "        │                       │\n",
    "        ▼                       ▼\n",
    "   Taglia sotto           Nessuna struttura\n",
    "        │                  → prova altri linkage\n",
    "        ▼                  → o dati senza cluster\n",
    "   fcluster(Z, K)\n",
    "        │\n",
    "        ▼\n",
    "   Valida con silhouette\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Prossimi passi\n",
    "→ **Lezione 23**: DBSCAN - clustering basato su densità per forme arbitrarie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f4b98",
   "metadata": {},
   "source": [
    "## Sezione 7 - End-of-lesson checklist e glossario\n",
    "\n",
    "### Checklist finale\n",
    "- [ ] Dati numerici scalati con `StandardScaler`\n",
    "- [ ] Linkage calcolato con metodo motivato (Ward default)\n",
    "- [ ] Dendrogramma visualizzato e letto (gambe lunghe, salti)\n",
    "- [ ] Altezza di taglio scelta con criterio\n",
    "- [ ] Cluster estratti con `fcluster` o `AgglomerativeClustering`\n",
    "- [ ] Silhouette calcolata per validare la scelta\n",
    "- [ ] Cluster interpretati e rinominati con etichette leggibili\n",
    "- [ ] Confronto rapido con K-Means se utile\n",
    "\n",
    "---\n",
    "\n",
    "### Glossario (termini usati)\n",
    "\n",
    "| # | Termine | Definizione |\n",
    "|---|---------|-------------|\n",
    "| 1 | Agglomerativo | Fusione bottom-up: ogni punto → cluster → un unico cluster |\n",
    "| 2 | Divisivo | Divisione top-down (non in sklearn) |\n",
    "| 3 | Dendrogramma | Albero delle fusioni, distanza sull'asse Y |\n",
    "| 4 | Linkage | Criterio di distanza tra cluster |\n",
    "| 5 | Ward | Linkage che minimizza l'incremento di varianza |\n",
    "| 6 | Single | Distanza minima tra punti (effetto catena!) |\n",
    "| 7 | Complete | Distanza massima tra punti |\n",
    "| 8 | Average | Media di tutte le distanze |\n",
    "| 9 | Effetto catena | Problema di Single: cluster fusi via punti ponte |\n",
    "| 10 | Taglio | Linea orizzontale che determina K |\n",
    "| 11 | fcluster | Funzione scipy per estrarre etichette |\n",
    "| 12 | Gambe lunghe | Salti di distanza nel dendrogramma → separazioni naturali |\n",
    "\n",
    "---\n",
    "\n",
    "## Sezione 8 - Didactic changelog\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | Originale | Versione iniziale del notebook |\n",
    "| 2.0 | 2026-01-XX | Riorganizzata nelle 8 sezioni obbligatorie |\n",
    "| 2.1 | 2026-01-XX | Aggiunte rationale e checkpoint a demo e esercizi |\n",
    "| 2.2 | 2026-01-XX | Inserite Methods explained, Common errors, Glossario |\n",
    "| 2.3 | 2026-01-XX | **Espansione didattica completa**: mappa lezione con tempi; ASCII visualization 4 linkage; confronto K-Means vs gerarchico; ASCII dendrogramma con livelli taglio; 5 take-home messages; template Python completo; flowchart decisionale; tabella linkage con raccomandazioni. |\n",
    "\n",
    "---\n",
    "\n",
    "## Note di rilascio v2.3\n",
    "\n",
    "### Contenuti aggiunti\n",
    "- **Header**: mappa temporale, ASCII linkage, tabella confronto\n",
    "- **Conclusione**: 5 principi, ASCII dendrogramma, template Python, flowchart\n",
    "\n",
    "### Miglioramenti pedagogici\n",
    "- Visualizzazione ASCII dei 4 metodi di linkage\n",
    "- Warning esplicito su Single linkage e effetto catena\n",
    "- Regola \"gambe lunghe\" con interpretazione\n",
    "- Tabella decisionale gerarchico vs K-Means\n",
    "\n",
    "### Competenze verificabili\n",
    "Dopo questa lezione lo studente può:\n",
    "1. Costruire un dendrogramma con scipy\n",
    "2. Scegliere il linkage appropriato\n",
    "3. Tagliare e validare con silhouette\n",
    "4. Decidere tra gerarchico e K-Means\n",
    "\n",
    "---\n",
    "\n",
    "**Fine della lezione**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
