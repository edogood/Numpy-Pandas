{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Titolo e obiettivi\n",
    "Lezione 36: Knowledge Mining con TF-IDF e ricerca semantica semplice.\n",
    "\n",
    "---\n",
    "\n",
    "## Mappa concettuale della lezione\n",
    "\n",
    "```\n",
    "KNOWLEDGE MINING - DAL TESTO ALLA CONOSCENZA\n",
    "=============================================\n",
    "\n",
    "LIVELLO 1: RECUPERO              LIVELLO 2: ESTRAZIONE\n",
    "+----------------------+         +----------------------+\n",
    "|  Information         |         |  Knowledge           |\n",
    "|  Retrieval           |   -->   |  Extraction          |\n",
    "|  \"trova documenti\"   |         |  \"estrai fatti\"      |\n",
    "+----------------------+         +----------------------+\n",
    "         |                                |\n",
    "         v                                v\n",
    "+----------------------+         +----------------------+\n",
    "| Query -> Ranking     |         | Entita, Relazioni    |\n",
    "| TF-IDF, coseno       |         | Pattern, Regole      |\n",
    "+----------------------+         +----------------------+\n",
    "\n",
    "\n",
    "PIPELINE KNOWLEDGE MINING\n",
    "=========================\n",
    "\n",
    "    +------------------+\n",
    "    |  CORPUS GREZZO   |\n",
    "    |  (testi, PDF...) |\n",
    "    +--------+---------+\n",
    "             |\n",
    "             v\n",
    "    +------------------+\n",
    "    | PREPROCESSING    |\n",
    "    | clean, tokenize  |\n",
    "    +--------+---------+\n",
    "             |\n",
    "    +--------+---------+\n",
    "    |                  |\n",
    "    v                  v\n",
    "+----------+    +-------------+\n",
    "| RICERCA  |    | ESTRAZIONE  |\n",
    "| TF-IDF   |    | NER, Regex  |\n",
    "| ranking  |    | patterns    |\n",
    "+----+-----+    +------+------+\n",
    "     |                 |\n",
    "     v                 v\n",
    "+----------+    +-------------+\n",
    "| DOCUMENTI|    | FATTI       |\n",
    "| RILEVANTI|    | STRUTTURATI |\n",
    "+----+-----+    +------+------+\n",
    "     |                 |\n",
    "     +--------+--------+\n",
    "              |\n",
    "              v\n",
    "    +------------------+\n",
    "    |  KNOWLEDGE BASE  |\n",
    "    |  interrogabile   |\n",
    "    +------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivi didattici\n",
    "\n",
    "| # | Obiettivo | Livello |\n",
    "|---|-----------|---------|\n",
    "| 1 | Distinguere IR da Knowledge Mining | Concettuale |\n",
    "| 2 | Implementare ricerca TF-IDF su corpus custom | Operativo |\n",
    "| 3 | Combinare ricerca e estrazione in pipeline | Integrazione |\n",
    "| 4 | Gestire aggiornamenti incrementali del corpus | Avanzato |\n",
    "| 5 | Valutare limiti del matching lessicale | Critico |\n",
    "| 6 | Preparare transizione verso embeddings | Prospettiva |\n",
    "\n",
    "---\n",
    "\n",
    "## Concetti chiave\n",
    "\n",
    "> **Knowledge Mining**: processo di estrazione di conoscenza strutturata (fatti, relazioni, pattern) da dati non strutturati (testo, documenti).\n",
    "\n",
    "> **Differenza IR vs KM**: IR trova documenti rilevanti; KM estrae informazioni specifiche dai documenti trovati.\n",
    "\n",
    "> **Gap semantico**: TF-IDF cattura solo match lessicali; \"auto\" e \"macchina\" non matchano anche se sinonimi.\n",
    "\n",
    "---\n",
    "\n",
    "## Limiti del matching lessicale\n",
    "\n",
    "```\n",
    "QUERY: \"problemi cardiaci\"\n",
    "\n",
    "DOCUMENTO A: \"Il paziente presenta aritmia e insufficienza cardiaca\"\n",
    "             ^^^^^^^^ match parziale (\"cardiaca\" ~ \"cardiaci\")\n",
    "\n",
    "DOCUMENTO B: \"Problemi al cuore riscontrati durante l'esame\"\n",
    "             ^^^^^^^^ match (\"problemi\") ma \"cuore\" =/= \"cardiaci\"\n",
    "\n",
    "DOCUMENTO C: \"Patologie cardiovascolari in aumento\"\n",
    "             NO MATCH LESSICALE (sinonimi, non termini identici)\n",
    "\n",
    "TF-IDF RANKING: A > B > C\n",
    "RILEVANZA REALE: A = B = C (tutti rilevanti!)\n",
    "```\n",
    "\n",
    "**Soluzione**: sinonimi manuali, stemming, o passaggio a embeddings semantici.\n",
    "\n",
    "---\n",
    "\n",
    "## Cosa useremo\n",
    "- `TfidfVectorizer` per rappresentazione vettoriale\n",
    "- `cosine_similarity` per ranking\n",
    "- Pattern regex per estrazione base\n",
    "- Dizionari di sinonimi per espansione\n",
    "\n",
    "## Prerequisiti\n",
    "- Information Retrieval base (Lezione 35)\n",
    "- TF-IDF e similarita' (Lezione 31)\n",
    "- Regex e pattern matching (Lezione 34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Teoria concettuale approfondita\n",
    "- Knowledge mining: trasformare documenti in vettori per recuperarli con query.\n",
    "- TF-IDF: pesa termini in base a frequenza/rarita'; utile per ranking.\n",
    "- Similarita' coseno: misura di vicinanza tra query e documenti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Schema mentale / mappa decisionale\n",
    "1. Raccogli documenti e pulisci testo.\n",
    "2. Fit del TF-IDF sul corpus; conserva vocabolario.\n",
    "3. Trasforma le query con lo stesso vectorizer.\n",
    "4. Calcola similarita' coseno e ordina i documenti.\n",
    "5. Valida risultati e aggiusta stopword/sinonimi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sezione dimostrativa\n",
    "Demo: pipeline TF-IDF, funzione di ricerca, due query di esempio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup librerie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus simulato\n",
    "documents = [\n",
    "    \"Politica estera e nuove alleanze in Europa\",\n",
    "    \"Analisi finanziaria e bilancio trimestrale dell'azienda\",\n",
    "    \"Guida pratica alla richiesta di rimborsi per viaggi\",\n",
    "    \"Manuale operativo per assistenza clienti e ticketing\",\n",
    "    \"Tutorial di machine learning applicato al marketing\",\n",
    "]\n",
    "print(f\"Documenti: {len(documents)}\")\n",
    "assert len(documents) > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vettorizzazione TF-IDF con stopword italiane\n",
    "vectorizer = TfidfVectorizer(stop_words='italian')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(f\"Shape TF-IDF: {X.shape}, sparsimita': {1 - X.nnz/(X.shape[0]*X.shape[1]):.1%}\")\n",
    "assert X.shape[0] == len(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di ricerca con similarita' coseno\n",
    "\n",
    "def search(query, top_k=3):\n",
    "    q_vec = vectorizer.transform([query])\n",
    "    sims = cosine_similarity(q_vec, X).flatten()\n",
    "    order = sims.argsort()[::-1][:top_k]\n",
    "    return [(i, sims[i], documents[i]) for i in order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query di esempio\n",
    "queries = [\"richiesta rimborsi viaggio\", \"marketing machine learning\"]\n",
    "for q in queries:\n",
    "    print(f\"\n",
    "Query: {q}\")\n",
    "    for idx, score, doc in search(q):\n",
    "        print(f\"  Score {score:.3f} -> {doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osservazioni\n",
    "- Le query recuperano documenti con overlap lessicale; sinonimi non gestiti.\n",
    "- Sparsimita' alta: controlla stopword e vocabolario per non degradare le prestazioni.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Esercizi svolti (step-by-step)\n",
    "## Esercizio 36.1 - Aggiungere un documento e rilanciare query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 36.1\n",
    "new_doc = \"Procedura dettagliata per rimborsi di biglietti aerei e hotel\"\n",
    "corpus2 = documents + [new_doc]\n",
    "X2 = vectorizer.fit_transform(corpus2)\n",
    "q_vec = vectorizer.transform([queries[0]])\n",
    "sims = cosine_similarity(q_vec, X2).flatten()\n",
    "order = sims.argsort()[::-1][:3]\n",
    "print(\"Top3 con nuovo documento:\")\n",
    "for i in order:\n",
    "    print(i, sims[i], corpus2[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 36.2 - Stopword personalizzate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 36.2\n",
    "custom_stop = ['analisi','guida','manuale']\n",
    "vec_custom = TfidfVectorizer(stop_words=set(custom_stop + list(TfidfVectorizer(stop_words='italian').get_stop_words())))\n",
    "Xc = vec_custom.fit_transform(documents)\n",
    "print(f\"Sparsimita' con stopword custom: {1 - Xc.nnz/(Xc.shape[0]*Xc.shape[1]):.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 36.3 - Sinonimi manuali\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 36.3\n",
    "synonyms = {'rimborsi': 'rimborso', 'refund': 'rimborso'}\n",
    "normalized = []\n",
    "for doc in documents:\n",
    "    tmp = doc\n",
    "    for k,v in synonyms.items():\n",
    "        tmp = tmp.replace(k, v)\n",
    "    normalized.append(tmp)\n",
    "\n",
    "vec_norm = TfidfVectorizer(stop_words='italian')\n",
    "Xn = vec_norm.fit_transform(normalized)\n",
    "print(\"Vocabolario normalizzato (prime 10 parole):\", list(vec_norm.get_feature_names_out())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusione operativa - Bignami Knowledge Mining\n",
    "\n",
    "---\n",
    "\n",
    "## I 5 Take-Home Messages\n",
    "\n",
    "| # | Concetto | Perche' conta |\n",
    "|---|----------|---------------|\n",
    "| 1 | **KM = IR + Estrazione** | Non basta trovare documenti, devi estrarre fatti |\n",
    "| 2 | **TF-IDF e' baseline, non soluzione finale** | Match lessicale ha gap semantico intrinseco |\n",
    "| 3 | **Sinonimi manuali colmano gap parzialmente** | Dizionari di dominio migliorano recall |\n",
    "| 4 | **Vocabolario fisso richiede aggiornamento** | Corpus che cresce -> refit periodico |\n",
    "| 5 | **Embeddings superano limiti lessicali** | Prossimo passo per semantic search vera |\n",
    "\n",
    "---\n",
    "\n",
    "## IR vs Knowledge Mining\n",
    "\n",
    "```\n",
    "+------------------+------------------+------------------+\n",
    "|   ASPETTO        |   IR             |   KNOWLEDGE      |\n",
    "|                  |                  |   MINING         |\n",
    "+------------------+------------------+------------------+\n",
    "| Output           | Lista documenti  | Fatti strutturati|\n",
    "| Granularita'     | Documento intero | Entita/relazioni |\n",
    "| Query            | Testo libero     | Pattern specifici|\n",
    "| Valutazione      | Precision/Recall | Accuracy estratto|\n",
    "| Uso tipico       | Motori di ricerca| Knowledge graphs |\n",
    "+------------------+------------------+------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline combinata IR + Estrazione\n",
    "\n",
    "```\n",
    "QUERY UTENTE                    PATTERN ESTRAZIONE\n",
    "     |                                |\n",
    "     v                                v\n",
    "+---------+                    +-----------+\n",
    "| TF-IDF  |                    | Regex/NER |\n",
    "| search  |                    | rules     |\n",
    "+----+----+                    +-----+-----+\n",
    "     |                               |\n",
    "     v                               v\n",
    "+------------------+          +------------------+\n",
    "| TOP-K DOCUMENTI  |   --->   | ESTRAI FATTI DA  |\n",
    "| rilevanti        |          | CIASCUN DOC      |\n",
    "+------------------+          +------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                              +------------------+\n",
    "                              | AGGREGAZIONE     |\n",
    "                              | dedup, merge     |\n",
    "                              +------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                              +------------------+\n",
    "                              | KNOWLEDGE BASE   |\n",
    "                              | strutturata      |\n",
    "                              +------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Template operativo\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "class KnowledgeMiner:\n",
    "    def __init__(self, corpus, synonyms=None):\n",
    "        self.corpus = corpus\n",
    "        self.synonyms = synonyms or {}\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        self.doc_matrix = self.vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    def search(self, query, top_k=5):\n",
    "        # Espandi query con sinonimi\n",
    "        expanded = self._expand(query)\n",
    "        q_vec = self.vectorizer.transform([expanded])\n",
    "        scores = cosine_similarity(q_vec, self.doc_matrix).flatten()\n",
    "        top_idx = scores.argsort()[::-1][:top_k]\n",
    "        return [(i, self.corpus[i], scores[i]) for i in top_idx]\n",
    "    \n",
    "    def _expand(self, query):\n",
    "        tokens = query.lower().split()\n",
    "        expanded = tokens.copy()\n",
    "        for t in tokens:\n",
    "            expanded.extend(self.synonyms.get(t, []))\n",
    "        return ' '.join(expanded)\n",
    "    \n",
    "    def extract_from_results(self, results, pattern):\n",
    "        \"\"\"Estrae fatti dai documenti trovati\"\"\"\n",
    "        facts = []\n",
    "        for idx, doc, score in results:\n",
    "            matches = re.findall(pattern, doc, re.IGNORECASE)\n",
    "            facts.extend([(idx, m, score) for m in matches])\n",
    "        return facts\n",
    "    \n",
    "    def add_documents(self, new_docs):\n",
    "        \"\"\"Aggiunge documenti e reindicizza\"\"\"\n",
    "        self.corpus.extend(new_docs)\n",
    "        self.doc_matrix = self.vectorizer.fit_transform(self.corpus)\n",
    "\n",
    "# Uso\n",
    "miner = KnowledgeMiner(corpus, synonyms={'auto': ['macchina', 'veicolo']})\n",
    "results = miner.search(\"problemi auto\")\n",
    "facts = miner.extract_from_results(results, r'\\b[A-Z]{2}\\d{3}[A-Z]{2}\\b')  # targhe\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Errori comuni e soluzioni\n",
    "\n",
    "| Errore | Conseguenza | Soluzione |\n",
    "|--------|-------------|-----------|\n",
    "| Ignorare gap semantico | Bassa recall su sinonimi | Dizionari, stemming, embeddings |\n",
    "| Non aggiornare indice | Nuovi doc non trovabili | Refit periodico o incrementale |\n",
    "| Estrazione senza validazione | Falsi positivi | Pattern precisi + post-filtering |\n",
    "| Corpus troppo piccolo | Vocabolario povero | Aumentare dati o usare pretrained |\n",
    "\n",
    "---\n",
    "\n",
    "## Metodi e concetti chiave\n",
    "\n",
    "| Elemento | Ruolo |\n",
    "|----------|-------|\n",
    "| `TfidfVectorizer` | Indicizzazione corpus |\n",
    "| `cosine_similarity` | Ranking per rilevanza |\n",
    "| Dizionario sinonimi | Espansione query manuale |\n",
    "| Regex patterns | Estrazione fatti |\n",
    "| Refit | Aggiornamento indice |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Checklist di fine lezione\n",
    "- [ ] Ho pulito il corpus e scelto stopword adeguate.\n",
    "- [ ] Ho fit il TF-IDF sul corpus e usato transform sulle query.\n",
    "- [ ] Ho controllato sparsimita' e dimensione del vocabolario.\n",
    "- [ ] Ho testato almeno due query e valutato i risultati.\n",
    "- [ ] Ho documentato normalizzazioni/sinonimi applicati.\n",
    "\n",
    "Glossario\n",
    "- TF-IDF: peso termini per frequenza/rarita'.\n",
    "- Similarita' coseno: misura di vicinanza tra vettori.\n",
    "- Stopword: termini poco informativi rimossi dal vocabolario.\n",
    "- Vocabolario: elenco di termini indicizzati dal vectorizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Changelog didattico\n",
    "\n",
    "| Versione | Data | Modifiche |\n",
    "|----------|------|-----------|\n",
    "| 1.0 | 2024-01-XX | Struttura iniziale 8 sezioni |\n",
    "| 2.0 | 2024-12-XX | Espansione completa Knowledge Mining |\n",
    "| 2.1 | - | Pipeline ASCII a due livelli (IR + Estrazione) |\n",
    "| 2.2 | - | Esempio gap semantico con documenti medici |\n",
    "| 2.3 | - | Confronto tabellare IR vs Knowledge Mining |\n",
    "| 2.4 | - | Classe KnowledgeMiner completa con metodi |\n",
    "| 2.5 | - | Gestione aggiornamento incrementale corpus |\n",
    "| 2.6 | - | Transizione concettuale verso embeddings |\n",
    "\n",
    "---\n",
    "\n",
    "## Note di versione\n",
    "\n",
    "**v2.0 - Espansione didattica completa**\n",
    "- Posizionamento KM come evoluzione di IR\n",
    "- Visualizzazione esplicita del gap semantico\n",
    "- Pipeline combinata ricerca + estrazione\n",
    "- Classe template riutilizzabile per progetti\n",
    "- Emphasis su limiti TF-IDF e prossimi passi\n",
    "- Preparazione per embeddings e semantic search\n",
    "\n",
    "**Dipendenze didattiche**\n",
    "- Richiede: Lezione 35 (IR base), Lezione 34 (patterns)\n",
    "- Prepara: Lezione 37+ (Deep Learning, embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
